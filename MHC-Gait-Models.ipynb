{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6MWT Total Sample Check\n",
    "\n",
    "### healthCodes of interest/associated synapse table:\n",
    "\n",
    "1. cab9f4ee-54e0-4b08-8eba-3b48085bd142 (v4-v1)\n",
    "2. 33f22bad-4570-43bb-bf68-263e6865ef76 (v4-v1)\n",
    "3. ff489c8a-f5ff-4f00-9682-33c44df02621 (v4-v2)\n",
    "4. 6fd3148e-f490-417a-9da8-a31d947e7aed (v4-v1)\n",
    "5. bb6613c1-5b48-4744-a5f5-2387149da94d (v4-v2)\n",
    "6. 43dcb6b4-24a9-4b71-bc9f-eef87e8adadb (v4-v2)\n",
    "7. fe1e5f81-ed68-4c45-b1a7-3a7443d5ae76 (v4-v2)\n",
    "8. 047b75f9-2778-4068-bc30-d47e8ea0780e (v4-v1)\n",
    "9. c6a9c011-defc-48a9-bd74-de6d3a72d2bd (v4-v2)\n",
    "10. e30dae44-8b7e-41a5-98e5-3f8abba35352 (v4-v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "# hc_filenum is the dictionary which stores the healthCode and num of files associated with that healthCode\n",
    "\n",
    "# num_of_files is just a list to count number of instances of certain number of files (Are there 0 files, 1 file...?)\n",
    "\n",
    "directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwt/accel_walk_dir'\n",
    "directory = os.fsencode(directory_in_str)\n",
    "hc_filenum = dict()\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    i = 0\n",
    "    for file in files:\n",
    "        i += 1\n",
    "    hc_filenum.update({subdir.decode()[subdir.decode().rfind('/') + 1:]: i})\n",
    "\n",
    "\n",
    "num_of_files = []\n",
    "for k, v in hc_filenum.items():\n",
    "        num_of_files.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291\n",
      "8129\n"
     ]
    }
   ],
   "source": [
    "print(num_of_files.count(0))\n",
    "print(len(hc_filenum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>healthCode</th>\n",
       "      <th>weight</th>\n",
       "      <th>weight2</th>\n",
       "      <th>sex</th>\n",
       "      <th>sex2</th>\n",
       "      <th>height</th>\n",
       "      <th>height2</th>\n",
       "      <th>currentAge</th>\n",
       "      <th>currentAge2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77f77904-6969-4b69-b408-131d7e434938</td>\n",
       "      <td>9c0a77cd-159b-423b-8e73-b7f3666ba938</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de3b154b-fe81-4ef7-b392-e51c36137e12</td>\n",
       "      <td>c4ed1db6-9bc0-46e5-a296-fd452a773072</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fd22a4b-b573-4a14-9503-9f4027a1822c</td>\n",
       "      <td>e4c01bfb-9688-4b96-9e80-137b3b0a6a4c</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8712c75a-2a69-41d7-9baf-eb3569e011af</td>\n",
       "      <td>c4ed1db6-9bc0-46e5-a296-fd452a773072</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2ee84b1b-ce33-405f-a27e-ab9ca150fe3b</td>\n",
       "      <td>90ccc54e-7916-4042-871b-bc25cc58867e</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ba83c4a7-1bb8-46b6-829b-e6ef7ff9696c</td>\n",
       "      <td>7008bee7-5a68-46a9-80a0-0f280df94f6d</td>\n",
       "      <td>221.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>03793227-ab8f-41ff-bc17-039b6eaa56db</td>\n",
       "      <td>d670264b-3edc-4d1f-b42d-6430bf9efb70</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43828c79-e658-4eca-a9ac-9fa27329fe4b</td>\n",
       "      <td>620e7c23-16bf-4b7c-80a1-af3a15e900a2</td>\n",
       "      <td>217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6788bff0-b65c-406f-b4c0-7f4a0cfdae20</td>\n",
       "      <td>74982b88-b3b3-4aa4-a7f1-715df241ab44</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bd5a34bc-7617-4ed2-a888-b57a1830f419</td>\n",
       "      <td>280f17b1-8b9e-40b5-9dd5-9c6d1e1b10ee</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99482689-3851-4ed3-bfc5-7124e709f0f2</td>\n",
       "      <td>6c23d224-591e-4160-b1df-706bfa2268ef</td>\n",
       "      <td>187.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fca99900-be8a-444e-a01f-b21b7198a807</td>\n",
       "      <td>deaebe71-9a37-493a-ada9-d93c4a23d83f</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6e153812-8d9c-4c09-ad83-9836652fb61c</td>\n",
       "      <td>cb7f3011-b6d3-4ff9-baba-0689994b23e2</td>\n",
       "      <td>361.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bb9ae76d-cff1-42d5-9673-1c339601bed9</td>\n",
       "      <td>d156e6e9-4a02-409d-9c59-aa04d17101d9</td>\n",
       "      <td>176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>de5ee62d-1caa-4dbc-9b8b-b307dbdaf1dc</td>\n",
       "      <td>f771225b-1ec6-4797-a79d-26f7d056e86c</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6b95bc22-68e9-4549-ae99-60cf70b4a8d9</td>\n",
       "      <td>915c331a-7250-4ba7-9047-39f69046e3d0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7fb16985-52ca-47a6-b87e-d1867fbe2f29</td>\n",
       "      <td>6819a834-d7fc-418f-9227-4718b05757bd</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>83455874-4b3a-4257-8188-2ecc94344608</td>\n",
       "      <td>f575687b-3b93-47af-950b-77ae2ee558d6</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>e9a2c2c0-0128-41f1-9da0-47477d940090</td>\n",
       "      <td>734d92f4-0b17-497c-a792-8c8aacf0c0f3</td>\n",
       "      <td>205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>d0984f7a-a6cc-4936-a3fb-25d52a200488</td>\n",
       "      <td>38520603-e165-41fa-a1ff-31aae34e5310</td>\n",
       "      <td>177.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>61ab53b8-8f45-4bbb-b939-775a64f1f7a4</td>\n",
       "      <td>1420f20a-7e25-4df1-b79f-194125b5f512</td>\n",
       "      <td>122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8d10c67c-ad02-4ed1-b69e-77c7f63046dc</td>\n",
       "      <td>44b3792d-d404-4eb0-97ab-942ad969f488</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6df7e9b0-7ccd-4537-99b1-38c872a39704</td>\n",
       "      <td>46b8102e-513f-40e5-9479-ee0df3d5b13a</td>\n",
       "      <td>271.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4445521e-6a8b-4297-83be-f5c942cd4e35</td>\n",
       "      <td>c78007ad-4a43-4fff-b81a-95fa78a74c53</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08a63a89-fdbb-41ba-948d-4deec8b04d9d</td>\n",
       "      <td>e28f3152-feb4-4412-82fe-4f8edcfff841</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>e5c683c5-2043-4c2d-affd-50307d82f6ae</td>\n",
       "      <td>3c3d2250-f475-4573-89a6-843ea50d5768</td>\n",
       "      <td>362.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2654c1da-7d79-4d2c-843a-17e3f325475e</td>\n",
       "      <td>90ccc54e-7916-4042-871b-bc25cc58867e</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>be93a9fd-812c-42d7-a1c1-842a84c33c87</td>\n",
       "      <td>09913b6c-7d0e-4959-9921-6dff5c8b82d4</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5aa32fc1-be45-4606-9808-4aadc0ef6995</td>\n",
       "      <td>74982b88-b3b3-4aa4-a7f1-715df241ab44</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>86b476eb-cc23-415f-8f24-a0d503fb52f6</td>\n",
       "      <td>7723c588-8176-4c00-ab36-b5ba1697173b</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44774</th>\n",
       "      <td>30559c42-2c0a-4cf4-b268-c18f5a4a55cc</td>\n",
       "      <td>22518c30-9ac7-4272-94c0-a552a3508926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44775</th>\n",
       "      <td>ab90b966-6efe-42f0-ba58-40ef67fb2bdc</td>\n",
       "      <td>d1c561c6-eb1f-476d-b63a-dafa7546b63c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44776</th>\n",
       "      <td>0c1b572c-f5c0-4d27-8b29-93c29ca2e453</td>\n",
       "      <td>776c151a-1c60-4109-9e54-561906812ce0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44777</th>\n",
       "      <td>a83350d3-e1de-4f4f-828a-f2457eac02e7</td>\n",
       "      <td>25e56528-4939-44b6-b243-137b7263b0b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44778</th>\n",
       "      <td>1811bb6d-4e14-42cc-a95c-5aa8288f0a2e</td>\n",
       "      <td>bc584770-2253-4344-ad2f-ead911b6e3a2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44779</th>\n",
       "      <td>860f6d39-9315-4de8-a523-cd6110c74fec</td>\n",
       "      <td>f372ae44-7f66-4ac9-8f0b-db519563927a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44780</th>\n",
       "      <td>0aaddc76-2167-49b1-ad90-4a2c07941f90</td>\n",
       "      <td>f372ae44-7f66-4ac9-8f0b-db519563927a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44781</th>\n",
       "      <td>c3006bc3-3b6d-410f-bbdb-023822ea9ff2</td>\n",
       "      <td>fec21464-5eb7-4c65-bc7c-7cbff43d2850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44782</th>\n",
       "      <td>b33fa2f4-3cf4-4909-8b1d-400d396ca925</td>\n",
       "      <td>3405b755-a037-4b1d-9ebd-6c46d00d67ba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44783</th>\n",
       "      <td>d7502988-17b1-4f8e-9486-6176eaf9ed22</td>\n",
       "      <td>47fc2f2c-80e3-40fd-b7f6-e171eabbafb7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44784</th>\n",
       "      <td>a448f863-c190-4a79-bfd6-aa7f44a042d2</td>\n",
       "      <td>cbaf99cb-fd25-4434-a8bc-e483eb2d0c7e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44785</th>\n",
       "      <td>91e4eb36-f933-43de-82db-7f20278266e0</td>\n",
       "      <td>5784f49f-33cf-415e-bf5f-667086604500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44786</th>\n",
       "      <td>e98c0309-b81e-4f99-ae23-8877b0f2c254</td>\n",
       "      <td>d1c561c6-eb1f-476d-b63a-dafa7546b63c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44787</th>\n",
       "      <td>889cc3c5-9fb7-4a3e-a81e-e1e82d190475</td>\n",
       "      <td>49461e00-809a-4d3e-bffe-1d50b71b4469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44788</th>\n",
       "      <td>7e43f30e-6b04-4934-b1d0-12cbefb65bea</td>\n",
       "      <td>f39b2eb4-3211-403d-825b-e717a5cdb50d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44789</th>\n",
       "      <td>a44f6e75-2414-4edd-af81-a61b4d4978c5</td>\n",
       "      <td>80877de1-e1f6-4f50-b0ae-7ece39c4b219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44790</th>\n",
       "      <td>d3d1b9e9-a2bc-4eb1-adcd-0d51fc4ac53b</td>\n",
       "      <td>aef3957c-3834-4f87-9f7f-bcfab8ea0649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44791</th>\n",
       "      <td>8d63d8dc-7b8a-4291-8273-a52b69023b11</td>\n",
       "      <td>6ef1357c-4174-4420-8af4-83b633bd277a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44792</th>\n",
       "      <td>c862f72c-d802-4727-a85a-98b6cb6fd8b2</td>\n",
       "      <td>5f7c25ee-2e4f-45f7-9e81-84c91be28cc8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44793</th>\n",
       "      <td>6f961d0a-6605-46be-bb60-f1bbb51adb49</td>\n",
       "      <td>0ea311be-7830-4d2d-bb3e-0ec055698f1f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44794</th>\n",
       "      <td>7ae0e816-24fe-49a1-8b72-6c581979c2ba</td>\n",
       "      <td>1d062596-e8e7-4a75-a1c0-a39e053c47b9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44795</th>\n",
       "      <td>fc0d80f9-0032-418e-9110-858c68289cd6</td>\n",
       "      <td>58972dcc-54d4-4b9f-96c8-da6c24dad91e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44796</th>\n",
       "      <td>05b5fc44-605e-478c-8442-66b4cb52ebbb</td>\n",
       "      <td>f2ce3938-5a24-4dc0-9991-ebee218bf506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44797</th>\n",
       "      <td>3b3e9f2b-b079-4840-a342-c34a40c39f28</td>\n",
       "      <td>31948491-672b-4fe0-884e-fa7161aae953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44798</th>\n",
       "      <td>2011e0cc-f59e-477c-b4e8-e3f2b896fb13</td>\n",
       "      <td>bd554b83-81af-4cae-89ca-4aa7362c037f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44799</th>\n",
       "      <td>0d414b2d-6ac8-410d-a0ff-a3c029c00f97</td>\n",
       "      <td>bf181501-f803-43cf-bbce-5bb19f29b380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44800</th>\n",
       "      <td>3ee7f904-d3a0-44af-8c23-96a787f36e0c</td>\n",
       "      <td>5784f49f-33cf-415e-bf5f-667086604500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44801</th>\n",
       "      <td>d52cd6f7-c376-4397-843f-df60748ea597</td>\n",
       "      <td>0108dedd-2159-434b-831f-ca68b8b2bff5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44802</th>\n",
       "      <td>63b613d5-28fb-4615-bf9c-b39d8fe8f3e3</td>\n",
       "      <td>99141974-57ac-433c-91fc-19f451172b5f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44803</th>\n",
       "      <td>fd34042c-a28e-4218-aff4-6cd13b0fc242</td>\n",
       "      <td>76f64214-d201-4d2e-aa84-3c9eba629517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34685 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   recordId  \\\n",
       "0      77f77904-6969-4b69-b408-131d7e434938   \n",
       "1      de3b154b-fe81-4ef7-b392-e51c36137e12   \n",
       "2      5fd22a4b-b573-4a14-9503-9f4027a1822c   \n",
       "3      8712c75a-2a69-41d7-9baf-eb3569e011af   \n",
       "4      2ee84b1b-ce33-405f-a27e-ab9ca150fe3b   \n",
       "5      ba83c4a7-1bb8-46b6-829b-e6ef7ff9696c   \n",
       "6      03793227-ab8f-41ff-bc17-039b6eaa56db   \n",
       "7      43828c79-e658-4eca-a9ac-9fa27329fe4b   \n",
       "8      6788bff0-b65c-406f-b4c0-7f4a0cfdae20   \n",
       "9      bd5a34bc-7617-4ed2-a888-b57a1830f419   \n",
       "10     99482689-3851-4ed3-bfc5-7124e709f0f2   \n",
       "11     fca99900-be8a-444e-a01f-b21b7198a807   \n",
       "12     6e153812-8d9c-4c09-ad83-9836652fb61c   \n",
       "13     bb9ae76d-cff1-42d5-9673-1c339601bed9   \n",
       "14     de5ee62d-1caa-4dbc-9b8b-b307dbdaf1dc   \n",
       "15     6b95bc22-68e9-4549-ae99-60cf70b4a8d9   \n",
       "16     7fb16985-52ca-47a6-b87e-d1867fbe2f29   \n",
       "17     83455874-4b3a-4257-8188-2ecc94344608   \n",
       "19     e9a2c2c0-0128-41f1-9da0-47477d940090   \n",
       "20     d0984f7a-a6cc-4936-a3fb-25d52a200488   \n",
       "21     61ab53b8-8f45-4bbb-b939-775a64f1f7a4   \n",
       "22     8d10c67c-ad02-4ed1-b69e-77c7f63046dc   \n",
       "23     6df7e9b0-7ccd-4537-99b1-38c872a39704   \n",
       "24     4445521e-6a8b-4297-83be-f5c942cd4e35   \n",
       "25     08a63a89-fdbb-41ba-948d-4deec8b04d9d   \n",
       "26     e5c683c5-2043-4c2d-affd-50307d82f6ae   \n",
       "27     2654c1da-7d79-4d2c-843a-17e3f325475e   \n",
       "28     be93a9fd-812c-42d7-a1c1-842a84c33c87   \n",
       "29     5aa32fc1-be45-4606-9808-4aadc0ef6995   \n",
       "30     86b476eb-cc23-415f-8f24-a0d503fb52f6   \n",
       "...                                     ...   \n",
       "44774  30559c42-2c0a-4cf4-b268-c18f5a4a55cc   \n",
       "44775  ab90b966-6efe-42f0-ba58-40ef67fb2bdc   \n",
       "44776  0c1b572c-f5c0-4d27-8b29-93c29ca2e453   \n",
       "44777  a83350d3-e1de-4f4f-828a-f2457eac02e7   \n",
       "44778  1811bb6d-4e14-42cc-a95c-5aa8288f0a2e   \n",
       "44779  860f6d39-9315-4de8-a523-cd6110c74fec   \n",
       "44780  0aaddc76-2167-49b1-ad90-4a2c07941f90   \n",
       "44781  c3006bc3-3b6d-410f-bbdb-023822ea9ff2   \n",
       "44782  b33fa2f4-3cf4-4909-8b1d-400d396ca925   \n",
       "44783  d7502988-17b1-4f8e-9486-6176eaf9ed22   \n",
       "44784  a448f863-c190-4a79-bfd6-aa7f44a042d2   \n",
       "44785  91e4eb36-f933-43de-82db-7f20278266e0   \n",
       "44786  e98c0309-b81e-4f99-ae23-8877b0f2c254   \n",
       "44787  889cc3c5-9fb7-4a3e-a81e-e1e82d190475   \n",
       "44788  7e43f30e-6b04-4934-b1d0-12cbefb65bea   \n",
       "44789  a44f6e75-2414-4edd-af81-a61b4d4978c5   \n",
       "44790  d3d1b9e9-a2bc-4eb1-adcd-0d51fc4ac53b   \n",
       "44791  8d63d8dc-7b8a-4291-8273-a52b69023b11   \n",
       "44792  c862f72c-d802-4727-a85a-98b6cb6fd8b2   \n",
       "44793  6f961d0a-6605-46be-bb60-f1bbb51adb49   \n",
       "44794  7ae0e816-24fe-49a1-8b72-6c581979c2ba   \n",
       "44795  fc0d80f9-0032-418e-9110-858c68289cd6   \n",
       "44796  05b5fc44-605e-478c-8442-66b4cb52ebbb   \n",
       "44797  3b3e9f2b-b079-4840-a342-c34a40c39f28   \n",
       "44798  2011e0cc-f59e-477c-b4e8-e3f2b896fb13   \n",
       "44799  0d414b2d-6ac8-410d-a0ff-a3c029c00f97   \n",
       "44800  3ee7f904-d3a0-44af-8c23-96a787f36e0c   \n",
       "44801  d52cd6f7-c376-4397-843f-df60748ea597   \n",
       "44802  63b613d5-28fb-4615-bf9c-b39d8fe8f3e3   \n",
       "44803  fd34042c-a28e-4218-aff4-6cd13b0fc242   \n",
       "\n",
       "                                 healthCode  weight  weight2     sex    sex2  \\\n",
       "0      9c0a77cd-159b-423b-8e73-b7f3666ba938   180.0      NaN  Female     NaN   \n",
       "1      c4ed1db6-9bc0-46e5-a296-fd452a773072   142.0      NaN    Male     NaN   \n",
       "2      e4c01bfb-9688-4b96-9e80-137b3b0a6a4c   190.0      NaN    Male     NaN   \n",
       "3      c4ed1db6-9bc0-46e5-a296-fd452a773072   142.0      NaN    Male     NaN   \n",
       "4      90ccc54e-7916-4042-871b-bc25cc58867e   245.0      NaN    Male     NaN   \n",
       "5      7008bee7-5a68-46a9-80a0-0f280df94f6d   221.0      NaN    Male     NaN   \n",
       "6      d670264b-3edc-4d1f-b42d-6430bf9efb70   140.0      NaN    Male     NaN   \n",
       "7      620e7c23-16bf-4b7c-80a1-af3a15e900a2   217.0      NaN    Male     NaN   \n",
       "8      74982b88-b3b3-4aa4-a7f1-715df241ab44   207.0      NaN    Male     NaN   \n",
       "9      280f17b1-8b9e-40b5-9dd5-9c6d1e1b10ee   140.0      NaN    Male     NaN   \n",
       "10     6c23d224-591e-4160-b1df-706bfa2268ef   187.0      NaN    Male     NaN   \n",
       "11     deaebe71-9a37-493a-ada9-d93c4a23d83f   165.0      NaN    Male     NaN   \n",
       "12     cb7f3011-b6d3-4ff9-baba-0689994b23e2   361.0      NaN    Male     NaN   \n",
       "13     d156e6e9-4a02-409d-9c59-aa04d17101d9   176.0      NaN    Male     NaN   \n",
       "14     f771225b-1ec6-4797-a79d-26f7d056e86c   195.0      NaN    Male     NaN   \n",
       "15     915c331a-7250-4ba7-9047-39f69046e3d0   182.0      NaN    Male     NaN   \n",
       "16     6819a834-d7fc-418f-9227-4718b05757bd   121.0      NaN  Female     NaN   \n",
       "17     f575687b-3b93-47af-950b-77ae2ee558d6    77.0      NaN  Female     NaN   \n",
       "19     734d92f4-0b17-497c-a792-8c8aacf0c0f3   205.0      NaN    Male     NaN   \n",
       "20     38520603-e165-41fa-a1ff-31aae34e5310   177.0      NaN    Male     NaN   \n",
       "21     1420f20a-7e25-4df1-b79f-194125b5f512   122.0      NaN  Female     NaN   \n",
       "22     44b3792d-d404-4eb0-97ab-942ad969f488   130.0      NaN  Female     NaN   \n",
       "23     46b8102e-513f-40e5-9479-ee0df3d5b13a   271.0      NaN    Male     NaN   \n",
       "24     c78007ad-4a43-4fff-b81a-95fa78a74c53   180.0      NaN    Male     NaN   \n",
       "25     e28f3152-feb4-4412-82fe-4f8edcfff841   165.0      NaN    Male     NaN   \n",
       "26     3c3d2250-f475-4573-89a6-843ea50d5768   362.0      NaN    Male     NaN   \n",
       "27     90ccc54e-7916-4042-871b-bc25cc58867e   245.0      NaN    Male     NaN   \n",
       "28     09913b6c-7d0e-4959-9921-6dff5c8b82d4   180.0      NaN    Male     NaN   \n",
       "29     74982b88-b3b3-4aa4-a7f1-715df241ab44   207.0      NaN    Male     NaN   \n",
       "30     7723c588-8176-4c00-ab36-b5ba1697173b   155.0      NaN    Male     NaN   \n",
       "...                                     ...     ...      ...     ...     ...   \n",
       "44774  22518c30-9ac7-4272-94c0-a552a3508926     NaN    137.0     NaN    Male   \n",
       "44775  d1c561c6-eb1f-476d-b63a-dafa7546b63c     NaN    123.0     NaN  Female   \n",
       "44776  776c151a-1c60-4109-9e54-561906812ce0     NaN    153.0     NaN    Male   \n",
       "44777  25e56528-4939-44b6-b243-137b7263b0b3     NaN    255.0     NaN  Female   \n",
       "44778  bc584770-2253-4344-ad2f-ead911b6e3a2     NaN    199.0     NaN    Male   \n",
       "44779  f372ae44-7f66-4ac9-8f0b-db519563927a     NaN      0.0     NaN  Female   \n",
       "44780  f372ae44-7f66-4ac9-8f0b-db519563927a     NaN      0.0     NaN  Female   \n",
       "44781  fec21464-5eb7-4c65-bc7c-7cbff43d2850     NaN      0.0     NaN    Male   \n",
       "44782  3405b755-a037-4b1d-9ebd-6c46d00d67ba     NaN    161.0     NaN  Female   \n",
       "44783  47fc2f2c-80e3-40fd-b7f6-e171eabbafb7     NaN    137.0     NaN  Female   \n",
       "44784  cbaf99cb-fd25-4434-a8bc-e483eb2d0c7e     NaN    256.0     NaN    Male   \n",
       "44785  5784f49f-33cf-415e-bf5f-667086604500     NaN    195.0     NaN    Male   \n",
       "44786  d1c561c6-eb1f-476d-b63a-dafa7546b63c     NaN    123.0     NaN  Female   \n",
       "44787  49461e00-809a-4d3e-bffe-1d50b71b4469     NaN    145.0     NaN  Female   \n",
       "44788  f39b2eb4-3211-403d-825b-e717a5cdb50d     NaN    109.0     NaN  Female   \n",
       "44789  80877de1-e1f6-4f50-b0ae-7ece39c4b219     NaN    147.0     NaN  Female   \n",
       "44790  aef3957c-3834-4f87-9f7f-bcfab8ea0649     NaN    144.0     NaN    Male   \n",
       "44791  6ef1357c-4174-4420-8af4-83b633bd277a     NaN    230.0     NaN    Male   \n",
       "44792  5f7c25ee-2e4f-45f7-9e81-84c91be28cc8     NaN      0.0     NaN  Female   \n",
       "44793  0ea311be-7830-4d2d-bb3e-0ec055698f1f     NaN    167.0     NaN    Male   \n",
       "44794  1d062596-e8e7-4a75-a1c0-a39e053c47b9     NaN    223.0     NaN    Male   \n",
       "44795  58972dcc-54d4-4b9f-96c8-da6c24dad91e     NaN    215.0     NaN    Male   \n",
       "44796  f2ce3938-5a24-4dc0-9991-ebee218bf506     NaN    198.0     NaN    Male   \n",
       "44797  31948491-672b-4fe0-884e-fa7161aae953     NaN    210.0     NaN    Male   \n",
       "44798  bd554b83-81af-4cae-89ca-4aa7362c037f     NaN    195.0     NaN    Male   \n",
       "44799  bf181501-f803-43cf-bbce-5bb19f29b380     NaN    203.0     NaN    Male   \n",
       "44800  5784f49f-33cf-415e-bf5f-667086604500     NaN    195.0     NaN    Male   \n",
       "44801  0108dedd-2159-434b-831f-ca68b8b2bff5     NaN    225.0     NaN    Male   \n",
       "44802  99141974-57ac-433c-91fc-19f451172b5f     NaN    184.0     NaN  Female   \n",
       "44803  76f64214-d201-4d2e-aa84-3c9eba629517     NaN    170.0     NaN    Male   \n",
       "\n",
       "       height  height2  currentAge  currentAge2  \n",
       "0        66.0      NaN        51.0          NaN  \n",
       "1        67.0      NaN        18.0          NaN  \n",
       "2        68.0      NaN        44.0          NaN  \n",
       "3        67.0      NaN        18.0          NaN  \n",
       "4        68.0      NaN        42.0          NaN  \n",
       "5        68.0      NaN        39.0          NaN  \n",
       "6        66.0      NaN        28.0          NaN  \n",
       "7        70.0      NaN        32.0          NaN  \n",
       "8        72.0      NaN        41.0          NaN  \n",
       "9        69.0      NaN        36.0          NaN  \n",
       "10       68.0      NaN        30.0          NaN  \n",
       "11       68.0      NaN        20.0          NaN  \n",
       "12       72.0      NaN        23.0          NaN  \n",
       "13       72.0      NaN        31.0          NaN  \n",
       "14       71.0      NaN        48.0          NaN  \n",
       "15       71.0      NaN        24.0          NaN  \n",
       "16       61.0      NaN        18.0          NaN  \n",
       "17       57.0      NaN        31.0          NaN  \n",
       "19       68.0      NaN        19.0          NaN  \n",
       "20       68.0      NaN        32.0          NaN  \n",
       "21       66.0      NaN        20.0          NaN  \n",
       "22       64.0      NaN        18.0          NaN  \n",
       "23       71.0      NaN        30.0          NaN  \n",
       "24       71.0      NaN        31.0          NaN  \n",
       "25       60.0      NaN        30.0          NaN  \n",
       "26       70.0      NaN        55.0          NaN  \n",
       "27       68.0      NaN        42.0          NaN  \n",
       "28       70.0      NaN        32.0          NaN  \n",
       "29       72.0      NaN        41.0          NaN  \n",
       "30       71.0      NaN        26.0          NaN  \n",
       "...       ...      ...         ...          ...  \n",
       "44774     NaN     73.0         NaN         23.0  \n",
       "44775     NaN     65.0         NaN         53.0  \n",
       "44776     NaN     71.0         NaN         26.0  \n",
       "44777     NaN     71.0         NaN         28.0  \n",
       "44778     NaN     73.0         NaN         36.0  \n",
       "44779     NaN      0.0         NaN         47.0  \n",
       "44780     NaN      0.0         NaN         47.0  \n",
       "44781     NaN      0.0         NaN         32.0  \n",
       "44782     NaN     63.0         NaN         63.0  \n",
       "44783     NaN     65.0         NaN         33.0  \n",
       "44784     NaN     72.0         NaN         37.0  \n",
       "44785     NaN     68.0         NaN         45.0  \n",
       "44786     NaN     65.0         NaN         53.0  \n",
       "44787     NaN     63.0         NaN         80.0  \n",
       "44788     NaN     61.0         NaN         25.0  \n",
       "44789     NaN     68.0         NaN         44.0  \n",
       "44790     NaN     65.0         NaN         47.0  \n",
       "44791     NaN     76.0         NaN         65.0  \n",
       "44792     NaN      0.0         NaN         74.0  \n",
       "44793     NaN     68.0         NaN         40.0  \n",
       "44794     NaN     73.0         NaN         70.0  \n",
       "44795     NaN     66.0         NaN         75.0  \n",
       "44796     NaN     71.0         NaN         56.0  \n",
       "44797     NaN     76.0         NaN         39.0  \n",
       "44798     NaN     71.0         NaN         30.0  \n",
       "44799     NaN     67.0         NaN         54.0  \n",
       "44800     NaN     68.0         NaN         45.0  \n",
       "44801     NaN     79.0         NaN         44.0  \n",
       "44802     NaN     66.0         NaN         29.0  \n",
       "44803     NaN     69.0         NaN         64.0  \n",
       "\n",
       "[34685 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "file = \"data/demographics.csv\"\n",
    "csv = pd.read_csv(file, low_memory=False)\n",
    "\n",
    "csv.drop(columns=['ROW_ID', 'ROW_VERSION', 'appVersion', 'phoneInfo', 'dataGroups', 'uploadDate', 'createdOn', \n",
    "                  'validationErrors', 'userSharingScope', 'NonIdentifiableDemographics.json.patientGoSleepTime', \n",
    "                  'NonIdentifiableDemographics.patientGoSleepTime', 'createdOnTimeZone',\n",
    "                 'NonIdentifiableDemographics.json.patientWakeUpTime', 'NonIdentifiableDemographics.patientWakeUpTime'\n",
    "                 , 'externalId'], \n",
    "         inplace=True)\n",
    "csv.rename(columns={'NonIdentifiableDemographics.json.patientWeightPounds': 'weight', 'NonIdentifiableDemographics.patientWeightPounds': 'weight2', \n",
    "                    'NonIdentifiableDemographics.json.patientBiologicalSex': 'sex', \n",
    "                    'NonIdentifiableDemographics.patientBiologicalSex': 'sex2',\n",
    "                   'NonIdentifiableDemographics.json.patientHeightInches': 'height',\n",
    "                   'NonIdentifiableDemographics.patientHeightInches': 'height2',\n",
    "                   'NonIdentifiableDemographics.json.patientCurrentAge': 'currentAge',\n",
    "                   'NonIdentifiableDemographics.patientCurrentAge': 'currentAge2'}, inplace=True)\n",
    "\n",
    "# drop the test version\n",
    "csv = csv.iloc[7:]\n",
    "csv.index = range(44804)\n",
    "\n",
    "csv.dropna(how='all', subset=['currentAge','currentAge2'], inplace=True)\n",
    "csv.dropna(how='all', subset=['weight', 'weight2'], inplace=True)\n",
    "csv.dropna(how='all', subset=['sex', 'sex2'], inplace=True)\n",
    "csv.dropna(how='all', subset=['height', 'height2'], inplace=True)\n",
    "\n",
    "csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "csv['currentAge'] = csv['currentAge'].fillna(csv['currentAge2'])\n",
    "csv['weight'] = csv['weight'].fillna(csv['weight2'])\n",
    "csv['height'] = csv['height'].fillna(csv['height2'])\n",
    "csv['sex'] = csv['sex'].fillna(csv['sex2'])\n",
    "csv = csv.drop('currentAge2',1)\n",
    "csv = csv.drop('weight2',1)\n",
    "csv = csv.drop('height2',1)\n",
    "csv = csv.drop('sex2',1)\n",
    "\n",
    "# Dropping the duplicate healthCode records... Don't know if this is the right thing to do but can easily be reversed\n",
    "csv = csv.drop_duplicates(subset='healthCode', keep='last', inplace=False)\n",
    "\n",
    "# Dropping the rows with 0 for any metric. This was not caught with the NaN cleaning/merging \n",
    "csv = csv[csv.currentAge != 0]\n",
    "csv = csv[csv.weight != 0]\n",
    "csv = csv[csv.height != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "\n",
    "directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwt/accel_walk_dir'\n",
    "directory = os.fsencode(directory_in_str)\n",
    "\n",
    "final_directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwtwindows'\n",
    "final_directory = os.fsencode(final_directory_in_str)\n",
    "\n",
    "# Set overlap to the amount you want the sliding windows to have in common \n",
    "# Example: If your sliding windows are of length 200 ms (2 seconds), make the overlap 99 for half of the window to overlap \n",
    "def moving_window(accelx, length, overlap, step=1):\n",
    "    streams = it.tee(accelx, length)\n",
    "    return zip(*[it.islice(stream, i, None, step + overlap) for stream, i in zip(streams, it.count(step=step))])\n",
    "\n",
    "def normalize_dataset(dataframe):\n",
    "    return (dataframe - dataframe.mean())\n",
    "\n",
    "# Just get from the 173 valid files we have \n",
    "def create_dataframes(num_of_ms, overlap, fn):\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        # You can choose to get the non mean normalized version by not calling the normalize_dataset function\n",
    "        a_df = normalize_dataset(pd.read_json(fn).set_index('timestamp'))\n",
    "        x = np.asarray(a_df.x)\n",
    "        y = np.asarray(a_df.y)\n",
    "        z = np.asarray(a_df.z)\n",
    "        x_ = list(moving_window(x, num_of_ms, overlap))\n",
    "        y_ = list(moving_window(y, num_of_ms, overlap))\n",
    "        z_ = list(moving_window(z, num_of_ms, overlap))\n",
    "        df = pd.DataFrame({'healthCode': subdir.decode()[subdir.decode().rfind('/')+1:], \n",
    "        'xwindows': x_, 'ywindows': y_, 'zwindows': z_}, columns=['healthCode', 'xwindows', \n",
    "        'ywindows', 'zwindows']).setIndex('healthCode')\n",
    "\n",
    "        if not os.path(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + str(num_of_ms) + str(overlap)):\n",
    "            os.makedirs(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + str(num_of_ms) + str(overlap))\n",
    "        df.to_hdf(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + str(num_of_ms) + str(overlap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-21bc02e969de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m             )\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'frame'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 853\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             decoded = {str(k): v for k, v in compat.iteritems(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools as it\n",
    "\n",
    "directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwt/accel_walk_dir'\n",
    "directory = os.fsencode(directory_in_str)\n",
    "\n",
    "def moving_window(accelx, length, overlap, step=1):\n",
    "    streams = it.tee(accelx, length)\n",
    "    return zip(*[it.islice(stream, i, None, step + overlap) for stream, i in zip(streams, it.count(step=step))])\n",
    "\n",
    "def normalize_dataset(dataframe):\n",
    "    return (dataframe - dataframe.mean())\n",
    "\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        test_df = normalize_dataset(pd.read_json(os.path.join(subdir.decode(), file.decode())).set_index('timestamp'))\n",
    "        x = np.asarray(test_df.x)\n",
    "        y = np.asarray(test_df.y)\n",
    "        z = np.asarray(test_df.z)\n",
    "        x_ = list(moving_window(x, 200, 99))\n",
    "        y_ = list(moving_window(y, 200, 99))\n",
    "        z_ = list(moving_window(z, 200, 99))\n",
    "\n",
    "        df = pd.DataFrame({'healthCode': subdir.decode()[subdir.decode().rfind('/')+1:], \n",
    "                'xwindows': x_, 'ywindows': y_, 'zwindows': z_}, columns=['healthCode', 'xwindows', \n",
    "                'ywindows', 'zwindows']).set_index('healthCode')\n",
    "        df.head()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_df = normalize_dataset(pd.read_json('data/test_accel_old.json')).set_index('timestamp')\n",
    "x = np.asarray(test_df.x)\n",
    "y = np.asarray(test_df.y)\n",
    "z = np.asarray(test_df.z)\n",
    "x_ = list(moving_window(x, 200, 99))\n",
    "y_ = list(moving_window(y, 200, 99))\n",
    "z_ = list(moving_window(z, 200, 99))\n",
    "\n",
    "df = pd.DataFrame({'healthCode': 'hello', \n",
    "            'xwindows': x_, 'ywindows': y_, 'zwindows': z_}, columns=['healthCode', 'xwindows', \n",
    "            'ywindows', 'zwindows']).set_index('healthCode')\n",
    "df.to_hdf('data/df.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing for generate_windows\n",
    "import sys, os, errno\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "\n",
    "directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwt/accel_walk_dir'\n",
    "directory = os.fsencode(directory_in_str)\n",
    "\n",
    "final_directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwtwindows'\n",
    "final_directory = os.fsencode(final_directory_in_str)\n",
    "\n",
    "# Set overlap to the amount you want the sliding windows to have in common \n",
    "# Example: If your sliding windows are of length 200 ms (2 seconds), make the overlap 99 for half of the window to overlap \n",
    "def moving_window(accelx, length, overlap, step=1):\n",
    "    streams = it.tee(accelx, length)\n",
    "    return zip(*[it.islice(stream, i, None, step + overlap) for stream, i in zip(streams, it.count(step=step))])\n",
    "\n",
    "def normalize_dataset(dataframe):\n",
    "    return (dataframe - dataframe.mean())\n",
    "\n",
    "def create_dataframes(num_of_ms, overlap):\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        i = 0\n",
    "        for file in files:\n",
    "            while (i < 1):\n",
    "                # You can choose to get the non mean normalized version by not calling the normalize_dataset function\n",
    "                a_df = normalize_dataset(pd.read_json(os.path.join(subdir.decode(), file.decode())).set_index('timestamp'))\n",
    "                x = np.asarray(a_df.x)\n",
    "                y = np.asarray(a_df.y)\n",
    "                z = np.asarray(a_df.z)\n",
    "                x_ = list(moving_window(x, num_of_ms, overlap))\n",
    "                y_ = list(moving_window(y, num_of_ms, overlap))\n",
    "                z_ = list(moving_window(z, num_of_ms, overlap))\n",
    "                df = pd.DataFrame({'healthCode': subdir.decode()[subdir.decode().rfind('/')+1:], \n",
    "                'xwindows': x_, 'ywindows': y_, 'zwindows': z_}, columns=['healthCode', 'xwindows', \n",
    "                'ywindows', 'zwindows']).set_index('healthCode')\n",
    "\n",
    "                \n",
    "                if not os.path.exists(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + '/' + str(num_of_ms) + '/' + str(overlap)):\n",
    "                    os.makedirs(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + '/' + str(num_of_ms) + '/' + str(overlap))\n",
    "                df.to_hdf(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + '/' + str(num_of_ms) + '/' + str(overlap) + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + str(num_of_ms) + str(overlap) +'.h5', key='df', mode='w')\n",
    "                i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-fc5e95da1c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_dataframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-124-06ad376af2d5>\u001b[0m in \u001b[0;36mcreate_dataframes\u001b[0;34m(num_of_ms, overlap)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;31m# You can choose to get the non mean normalized version by not calling the normalize_dataset function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0ma_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_unit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     )\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_from_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \"\"\"\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/software/user/open/python/3.6.1/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "create_dataframes(200, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OLD DATA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "newtotal_df  = pd.read_hdf('newtotal_df.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Very important to run for any number of samples as it makes the feature frame uniform\n",
    "def find_lowest_num_samples(total_df):\n",
    "    '''\n",
    "    This function finds the minimum number of samples from all of the runs present so that we keep same dimensions\n",
    "    for every run that we have\n",
    "    '''\n",
    "    total = [len(total_df.loc[x].average_accel) for x in list(set(total_df.index))]\n",
    "    return min(total)\n",
    "\n",
    "def min_df(lowest_num_of_samples, total_df):\n",
    "    '''\n",
    "    Returns the dataframe with features for every healthCode present so that there are only the minimum amount of \n",
    "    samples needed\n",
    "    '''\n",
    "    newdf = pd.DataFrame()\n",
    "    unique_healthcodes = list(set(total_df.index))\n",
    "    for elem in unique_healthcodes:\n",
    "        newdf = newdf.append(total_df.loc[elem].iloc[:lowest_num_of_samples])\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newtotal_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-c8e7a0030629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meverything\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_lowest_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewtotal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewtotal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'newtotal_df' is not defined"
     ]
    }
   ],
   "source": [
    "everything = min_df(find_lowest_num_samples(newtotal_df), newtotal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "everything = everything[everything.weight < 400]\n",
    "everything = everything[everything.weight > 80]\n",
    "\n",
    "# this dataframe doesn't have demographic data\n",
    "everything_no_demog = everything.drop(columns=['sex', 'currentAge', 'weight', 'height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>currentAge</th>\n",
       "      <th>fundamental_freq</th>\n",
       "      <th>average_accel</th>\n",
       "      <th>peakcount</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mut_x</th>\n",
       "      <th>...</th>\n",
       "      <th>medf_y</th>\n",
       "      <th>medf_z</th>\n",
       "      <th>cross_xz</th>\n",
       "      <th>cross_yz</th>\n",
       "      <th>spect_cent_x</th>\n",
       "      <th>spect_cent_y</th>\n",
       "      <th>spect_cent_z</th>\n",
       "      <th>average_dist_meanx</th>\n",
       "      <th>average_dist_meany</th>\n",
       "      <th>average_dist_meanz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>108.314444</td>\n",
       "      <td>1.361654</td>\n",
       "      <td>12</td>\n",
       "      <td>2.064969</td>\n",
       "      <td>-0.330143</td>\n",
       "      <td>0.690610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815326</td>\n",
       "      <td>0.261730</td>\n",
       "      <td>-1.108732</td>\n",
       "      <td>1.423415</td>\n",
       "      <td>0.303866</td>\n",
       "      <td>0.484718</td>\n",
       "      <td>0.891400</td>\n",
       "      <td>0.240233</td>\n",
       "      <td>0.241233</td>\n",
       "      <td>0.312021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>95.117992</td>\n",
       "      <td>1.399965</td>\n",
       "      <td>13</td>\n",
       "      <td>2.064969</td>\n",
       "      <td>-0.330143</td>\n",
       "      <td>0.802499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.900119</td>\n",
       "      <td>0.383518</td>\n",
       "      <td>-1.424095</td>\n",
       "      <td>1.614554</td>\n",
       "      <td>0.055270</td>\n",
       "      <td>0.206965</td>\n",
       "      <td>0.505872</td>\n",
       "      <td>0.215864</td>\n",
       "      <td>0.247436</td>\n",
       "      <td>0.306005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>93.161575</td>\n",
       "      <td>1.300919</td>\n",
       "      <td>12</td>\n",
       "      <td>1.786842</td>\n",
       "      <td>-0.142095</td>\n",
       "      <td>0.615637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781222</td>\n",
       "      <td>0.208414</td>\n",
       "      <td>-0.773675</td>\n",
       "      <td>0.980318</td>\n",
       "      <td>0.896903</td>\n",
       "      <td>0.608516</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.192852</td>\n",
       "      <td>0.216332</td>\n",
       "      <td>0.278009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>100.162152</td>\n",
       "      <td>1.274289</td>\n",
       "      <td>10</td>\n",
       "      <td>1.683957</td>\n",
       "      <td>-0.142095</td>\n",
       "      <td>0.531247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779094</td>\n",
       "      <td>0.077215</td>\n",
       "      <td>-0.622452</td>\n",
       "      <td>0.878936</td>\n",
       "      <td>0.177303</td>\n",
       "      <td>0.664331</td>\n",
       "      <td>1.269846</td>\n",
       "      <td>0.169978</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.262656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>108.066819</td>\n",
       "      <td>1.299515</td>\n",
       "      <td>10</td>\n",
       "      <td>1.729218</td>\n",
       "      <td>-0.205279</td>\n",
       "      <td>0.581625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737040</td>\n",
       "      <td>0.084270</td>\n",
       "      <td>-0.669505</td>\n",
       "      <td>0.852864</td>\n",
       "      <td>0.319803</td>\n",
       "      <td>0.922528</td>\n",
       "      <td>1.160783</td>\n",
       "      <td>0.156258</td>\n",
       "      <td>0.195590</td>\n",
       "      <td>0.256213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      weight  height     sex  currentAge  \\\n",
       "healthCode                                                                 \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   247.0    62.0  Female        61.0   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   247.0    62.0  Female        61.0   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   247.0    62.0  Female        61.0   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   247.0    62.0  Female        61.0   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   247.0    62.0  Female        61.0   \n",
       "\n",
       "                                      fundamental_freq  average_accel  \\\n",
       "healthCode                                                              \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        108.314444       1.361654   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         95.117992       1.399965   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         93.161575       1.300919   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        100.162152       1.274289   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        108.066819       1.299515   \n",
       "\n",
       "                                      peakcount       max       min     mut_x  \\\n",
       "healthCode                                                                      \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  2.064969 -0.330143  0.690610   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         13  2.064969 -0.330143  0.802499   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  1.786842 -0.142095  0.615637   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.683957 -0.142095  0.531247   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.729218 -0.205279  0.581625   \n",
       "\n",
       "                                             ...            medf_y    medf_z  \\\n",
       "healthCode                                   ...                               \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.815326  0.261730   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.900119  0.383518   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.781222  0.208414   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.779094  0.077215   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.737040  0.084270   \n",
       "\n",
       "                                      cross_xz  cross_yz  spect_cent_x  \\\n",
       "healthCode                                                               \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -1.108732  1.423415      0.303866   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -1.424095  1.614554      0.055270   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.773675  0.980318      0.896903   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.622452  0.878936      0.177303   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.669505  0.852864      0.319803   \n",
       "\n",
       "                                      spect_cent_y  spect_cent_z  \\\n",
       "healthCode                                                         \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.484718      0.891400   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.206965      0.505872   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.608516      0.523008   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.664331      1.269846   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.922528      1.160783   \n",
       "\n",
       "                                      average_dist_meanx  average_dist_meany  \\\n",
       "healthCode                                                                     \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.240233            0.241233   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.215864            0.247436   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.192852            0.216332   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.169978            0.200500   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.156258            0.195590   \n",
       "\n",
       "                                      average_dist_meanz  \n",
       "healthCode                                                \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.312021  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.306005  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.278009  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.262656  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.256213  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fundamental_freq</th>\n",
       "      <th>average_accel</th>\n",
       "      <th>peakcount</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mut_x</th>\n",
       "      <th>mut_y</th>\n",
       "      <th>mut_z</th>\n",
       "      <th>muf_x</th>\n",
       "      <th>muf_y</th>\n",
       "      <th>...</th>\n",
       "      <th>medf_y</th>\n",
       "      <th>medf_z</th>\n",
       "      <th>cross_xz</th>\n",
       "      <th>cross_yz</th>\n",
       "      <th>spect_cent_x</th>\n",
       "      <th>spect_cent_y</th>\n",
       "      <th>spect_cent_z</th>\n",
       "      <th>average_dist_meanx</th>\n",
       "      <th>average_dist_meany</th>\n",
       "      <th>average_dist_meanz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>108.314444</td>\n",
       "      <td>1.361654</td>\n",
       "      <td>12</td>\n",
       "      <td>2.064969</td>\n",
       "      <td>-0.330143</td>\n",
       "      <td>0.690610</td>\n",
       "      <td>-0.886621</td>\n",
       "      <td>-0.622883</td>\n",
       "      <td>2.408580</td>\n",
       "      <td>2.420899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815326</td>\n",
       "      <td>0.261730</td>\n",
       "      <td>-1.108732</td>\n",
       "      <td>1.423415</td>\n",
       "      <td>0.303866</td>\n",
       "      <td>0.484718</td>\n",
       "      <td>0.891400</td>\n",
       "      <td>0.240233</td>\n",
       "      <td>0.241233</td>\n",
       "      <td>0.312021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>95.117992</td>\n",
       "      <td>1.399965</td>\n",
       "      <td>13</td>\n",
       "      <td>2.064969</td>\n",
       "      <td>-0.330143</td>\n",
       "      <td>0.802499</td>\n",
       "      <td>-0.909826</td>\n",
       "      <td>-0.563515</td>\n",
       "      <td>2.063195</td>\n",
       "      <td>2.432729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.900119</td>\n",
       "      <td>0.383518</td>\n",
       "      <td>-1.424095</td>\n",
       "      <td>1.614554</td>\n",
       "      <td>0.055270</td>\n",
       "      <td>0.206965</td>\n",
       "      <td>0.505872</td>\n",
       "      <td>0.215864</td>\n",
       "      <td>0.247436</td>\n",
       "      <td>0.306005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>93.161575</td>\n",
       "      <td>1.300919</td>\n",
       "      <td>12</td>\n",
       "      <td>1.786842</td>\n",
       "      <td>-0.142095</td>\n",
       "      <td>0.615637</td>\n",
       "      <td>-0.780069</td>\n",
       "      <td>-0.795731</td>\n",
       "      <td>1.537021</td>\n",
       "      <td>1.699596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781222</td>\n",
       "      <td>0.208414</td>\n",
       "      <td>-0.773675</td>\n",
       "      <td>0.980318</td>\n",
       "      <td>0.896903</td>\n",
       "      <td>0.608516</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.192852</td>\n",
       "      <td>0.216332</td>\n",
       "      <td>0.278009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>100.162152</td>\n",
       "      <td>1.274289</td>\n",
       "      <td>10</td>\n",
       "      <td>1.683957</td>\n",
       "      <td>-0.142095</td>\n",
       "      <td>0.531247</td>\n",
       "      <td>-0.750150</td>\n",
       "      <td>-0.853475</td>\n",
       "      <td>1.151398</td>\n",
       "      <td>1.632215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779094</td>\n",
       "      <td>0.077215</td>\n",
       "      <td>-0.622452</td>\n",
       "      <td>0.878936</td>\n",
       "      <td>0.177303</td>\n",
       "      <td>0.664331</td>\n",
       "      <td>1.269846</td>\n",
       "      <td>0.169978</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.262656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>108.066819</td>\n",
       "      <td>1.299515</td>\n",
       "      <td>10</td>\n",
       "      <td>1.729218</td>\n",
       "      <td>-0.205279</td>\n",
       "      <td>0.581625</td>\n",
       "      <td>-0.740917</td>\n",
       "      <td>-0.868740</td>\n",
       "      <td>1.131018</td>\n",
       "      <td>1.579905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737040</td>\n",
       "      <td>0.084270</td>\n",
       "      <td>-0.669505</td>\n",
       "      <td>0.852864</td>\n",
       "      <td>0.319803</td>\n",
       "      <td>0.922528</td>\n",
       "      <td>1.160783</td>\n",
       "      <td>0.156258</td>\n",
       "      <td>0.195590</td>\n",
       "      <td>0.256213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>109.731461</td>\n",
       "      <td>1.307171</td>\n",
       "      <td>8</td>\n",
       "      <td>1.862491</td>\n",
       "      <td>-0.205279</td>\n",
       "      <td>0.613979</td>\n",
       "      <td>-0.713431</td>\n",
       "      <td>-0.877655</td>\n",
       "      <td>1.197633</td>\n",
       "      <td>1.555487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714885</td>\n",
       "      <td>0.182796</td>\n",
       "      <td>-0.699567</td>\n",
       "      <td>0.812884</td>\n",
       "      <td>0.374420</td>\n",
       "      <td>0.966315</td>\n",
       "      <td>1.395159</td>\n",
       "      <td>0.147237</td>\n",
       "      <td>0.194389</td>\n",
       "      <td>0.253153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>107.141324</td>\n",
       "      <td>1.307852</td>\n",
       "      <td>10</td>\n",
       "      <td>1.862491</td>\n",
       "      <td>-0.117244</td>\n",
       "      <td>0.620030</td>\n",
       "      <td>-0.699920</td>\n",
       "      <td>-0.883751</td>\n",
       "      <td>1.157659</td>\n",
       "      <td>1.531361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.726893</td>\n",
       "      <td>0.146422</td>\n",
       "      <td>-0.701589</td>\n",
       "      <td>0.791987</td>\n",
       "      <td>0.341018</td>\n",
       "      <td>0.678090</td>\n",
       "      <td>1.303551</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.190995</td>\n",
       "      <td>0.248046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>103.723405</td>\n",
       "      <td>1.313845</td>\n",
       "      <td>9</td>\n",
       "      <td>1.831361</td>\n",
       "      <td>-0.116085</td>\n",
       "      <td>0.668747</td>\n",
       "      <td>-0.721150</td>\n",
       "      <td>-0.849102</td>\n",
       "      <td>1.293646</td>\n",
       "      <td>1.541653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.706561</td>\n",
       "      <td>0.157716</td>\n",
       "      <td>-0.787594</td>\n",
       "      <td>0.849309</td>\n",
       "      <td>0.539139</td>\n",
       "      <td>0.792449</td>\n",
       "      <td>0.934569</td>\n",
       "      <td>0.135015</td>\n",
       "      <td>0.185874</td>\n",
       "      <td>0.242997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>95.706105</td>\n",
       "      <td>1.338492</td>\n",
       "      <td>9</td>\n",
       "      <td>1.831361</td>\n",
       "      <td>-0.116085</td>\n",
       "      <td>0.723892</td>\n",
       "      <td>-0.692789</td>\n",
       "      <td>-0.866560</td>\n",
       "      <td>1.400238</td>\n",
       "      <td>1.525359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.656978</td>\n",
       "      <td>0.252391</td>\n",
       "      <td>-0.835363</td>\n",
       "      <td>0.799470</td>\n",
       "      <td>0.356895</td>\n",
       "      <td>0.415980</td>\n",
       "      <td>1.094721</td>\n",
       "      <td>0.131864</td>\n",
       "      <td>0.181516</td>\n",
       "      <td>0.239425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>98.245296</td>\n",
       "      <td>1.360542</td>\n",
       "      <td>14</td>\n",
       "      <td>1.714565</td>\n",
       "      <td>-0.149190</td>\n",
       "      <td>0.713559</td>\n",
       "      <td>-0.650981</td>\n",
       "      <td>-0.937036</td>\n",
       "      <td>1.326184</td>\n",
       "      <td>1.586319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.657954</td>\n",
       "      <td>0.146233</td>\n",
       "      <td>-0.761506</td>\n",
       "      <td>0.694724</td>\n",
       "      <td>0.687310</td>\n",
       "      <td>0.729889</td>\n",
       "      <td>0.550284</td>\n",
       "      <td>0.129255</td>\n",
       "      <td>0.177092</td>\n",
       "      <td>0.233075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>100.527171</td>\n",
       "      <td>1.387331</td>\n",
       "      <td>11</td>\n",
       "      <td>1.771999</td>\n",
       "      <td>-0.149190</td>\n",
       "      <td>0.786215</td>\n",
       "      <td>-0.669889</td>\n",
       "      <td>-0.902668</td>\n",
       "      <td>1.717213</td>\n",
       "      <td>1.514250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.682765</td>\n",
       "      <td>0.092975</td>\n",
       "      <td>-0.870989</td>\n",
       "      <td>0.742121</td>\n",
       "      <td>0.374878</td>\n",
       "      <td>0.304298</td>\n",
       "      <td>0.444606</td>\n",
       "      <td>0.129458</td>\n",
       "      <td>0.175094</td>\n",
       "      <td>0.225587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>94.902995</td>\n",
       "      <td>1.391027</td>\n",
       "      <td>7</td>\n",
       "      <td>1.821847</td>\n",
       "      <td>-0.009313</td>\n",
       "      <td>0.828527</td>\n",
       "      <td>-0.741714</td>\n",
       "      <td>-0.807926</td>\n",
       "      <td>1.523948</td>\n",
       "      <td>1.723703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.758441</td>\n",
       "      <td>0.392156</td>\n",
       "      <td>-1.025497</td>\n",
       "      <td>0.918047</td>\n",
       "      <td>0.573125</td>\n",
       "      <td>0.193399</td>\n",
       "      <td>0.262078</td>\n",
       "      <td>0.128364</td>\n",
       "      <td>0.174815</td>\n",
       "      <td>0.222414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>102.487545</td>\n",
       "      <td>1.359509</td>\n",
       "      <td>7</td>\n",
       "      <td>1.821847</td>\n",
       "      <td>-0.078247</td>\n",
       "      <td>0.770966</td>\n",
       "      <td>-0.754207</td>\n",
       "      <td>-0.795563</td>\n",
       "      <td>1.353717</td>\n",
       "      <td>1.694970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756640</td>\n",
       "      <td>0.121150</td>\n",
       "      <td>-0.969083</td>\n",
       "      <td>0.948017</td>\n",
       "      <td>0.878901</td>\n",
       "      <td>0.192182</td>\n",
       "      <td>0.622840</td>\n",
       "      <td>0.126270</td>\n",
       "      <td>0.173775</td>\n",
       "      <td>0.221624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>108.900845</td>\n",
       "      <td>1.344979</td>\n",
       "      <td>6</td>\n",
       "      <td>1.857509</td>\n",
       "      <td>-0.078247</td>\n",
       "      <td>0.760305</td>\n",
       "      <td>-0.730384</td>\n",
       "      <td>-0.807791</td>\n",
       "      <td>1.357898</td>\n",
       "      <td>1.616392</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.719767</td>\n",
       "      <td>0.081930</td>\n",
       "      <td>-0.941214</td>\n",
       "      <td>0.904174</td>\n",
       "      <td>0.712077</td>\n",
       "      <td>0.538247</td>\n",
       "      <td>1.142288</td>\n",
       "      <td>0.125267</td>\n",
       "      <td>0.172130</td>\n",
       "      <td>0.219561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>109.154748</td>\n",
       "      <td>1.342602</td>\n",
       "      <td>10</td>\n",
       "      <td>1.857509</td>\n",
       "      <td>-0.131206</td>\n",
       "      <td>0.752882</td>\n",
       "      <td>-0.746872</td>\n",
       "      <td>-0.798955</td>\n",
       "      <td>1.546340</td>\n",
       "      <td>1.520144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.730288</td>\n",
       "      <td>0.074852</td>\n",
       "      <td>-0.942334</td>\n",
       "      <td>0.934811</td>\n",
       "      <td>0.825119</td>\n",
       "      <td>0.678696</td>\n",
       "      <td>0.906691</td>\n",
       "      <td>0.124248</td>\n",
       "      <td>0.171290</td>\n",
       "      <td>0.217375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>102.646973</td>\n",
       "      <td>1.344636</td>\n",
       "      <td>9</td>\n",
       "      <td>1.802260</td>\n",
       "      <td>-0.131206</td>\n",
       "      <td>0.740430</td>\n",
       "      <td>-0.758812</td>\n",
       "      <td>-0.802888</td>\n",
       "      <td>1.460257</td>\n",
       "      <td>1.555709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755519</td>\n",
       "      <td>0.364381</td>\n",
       "      <td>-0.922208</td>\n",
       "      <td>0.945103</td>\n",
       "      <td>0.749242</td>\n",
       "      <td>0.915445</td>\n",
       "      <td>1.258717</td>\n",
       "      <td>0.123298</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.216757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>94.047589</td>\n",
       "      <td>1.362276</td>\n",
       "      <td>9</td>\n",
       "      <td>1.775034</td>\n",
       "      <td>-0.130712</td>\n",
       "      <td>0.756105</td>\n",
       "      <td>-0.756897</td>\n",
       "      <td>-0.813937</td>\n",
       "      <td>1.394568</td>\n",
       "      <td>1.573560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.757823</td>\n",
       "      <td>0.241106</td>\n",
       "      <td>-0.928949</td>\n",
       "      <td>0.929922</td>\n",
       "      <td>0.398179</td>\n",
       "      <td>0.755275</td>\n",
       "      <td>1.117008</td>\n",
       "      <td>0.122566</td>\n",
       "      <td>0.170022</td>\n",
       "      <td>0.217175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>95.770697</td>\n",
       "      <td>1.379599</td>\n",
       "      <td>12</td>\n",
       "      <td>1.771262</td>\n",
       "      <td>-0.208031</td>\n",
       "      <td>0.776573</td>\n",
       "      <td>-0.759795</td>\n",
       "      <td>-0.813358</td>\n",
       "      <td>1.329132</td>\n",
       "      <td>1.761010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.787883</td>\n",
       "      <td>0.069861</td>\n",
       "      <td>-0.954774</td>\n",
       "      <td>0.934146</td>\n",
       "      <td>0.493444</td>\n",
       "      <td>0.931416</td>\n",
       "      <td>0.519440</td>\n",
       "      <td>0.120759</td>\n",
       "      <td>0.169525</td>\n",
       "      <td>0.218042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>99.687678</td>\n",
       "      <td>1.387466</td>\n",
       "      <td>13</td>\n",
       "      <td>1.825576</td>\n",
       "      <td>-0.208031</td>\n",
       "      <td>0.778579</td>\n",
       "      <td>-0.750619</td>\n",
       "      <td>-0.826945</td>\n",
       "      <td>1.428243</td>\n",
       "      <td>1.872350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761371</td>\n",
       "      <td>0.078687</td>\n",
       "      <td>-0.941513</td>\n",
       "      <td>0.907701</td>\n",
       "      <td>0.446762</td>\n",
       "      <td>0.695264</td>\n",
       "      <td>0.405988</td>\n",
       "      <td>0.119078</td>\n",
       "      <td>0.168535</td>\n",
       "      <td>0.219156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>98.898877</td>\n",
       "      <td>1.394423</td>\n",
       "      <td>9</td>\n",
       "      <td>1.860749</td>\n",
       "      <td>-0.102235</td>\n",
       "      <td>0.781270</td>\n",
       "      <td>-0.729907</td>\n",
       "      <td>-0.853349</td>\n",
       "      <td>1.403245</td>\n",
       "      <td>1.710714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.742465</td>\n",
       "      <td>0.162758</td>\n",
       "      <td>-0.915533</td>\n",
       "      <td>0.855344</td>\n",
       "      <td>0.597968</td>\n",
       "      <td>0.415603</td>\n",
       "      <td>0.624520</td>\n",
       "      <td>0.118110</td>\n",
       "      <td>0.167335</td>\n",
       "      <td>0.220526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>96.307548</td>\n",
       "      <td>1.378818</td>\n",
       "      <td>6</td>\n",
       "      <td>1.860749</td>\n",
       "      <td>-0.057689</td>\n",
       "      <td>0.787840</td>\n",
       "      <td>-0.747305</td>\n",
       "      <td>-0.814065</td>\n",
       "      <td>1.585836</td>\n",
       "      <td>1.891071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755465</td>\n",
       "      <td>0.336637</td>\n",
       "      <td>-0.967785</td>\n",
       "      <td>0.917991</td>\n",
       "      <td>0.274690</td>\n",
       "      <td>0.081796</td>\n",
       "      <td>0.347779</td>\n",
       "      <td>0.117879</td>\n",
       "      <td>0.166682</td>\n",
       "      <td>0.220755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>96.702952</td>\n",
       "      <td>1.349875</td>\n",
       "      <td>6</td>\n",
       "      <td>1.828100</td>\n",
       "      <td>-0.029004</td>\n",
       "      <td>0.764451</td>\n",
       "      <td>-0.767287</td>\n",
       "      <td>-0.782714</td>\n",
       "      <td>1.464625</td>\n",
       "      <td>1.787889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.740771</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>-0.976667</td>\n",
       "      <td>0.980291</td>\n",
       "      <td>0.393992</td>\n",
       "      <td>0.102864</td>\n",
       "      <td>0.831110</td>\n",
       "      <td>0.118133</td>\n",
       "      <td>0.166568</td>\n",
       "      <td>0.219411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>109.502374</td>\n",
       "      <td>1.355172</td>\n",
       "      <td>7</td>\n",
       "      <td>1.854060</td>\n",
       "      <td>-0.051702</td>\n",
       "      <td>0.753059</td>\n",
       "      <td>-0.749572</td>\n",
       "      <td>-0.814916</td>\n",
       "      <td>1.405809</td>\n",
       "      <td>1.519122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692027</td>\n",
       "      <td>0.228329</td>\n",
       "      <td>-0.924094</td>\n",
       "      <td>0.919815</td>\n",
       "      <td>0.875586</td>\n",
       "      <td>0.621358</td>\n",
       "      <td>1.191681</td>\n",
       "      <td>0.117878</td>\n",
       "      <td>0.166404</td>\n",
       "      <td>0.220085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>116.394760</td>\n",
       "      <td>1.380513</td>\n",
       "      <td>8</td>\n",
       "      <td>1.854060</td>\n",
       "      <td>-0.051702</td>\n",
       "      <td>0.816185</td>\n",
       "      <td>-0.776699</td>\n",
       "      <td>-0.721390</td>\n",
       "      <td>1.881259</td>\n",
       "      <td>1.738262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781398</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>-1.131406</td>\n",
       "      <td>1.076670</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.786356</td>\n",
       "      <td>1.240218</td>\n",
       "      <td>0.119135</td>\n",
       "      <td>0.166836</td>\n",
       "      <td>0.223415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>109.615936</td>\n",
       "      <td>1.510821</td>\n",
       "      <td>12</td>\n",
       "      <td>2.360111</td>\n",
       "      <td>-0.102887</td>\n",
       "      <td>1.124904</td>\n",
       "      <td>-0.621356</td>\n",
       "      <td>-0.352783</td>\n",
       "      <td>3.616662</td>\n",
       "      <td>2.766881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.730265</td>\n",
       "      <td>0.760603</td>\n",
       "      <td>-3.188658</td>\n",
       "      <td>1.761300</td>\n",
       "      <td>0.877253</td>\n",
       "      <td>0.789743</td>\n",
       "      <td>0.669656</td>\n",
       "      <td>0.130391</td>\n",
       "      <td>0.174915</td>\n",
       "      <td>0.228530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>107.197481</td>\n",
       "      <td>1.521793</td>\n",
       "      <td>18</td>\n",
       "      <td>2.542108</td>\n",
       "      <td>-0.278029</td>\n",
       "      <td>1.305427</td>\n",
       "      <td>-0.007060</td>\n",
       "      <td>-0.205313</td>\n",
       "      <td>3.929681</td>\n",
       "      <td>3.263623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.599603</td>\n",
       "      <td>-6.358237</td>\n",
       "      <td>0.034385</td>\n",
       "      <td>1.398453</td>\n",
       "      <td>1.141195</td>\n",
       "      <td>0.276229</td>\n",
       "      <td>0.140732</td>\n",
       "      <td>0.186457</td>\n",
       "      <td>0.231050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>97.611163</td>\n",
       "      <td>1.337596</td>\n",
       "      <td>18</td>\n",
       "      <td>2.787768</td>\n",
       "      <td>-0.367846</td>\n",
       "      <td>1.085107</td>\n",
       "      <td>0.493045</td>\n",
       "      <td>-0.272621</td>\n",
       "      <td>4.004222</td>\n",
       "      <td>3.797662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416234</td>\n",
       "      <td>1.163063</td>\n",
       "      <td>-3.980283</td>\n",
       "      <td>-1.808539</td>\n",
       "      <td>2.427015</td>\n",
       "      <td>0.693736</td>\n",
       "      <td>0.076705</td>\n",
       "      <td>0.147303</td>\n",
       "      <td>0.189583</td>\n",
       "      <td>0.231789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>84.728459</td>\n",
       "      <td>1.137462</td>\n",
       "      <td>16</td>\n",
       "      <td>2.787768</td>\n",
       "      <td>-0.805225</td>\n",
       "      <td>0.682007</td>\n",
       "      <td>0.689005</td>\n",
       "      <td>-0.306396</td>\n",
       "      <td>2.982157</td>\n",
       "      <td>3.858923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645383</td>\n",
       "      <td>1.260064</td>\n",
       "      <td>-2.225903</td>\n",
       "      <td>-2.248741</td>\n",
       "      <td>1.381585</td>\n",
       "      <td>0.481171</td>\n",
       "      <td>0.062616</td>\n",
       "      <td>0.154285</td>\n",
       "      <td>0.193580</td>\n",
       "      <td>0.230438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>74.483441</td>\n",
       "      <td>0.948787</td>\n",
       "      <td>12</td>\n",
       "      <td>1.710222</td>\n",
       "      <td>-1.275452</td>\n",
       "      <td>0.269216</td>\n",
       "      <td>0.738074</td>\n",
       "      <td>-0.372125</td>\n",
       "      <td>1.953287</td>\n",
       "      <td>2.489452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700643</td>\n",
       "      <td>0.612980</td>\n",
       "      <td>-0.723455</td>\n",
       "      <td>-1.983402</td>\n",
       "      <td>0.348549</td>\n",
       "      <td>0.496770</td>\n",
       "      <td>0.170647</td>\n",
       "      <td>0.156555</td>\n",
       "      <td>0.195372</td>\n",
       "      <td>0.231140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>59.160786</td>\n",
       "      <td>0.774666</td>\n",
       "      <td>9</td>\n",
       "      <td>1.710222</td>\n",
       "      <td>-2.584695</td>\n",
       "      <td>-0.087773</td>\n",
       "      <td>0.564067</td>\n",
       "      <td>-0.340849</td>\n",
       "      <td>1.892667</td>\n",
       "      <td>2.283208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526914</td>\n",
       "      <td>0.245872</td>\n",
       "      <td>0.257513</td>\n",
       "      <td>-1.654890</td>\n",
       "      <td>0.198529</td>\n",
       "      <td>0.454449</td>\n",
       "      <td>0.040465</td>\n",
       "      <td>0.161543</td>\n",
       "      <td>0.197066</td>\n",
       "      <td>0.231756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>54.670532</td>\n",
       "      <td>0.575156</td>\n",
       "      <td>13</td>\n",
       "      <td>1.084443</td>\n",
       "      <td>-2.989565</td>\n",
       "      <td>-0.060434</td>\n",
       "      <td>0.366474</td>\n",
       "      <td>-0.177837</td>\n",
       "      <td>1.240506</td>\n",
       "      <td>1.557306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390761</td>\n",
       "      <td>0.286877</td>\n",
       "      <td>0.339828</td>\n",
       "      <td>-2.060733</td>\n",
       "      <td>0.108185</td>\n",
       "      <td>0.591215</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.283205</td>\n",
       "      <td>0.207867</td>\n",
       "      <td>0.134309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>50.197878</td>\n",
       "      <td>0.590773</td>\n",
       "      <td>13</td>\n",
       "      <td>0.995646</td>\n",
       "      <td>-2.989565</td>\n",
       "      <td>-0.003278</td>\n",
       "      <td>0.329506</td>\n",
       "      <td>-0.188336</td>\n",
       "      <td>1.476970</td>\n",
       "      <td>1.496544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389953</td>\n",
       "      <td>0.075689</td>\n",
       "      <td>0.017404</td>\n",
       "      <td>-1.749560</td>\n",
       "      <td>0.285561</td>\n",
       "      <td>0.262477</td>\n",
       "      <td>0.033367</td>\n",
       "      <td>0.283366</td>\n",
       "      <td>0.207964</td>\n",
       "      <td>0.134221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>47.782384</td>\n",
       "      <td>0.590482</td>\n",
       "      <td>13</td>\n",
       "      <td>0.942986</td>\n",
       "      <td>-2.138058</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>0.315417</td>\n",
       "      <td>-0.135908</td>\n",
       "      <td>1.563046</td>\n",
       "      <td>1.666211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392547</td>\n",
       "      <td>0.248879</td>\n",
       "      <td>-0.268926</td>\n",
       "      <td>-2.320806</td>\n",
       "      <td>0.252182</td>\n",
       "      <td>0.439522</td>\n",
       "      <td>0.092253</td>\n",
       "      <td>0.283636</td>\n",
       "      <td>0.208019</td>\n",
       "      <td>0.134122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>42.196222</td>\n",
       "      <td>0.556906</td>\n",
       "      <td>16</td>\n",
       "      <td>0.864719</td>\n",
       "      <td>-2.138058</td>\n",
       "      <td>0.055710</td>\n",
       "      <td>0.293009</td>\n",
       "      <td>-0.084476</td>\n",
       "      <td>1.468887</td>\n",
       "      <td>1.447788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367362</td>\n",
       "      <td>0.075561</td>\n",
       "      <td>-0.659481</td>\n",
       "      <td>-3.468569</td>\n",
       "      <td>0.297095</td>\n",
       "      <td>0.200665</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.283847</td>\n",
       "      <td>0.208008</td>\n",
       "      <td>0.134009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>39.810042</td>\n",
       "      <td>0.527231</td>\n",
       "      <td>15</td>\n",
       "      <td>0.843019</td>\n",
       "      <td>-2.010558</td>\n",
       "      <td>0.039838</td>\n",
       "      <td>0.267278</td>\n",
       "      <td>-0.009021</td>\n",
       "      <td>1.491368</td>\n",
       "      <td>1.334600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304961</td>\n",
       "      <td>0.084338</td>\n",
       "      <td>-4.416305</td>\n",
       "      <td>-29.629503</td>\n",
       "      <td>0.223166</td>\n",
       "      <td>0.113958</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>0.283988</td>\n",
       "      <td>0.207988</td>\n",
       "      <td>0.133984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>36.931195</td>\n",
       "      <td>0.503638</td>\n",
       "      <td>14</td>\n",
       "      <td>0.764068</td>\n",
       "      <td>-1.442573</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.240355</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>1.537252</td>\n",
       "      <td>1.522780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220977</td>\n",
       "      <td>0.302821</td>\n",
       "      <td>0.117769</td>\n",
       "      <td>3.151337</td>\n",
       "      <td>0.092346</td>\n",
       "      <td>0.163031</td>\n",
       "      <td>0.074937</td>\n",
       "      <td>0.284105</td>\n",
       "      <td>0.207942</td>\n",
       "      <td>0.133973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>34.658806</td>\n",
       "      <td>0.460887</td>\n",
       "      <td>15</td>\n",
       "      <td>0.764068</td>\n",
       "      <td>-1.790348</td>\n",
       "      <td>-0.016127</td>\n",
       "      <td>0.154874</td>\n",
       "      <td>0.088969</td>\n",
       "      <td>1.355097</td>\n",
       "      <td>1.697312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160941</td>\n",
       "      <td>0.131571</td>\n",
       "      <td>-0.181271</td>\n",
       "      <td>1.740769</td>\n",
       "      <td>0.080994</td>\n",
       "      <td>0.167767</td>\n",
       "      <td>0.020826</td>\n",
       "      <td>0.284131</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.133917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>32.293427</td>\n",
       "      <td>0.413331</td>\n",
       "      <td>16</td>\n",
       "      <td>0.702907</td>\n",
       "      <td>-1.833830</td>\n",
       "      <td>-0.042679</td>\n",
       "      <td>0.055726</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>1.363648</td>\n",
       "      <td>1.123566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044463</td>\n",
       "      <td>0.171553</td>\n",
       "      <td>-1.249398</td>\n",
       "      <td>1.631330</td>\n",
       "      <td>0.071188</td>\n",
       "      <td>0.077944</td>\n",
       "      <td>0.020183</td>\n",
       "      <td>0.283994</td>\n",
       "      <td>0.207949</td>\n",
       "      <td>0.133869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>29.552085</td>\n",
       "      <td>0.380679</td>\n",
       "      <td>16</td>\n",
       "      <td>0.643823</td>\n",
       "      <td>-2.261571</td>\n",
       "      <td>-0.029943</td>\n",
       "      <td>0.058551</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>1.431346</td>\n",
       "      <td>1.380150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.072429</td>\n",
       "      <td>139.884578</td>\n",
       "      <td>-273.532282</td>\n",
       "      <td>0.108464</td>\n",
       "      <td>0.055813</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.283855</td>\n",
       "      <td>0.207907</td>\n",
       "      <td>0.133806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>28.628681</td>\n",
       "      <td>0.388151</td>\n",
       "      <td>15</td>\n",
       "      <td>0.748551</td>\n",
       "      <td>-2.261571</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>0.121179</td>\n",
       "      <td>-0.001118</td>\n",
       "      <td>1.501596</td>\n",
       "      <td>1.056335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080848</td>\n",
       "      <td>0.088312</td>\n",
       "      <td>-12.723873</td>\n",
       "      <td>-108.346334</td>\n",
       "      <td>0.044698</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.283832</td>\n",
       "      <td>0.207777</td>\n",
       "      <td>0.133723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>31.202012</td>\n",
       "      <td>0.424769</td>\n",
       "      <td>12</td>\n",
       "      <td>0.748551</td>\n",
       "      <td>-2.296559</td>\n",
       "      <td>0.027899</td>\n",
       "      <td>0.161286</td>\n",
       "      <td>-0.007585</td>\n",
       "      <td>1.290107</td>\n",
       "      <td>1.100962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113425</td>\n",
       "      <td>0.072110</td>\n",
       "      <td>-3.678264</td>\n",
       "      <td>-21.264081</td>\n",
       "      <td>0.082740</td>\n",
       "      <td>0.058674</td>\n",
       "      <td>0.025675</td>\n",
       "      <td>0.283891</td>\n",
       "      <td>0.207667</td>\n",
       "      <td>0.133650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>37.043244</td>\n",
       "      <td>0.474132</td>\n",
       "      <td>9</td>\n",
       "      <td>0.811739</td>\n",
       "      <td>-2.296559</td>\n",
       "      <td>0.044889</td>\n",
       "      <td>0.215733</td>\n",
       "      <td>0.020089</td>\n",
       "      <td>1.468869</td>\n",
       "      <td>1.291631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174560</td>\n",
       "      <td>0.237978</td>\n",
       "      <td>2.234494</td>\n",
       "      <td>10.738798</td>\n",
       "      <td>0.114589</td>\n",
       "      <td>0.046153</td>\n",
       "      <td>0.068277</td>\n",
       "      <td>0.283968</td>\n",
       "      <td>0.207623</td>\n",
       "      <td>0.133653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>40.417721</td>\n",
       "      <td>0.521556</td>\n",
       "      <td>13</td>\n",
       "      <td>0.811739</td>\n",
       "      <td>-2.106328</td>\n",
       "      <td>0.071501</td>\n",
       "      <td>0.263963</td>\n",
       "      <td>0.051385</td>\n",
       "      <td>1.597287</td>\n",
       "      <td>1.274305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277282</td>\n",
       "      <td>0.086551</td>\n",
       "      <td>1.391487</td>\n",
       "      <td>5.136993</td>\n",
       "      <td>0.221140</td>\n",
       "      <td>0.064596</td>\n",
       "      <td>0.041588</td>\n",
       "      <td>0.284096</td>\n",
       "      <td>0.207568</td>\n",
       "      <td>0.133740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>75.082048</td>\n",
       "      <td>0.854830</td>\n",
       "      <td>8</td>\n",
       "      <td>1.886988</td>\n",
       "      <td>-1.942437</td>\n",
       "      <td>-0.156788</td>\n",
       "      <td>-0.100397</td>\n",
       "      <td>-0.219808</td>\n",
       "      <td>3.007575</td>\n",
       "      <td>2.863405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142211</td>\n",
       "      <td>0.882256</td>\n",
       "      <td>0.713297</td>\n",
       "      <td>0.456749</td>\n",
       "      <td>1.174703</td>\n",
       "      <td>1.360654</td>\n",
       "      <td>0.701078</td>\n",
       "      <td>0.284697</td>\n",
       "      <td>0.208582</td>\n",
       "      <td>0.134190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>94.444034</td>\n",
       "      <td>1.329242</td>\n",
       "      <td>10</td>\n",
       "      <td>1.886988</td>\n",
       "      <td>-0.720750</td>\n",
       "      <td>-0.597080</td>\n",
       "      <td>-0.750786</td>\n",
       "      <td>-0.553879</td>\n",
       "      <td>3.399014</td>\n",
       "      <td>3.539193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.995751</td>\n",
       "      <td>0.383466</td>\n",
       "      <td>1.077998</td>\n",
       "      <td>1.355506</td>\n",
       "      <td>1.566478</td>\n",
       "      <td>1.597249</td>\n",
       "      <td>0.434970</td>\n",
       "      <td>0.284928</td>\n",
       "      <td>0.209312</td>\n",
       "      <td>0.134474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>87.495524</td>\n",
       "      <td>1.165725</td>\n",
       "      <td>10</td>\n",
       "      <td>1.811632</td>\n",
       "      <td>-1.141026</td>\n",
       "      <td>-0.420132</td>\n",
       "      <td>-0.614889</td>\n",
       "      <td>-0.542789</td>\n",
       "      <td>2.771241</td>\n",
       "      <td>3.365093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918069</td>\n",
       "      <td>0.584309</td>\n",
       "      <td>0.774024</td>\n",
       "      <td>1.132832</td>\n",
       "      <td>0.914419</td>\n",
       "      <td>1.417420</td>\n",
       "      <td>0.700633</td>\n",
       "      <td>0.285448</td>\n",
       "      <td>0.210122</td>\n",
       "      <td>0.134747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>54.148387</td>\n",
       "      <td>0.686534</td>\n",
       "      <td>11</td>\n",
       "      <td>1.510674</td>\n",
       "      <td>-2.140450</td>\n",
       "      <td>0.042709</td>\n",
       "      <td>-0.012121</td>\n",
       "      <td>-0.304625</td>\n",
       "      <td>2.166259</td>\n",
       "      <td>2.603800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140143</td>\n",
       "      <td>0.289127</td>\n",
       "      <td>-0.140202</td>\n",
       "      <td>0.039789</td>\n",
       "      <td>0.541762</td>\n",
       "      <td>0.814258</td>\n",
       "      <td>0.195182</td>\n",
       "      <td>0.285778</td>\n",
       "      <td>0.210579</td>\n",
       "      <td>0.134944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>38.922347</td>\n",
       "      <td>0.505641</td>\n",
       "      <td>10</td>\n",
       "      <td>0.985312</td>\n",
       "      <td>-2.140450</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.149271</td>\n",
       "      <td>-0.123074</td>\n",
       "      <td>1.594438</td>\n",
       "      <td>1.395415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235526</td>\n",
       "      <td>0.088317</td>\n",
       "      <td>-1.002111</td>\n",
       "      <td>-1.212861</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.187069</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>0.285859</td>\n",
       "      <td>0.210689</td>\n",
       "      <td>0.134856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>46.782520</td>\n",
       "      <td>0.581770</td>\n",
       "      <td>13</td>\n",
       "      <td>1.053941</td>\n",
       "      <td>-1.637924</td>\n",
       "      <td>0.058261</td>\n",
       "      <td>0.335409</td>\n",
       "      <td>-0.106074</td>\n",
       "      <td>1.535914</td>\n",
       "      <td>1.903042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364928</td>\n",
       "      <td>0.158951</td>\n",
       "      <td>-0.549252</td>\n",
       "      <td>-3.162031</td>\n",
       "      <td>0.106726</td>\n",
       "      <td>0.398723</td>\n",
       "      <td>0.020272</td>\n",
       "      <td>0.285814</td>\n",
       "      <td>0.210847</td>\n",
       "      <td>0.134881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>57.402264</td>\n",
       "      <td>0.693930</td>\n",
       "      <td>17</td>\n",
       "      <td>1.053941</td>\n",
       "      <td>-1.637924</td>\n",
       "      <td>-0.036074</td>\n",
       "      <td>0.538527</td>\n",
       "      <td>-0.093952</td>\n",
       "      <td>1.625960</td>\n",
       "      <td>1.667349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520362</td>\n",
       "      <td>0.123037</td>\n",
       "      <td>0.383964</td>\n",
       "      <td>-5.731964</td>\n",
       "      <td>0.220850</td>\n",
       "      <td>0.242931</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>0.285831</td>\n",
       "      <td>0.210763</td>\n",
       "      <td>0.134990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>59.193564</td>\n",
       "      <td>0.718177</td>\n",
       "      <td>16</td>\n",
       "      <td>1.047500</td>\n",
       "      <td>-1.377616</td>\n",
       "      <td>-0.016416</td>\n",
       "      <td>0.510769</td>\n",
       "      <td>-0.093306</td>\n",
       "      <td>1.583041</td>\n",
       "      <td>1.875385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532638</td>\n",
       "      <td>0.131984</td>\n",
       "      <td>0.175934</td>\n",
       "      <td>-5.474108</td>\n",
       "      <td>0.472589</td>\n",
       "      <td>0.631294</td>\n",
       "      <td>0.059678</td>\n",
       "      <td>0.286101</td>\n",
       "      <td>0.210636</td>\n",
       "      <td>0.135071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>55.269961</td>\n",
       "      <td>0.720331</td>\n",
       "      <td>16</td>\n",
       "      <td>1.036543</td>\n",
       "      <td>-1.377616</td>\n",
       "      <td>0.044006</td>\n",
       "      <td>0.461338</td>\n",
       "      <td>-0.104996</td>\n",
       "      <td>1.749718</td>\n",
       "      <td>1.598822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534621</td>\n",
       "      <td>0.088217</td>\n",
       "      <td>-0.419126</td>\n",
       "      <td>-4.393870</td>\n",
       "      <td>0.527972</td>\n",
       "      <td>0.231336</td>\n",
       "      <td>0.015047</td>\n",
       "      <td>0.286480</td>\n",
       "      <td>0.210557</td>\n",
       "      <td>0.135106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>51.777941</td>\n",
       "      <td>0.733484</td>\n",
       "      <td>16</td>\n",
       "      <td>1.224945</td>\n",
       "      <td>-0.926932</td>\n",
       "      <td>0.048026</td>\n",
       "      <td>0.443718</td>\n",
       "      <td>-0.147762</td>\n",
       "      <td>1.745421</td>\n",
       "      <td>1.674620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520987</td>\n",
       "      <td>0.090344</td>\n",
       "      <td>-0.325023</td>\n",
       "      <td>-3.002924</td>\n",
       "      <td>0.500751</td>\n",
       "      <td>0.140482</td>\n",
       "      <td>0.023202</td>\n",
       "      <td>0.286942</td>\n",
       "      <td>0.210523</td>\n",
       "      <td>0.135128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>53.430303</td>\n",
       "      <td>0.733542</td>\n",
       "      <td>20</td>\n",
       "      <td>1.224945</td>\n",
       "      <td>-0.877499</td>\n",
       "      <td>0.073468</td>\n",
       "      <td>0.437851</td>\n",
       "      <td>-0.153555</td>\n",
       "      <td>1.743833</td>\n",
       "      <td>1.748031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511786</td>\n",
       "      <td>0.166433</td>\n",
       "      <td>-0.478449</td>\n",
       "      <td>-2.851425</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.199524</td>\n",
       "      <td>0.041826</td>\n",
       "      <td>0.287370</td>\n",
       "      <td>0.210571</td>\n",
       "      <td>0.135136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>51.214433</td>\n",
       "      <td>0.693997</td>\n",
       "      <td>17</td>\n",
       "      <td>1.200535</td>\n",
       "      <td>-0.923485</td>\n",
       "      <td>0.118693</td>\n",
       "      <td>0.376886</td>\n",
       "      <td>-0.115565</td>\n",
       "      <td>1.815211</td>\n",
       "      <td>1.703896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467521</td>\n",
       "      <td>0.071888</td>\n",
       "      <td>-1.027066</td>\n",
       "      <td>-3.261252</td>\n",
       "      <td>0.094648</td>\n",
       "      <td>0.300684</td>\n",
       "      <td>0.022210</td>\n",
       "      <td>0.287790</td>\n",
       "      <td>0.210652</td>\n",
       "      <td>0.135053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>44.914665</td>\n",
       "      <td>0.650373</td>\n",
       "      <td>14</td>\n",
       "      <td>1.085397</td>\n",
       "      <td>-1.012870</td>\n",
       "      <td>0.088389</td>\n",
       "      <td>0.365390</td>\n",
       "      <td>-0.158675</td>\n",
       "      <td>1.829881</td>\n",
       "      <td>1.595899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434356</td>\n",
       "      <td>0.068317</td>\n",
       "      <td>-0.557043</td>\n",
       "      <td>-2.302763</td>\n",
       "      <td>0.175848</td>\n",
       "      <td>0.314835</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>0.288108</td>\n",
       "      <td>0.210628</td>\n",
       "      <td>0.134981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>54.813194</td>\n",
       "      <td>0.705982</td>\n",
       "      <td>9</td>\n",
       "      <td>1.310744</td>\n",
       "      <td>-1.132053</td>\n",
       "      <td>0.063241</td>\n",
       "      <td>0.222270</td>\n",
       "      <td>-0.219398</td>\n",
       "      <td>2.026275</td>\n",
       "      <td>3.165813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350760</td>\n",
       "      <td>0.090294</td>\n",
       "      <td>-0.288250</td>\n",
       "      <td>-1.013090</td>\n",
       "      <td>0.513440</td>\n",
       "      <td>1.006450</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.288429</td>\n",
       "      <td>0.210976</td>\n",
       "      <td>0.135117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>69.794588</td>\n",
       "      <td>0.975835</td>\n",
       "      <td>6</td>\n",
       "      <td>1.797117</td>\n",
       "      <td>-1.132053</td>\n",
       "      <td>-0.244063</td>\n",
       "      <td>-0.287646</td>\n",
       "      <td>-0.366261</td>\n",
       "      <td>2.087223</td>\n",
       "      <td>2.383438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191880</td>\n",
       "      <td>0.343909</td>\n",
       "      <td>0.666364</td>\n",
       "      <td>0.785358</td>\n",
       "      <td>0.382773</td>\n",
       "      <td>0.100276</td>\n",
       "      <td>0.231170</td>\n",
       "      <td>0.289133</td>\n",
       "      <td>0.212087</td>\n",
       "      <td>0.135395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>70.422743</td>\n",
       "      <td>0.860847</td>\n",
       "      <td>10</td>\n",
       "      <td>1.797117</td>\n",
       "      <td>-2.514068</td>\n",
       "      <td>-0.237525</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>-0.339755</td>\n",
       "      <td>2.910221</td>\n",
       "      <td>2.676493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020616</td>\n",
       "      <td>0.163606</td>\n",
       "      <td>0.699107</td>\n",
       "      <td>0.581294</td>\n",
       "      <td>0.926911</td>\n",
       "      <td>1.080601</td>\n",
       "      <td>0.117749</td>\n",
       "      <td>0.289590</td>\n",
       "      <td>0.213048</td>\n",
       "      <td>0.135599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>47.536576</td>\n",
       "      <td>0.609779</td>\n",
       "      <td>12</td>\n",
       "      <td>1.198004</td>\n",
       "      <td>-2.514068</td>\n",
       "      <td>0.138246</td>\n",
       "      <td>0.256023</td>\n",
       "      <td>-0.177436</td>\n",
       "      <td>1.871819</td>\n",
       "      <td>1.651358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288756</td>\n",
       "      <td>0.106597</td>\n",
       "      <td>-0.779132</td>\n",
       "      <td>-1.442906</td>\n",
       "      <td>0.643658</td>\n",
       "      <td>0.127020</td>\n",
       "      <td>0.128023</td>\n",
       "      <td>0.289851</td>\n",
       "      <td>0.213211</td>\n",
       "      <td>0.135550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60896 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fundamental_freq  average_accel  \\\n",
       "healthCode                                                              \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        108.314444       1.361654   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         95.117992       1.399965   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         93.161575       1.300919   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        100.162152       1.274289   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        108.066819       1.299515   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        109.731461       1.307171   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        107.141324       1.307852   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        103.723405       1.313845   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         95.706105       1.338492   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         98.245296       1.360542   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        100.527171       1.387331   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         94.902995       1.391027   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        102.487545       1.359509   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        108.900845       1.344979   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        109.154748       1.342602   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        102.646973       1.344636   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         94.047589       1.362276   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         95.770697       1.379599   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         99.687678       1.387466   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         98.898877       1.394423   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         96.307548       1.378818   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         96.702952       1.349875   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        109.502374       1.355172   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        116.394760       1.380513   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        109.615936       1.510821   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        107.197481       1.521793   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         97.611163       1.337596   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         84.728459       1.137462   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         74.483441       0.948787   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         59.160786       0.774666   \n",
       "...                                                ...            ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         54.670532       0.575156   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         50.197878       0.590773   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         47.782384       0.590482   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         42.196222       0.556906   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         39.810042       0.527231   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         36.931195       0.503638   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         34.658806       0.460887   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         32.293427       0.413331   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         29.552085       0.380679   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         28.628681       0.388151   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         31.202012       0.424769   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         37.043244       0.474132   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         40.417721       0.521556   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         75.082048       0.854830   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         94.444034       1.329242   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         87.495524       1.165725   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         54.148387       0.686534   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         38.922347       0.505641   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         46.782520       0.581770   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         57.402264       0.693930   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         59.193564       0.718177   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         55.269961       0.720331   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         51.777941       0.733484   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         53.430303       0.733542   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         51.214433       0.693997   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         44.914665       0.650373   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         54.813194       0.705982   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         69.794588       0.975835   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         70.422743       0.860847   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         47.536576       0.609779   \n",
       "\n",
       "                                      peakcount       max       min     mut_x  \\\n",
       "healthCode                                                                      \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  2.064969 -0.330143  0.690610   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         13  2.064969 -0.330143  0.802499   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  1.786842 -0.142095  0.615637   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.683957 -0.142095  0.531247   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.729218 -0.205279  0.581625   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          8  1.862491 -0.205279  0.613979   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.862491 -0.117244  0.620030   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.831361 -0.116085  0.668747   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.831361 -0.116085  0.723892   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         14  1.714565 -0.149190  0.713559   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         11  1.771999 -0.149190  0.786215   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          7  1.821847 -0.009313  0.828527   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          7  1.821847 -0.078247  0.770966   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          6  1.857509 -0.078247  0.760305   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.857509 -0.131206  0.752882   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.802260 -0.131206  0.740430   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.775034 -0.130712  0.756105   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  1.771262 -0.208031  0.776573   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         13  1.825576 -0.208031  0.778579   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.860749 -0.102235  0.781270   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          6  1.860749 -0.057689  0.787840   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          6  1.828100 -0.029004  0.764451   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          7  1.854060 -0.051702  0.753059   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          8  1.854060 -0.051702  0.816185   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  2.360111 -0.102887  1.124904   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         18  2.542108 -0.278029  1.305427   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         18  2.787768 -0.367846  1.085107   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         16  2.787768 -0.805225  0.682007   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  1.710222 -1.275452  0.269216   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.710222 -2.584695 -0.087773   \n",
       "...                                         ...       ...       ...       ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         13  1.084443 -2.989565 -0.060434   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         13  0.995646 -2.989565 -0.003278   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         13  0.942986 -2.138058  0.036549   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  0.864719 -2.138058  0.055710   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         15  0.843019 -2.010558  0.039838   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         14  0.764068 -1.442573  0.008982   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         15  0.764068 -1.790348 -0.016127   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  0.702907 -1.833830 -0.042679   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  0.643823 -2.261571 -0.029943   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         15  0.748551 -2.261571  0.014231   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         12  0.748551 -2.296559  0.027899   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d          9  0.811739 -2.296559  0.044889   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         13  0.811739 -2.106328  0.071501   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d          8  1.886988 -1.942437 -0.156788   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         10  1.886988 -0.720750 -0.597080   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         10  1.811632 -1.141026 -0.420132   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         11  1.510674 -2.140450  0.042709   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         10  0.985312 -2.140450  0.123333   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         13  1.053941 -1.637924  0.058261   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         17  1.053941 -1.637924 -0.036074   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  1.047500 -1.377616 -0.016416   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  1.036543 -1.377616  0.044006   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  1.224945 -0.926932  0.048026   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         20  1.224945 -0.877499  0.073468   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         17  1.200535 -0.923485  0.118693   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         14  1.085397 -1.012870  0.088389   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d          9  1.310744 -1.132053  0.063241   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d          6  1.797117 -1.132053 -0.244063   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         10  1.797117 -2.514068 -0.237525   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         12  1.198004 -2.514068  0.138246   \n",
       "\n",
       "                                         mut_y     mut_z     muf_x     muf_y  \\\n",
       "healthCode                                                                     \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.886621 -0.622883  2.408580  2.420899   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.909826 -0.563515  2.063195  2.432729   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.780069 -0.795731  1.537021  1.699596   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.750150 -0.853475  1.151398  1.632215   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.740917 -0.868740  1.131018  1.579905   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.713431 -0.877655  1.197633  1.555487   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.699920 -0.883751  1.157659  1.531361   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.721150 -0.849102  1.293646  1.541653   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.692789 -0.866560  1.400238  1.525359   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.650981 -0.937036  1.326184  1.586319   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.669889 -0.902668  1.717213  1.514250   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.741714 -0.807926  1.523948  1.723703   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.754207 -0.795563  1.353717  1.694970   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.730384 -0.807791  1.357898  1.616392   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.746872 -0.798955  1.546340  1.520144   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.758812 -0.802888  1.460257  1.555709   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.756897 -0.813937  1.394568  1.573560   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.759795 -0.813358  1.329132  1.761010   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.750619 -0.826945  1.428243  1.872350   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.729907 -0.853349  1.403245  1.710714   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.747305 -0.814065  1.585836  1.891071   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.767287 -0.782714  1.464625  1.787889   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.749572 -0.814916  1.405809  1.519122   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.776699 -0.721390  1.881259  1.738262   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.621356 -0.352783  3.616662  2.766881   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.007060 -0.205313  3.929681  3.263623   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c  0.493045 -0.272621  4.004222  3.797662   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c  0.689005 -0.306396  2.982157  3.858923   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c  0.738074 -0.372125  1.953287  2.489452   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c  0.564067 -0.340849  1.892667  2.283208   \n",
       "...                                        ...       ...       ...       ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.366474 -0.177837  1.240506  1.557306   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.329506 -0.188336  1.476970  1.496544   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.315417 -0.135908  1.563046  1.666211   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.293009 -0.084476  1.468887  1.447788   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.267278 -0.009021  1.491368  1.334600   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.240355  0.076271  1.537252  1.522780   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.154874  0.088969  1.355097  1.697312   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.055726  0.034160  1.363648  1.123566   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.058551 -0.000214  1.431346  1.380150   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.121179 -0.001118  1.501596  1.056335   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.161286 -0.007585  1.290107  1.100962   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.215733  0.020089  1.468869  1.291631   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.263963  0.051385  1.597287  1.274305   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.100397 -0.219808  3.007575  2.863405   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.750786 -0.553879  3.399014  3.539193   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.614889 -0.542789  2.771241  3.365093   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.012121 -0.304625  2.166259  2.603800   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.149271 -0.123074  1.594438  1.395415   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.335409 -0.106074  1.535914  1.903042   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.538527 -0.093952  1.625960  1.667349   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.510769 -0.093306  1.583041  1.875385   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.461338 -0.104996  1.749718  1.598822   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.443718 -0.147762  1.745421  1.674620   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.437851 -0.153555  1.743833  1.748031   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.376886 -0.115565  1.815211  1.703896   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.365390 -0.158675  1.829881  1.595899   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.222270 -0.219398  2.026275  3.165813   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.287646 -0.366261  2.087223  2.383438   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.197497 -0.339755  2.910221  2.676493   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.256023 -0.177436  1.871819  1.651358   \n",
       "\n",
       "                                             ...            medf_y    medf_z  \\\n",
       "healthCode                                   ...                               \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.815326  0.261730   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.900119  0.383518   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.781222  0.208414   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.779094  0.077215   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.737040  0.084270   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.714885  0.182796   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.726893  0.146422   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.706561  0.157716   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.656978  0.252391   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.657954  0.146233   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.682765  0.092975   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.758441  0.392156   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.756640  0.121150   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.719767  0.081930   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.730288  0.074852   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.755519  0.364381   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.757823  0.241106   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.787883  0.069861   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.761371  0.078687   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.742465  0.162758   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.755465  0.336637   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.740771  0.078777   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.692027  0.228329   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.781398  0.792999   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.730265  0.760603   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...          0.135800  0.599603   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...          0.416234  1.163063   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...          0.645383  1.260064   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...          0.700643  0.612980   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...          0.526914  0.245872   \n",
       "...                                          ...               ...       ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.390761  0.286877   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.389953  0.075689   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.392547  0.248879   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.367362  0.075561   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.304961  0.084338   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.220977  0.302821   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.160941  0.131571   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.044463  0.171553   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.001189  0.072429   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.080848  0.088312   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.113425  0.072110   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.174560  0.237978   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.277282  0.086551   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.142211  0.882256   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...         -0.995751  0.383466   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...         -0.918069  0.584309   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.140143  0.289127   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.235526  0.088317   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.364928  0.158951   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.520362  0.123037   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.532638  0.131984   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.534621  0.088217   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.520987  0.090344   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.511786  0.166433   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.467521  0.071888   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.434356  0.068317   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.350760  0.090294   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...         -0.191880  0.343909   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...         -0.020616  0.163606   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.288756  0.106597   \n",
       "\n",
       "                                        cross_xz    cross_yz  spect_cent_x  \\\n",
       "healthCode                                                                   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -1.108732    1.423415      0.303866   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -1.424095    1.614554      0.055270   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.773675    0.980318      0.896903   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.622452    0.878936      0.177303   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.669505    0.852864      0.319803   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.699567    0.812884      0.374420   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.701589    0.791987      0.341018   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.787594    0.849309      0.539139   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.835363    0.799470      0.356895   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.761506    0.694724      0.687310   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.870989    0.742121      0.374878   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -1.025497    0.918047      0.573125   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.969083    0.948017      0.878901   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.941214    0.904174      0.712077   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.942334    0.934811      0.825119   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.922208    0.945103      0.749242   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.928949    0.929922      0.398179   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.954774    0.934146      0.493444   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.941513    0.907701      0.446762   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.915533    0.855344      0.597968   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.967785    0.917991      0.274690   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.976667    0.980291      0.393992   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.924094    0.919815      0.875586   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -1.131406    1.076670      0.583398   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -3.188658    1.761300      0.877253   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -6.358237    0.034385      1.398453   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -3.980283   -1.808539      2.427015   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -2.225903   -2.248741      1.381585   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.723455   -1.983402      0.348549   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c    0.257513   -1.654890      0.198529   \n",
       "...                                          ...         ...           ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.339828   -2.060733      0.108185   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.017404   -1.749560      0.285561   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.268926   -2.320806      0.252182   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.659481   -3.468569      0.297095   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -4.416305  -29.629503      0.223166   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.117769    3.151337      0.092346   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.181271    1.740769      0.080994   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -1.249398    1.631330      0.071188   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  139.884578 -273.532282      0.108464   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  -12.723873 -108.346334      0.044698   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -3.678264  -21.264081      0.082740   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    2.234494   10.738798      0.114589   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    1.391487    5.136993      0.221140   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.713297    0.456749      1.174703   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    1.077998    1.355506      1.566478   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.774024    1.132832      0.914419   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.140202    0.039789      0.541762   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -1.002111   -1.212861      0.035937   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.549252   -3.162031      0.106726   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.383964   -5.731964      0.220850   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.175934   -5.474108      0.472589   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.419126   -4.393870      0.527972   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.325023   -3.002924      0.500751   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.478449   -2.851425      0.167300   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -1.027066   -3.261252      0.094648   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.557043   -2.302763      0.175848   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.288250   -1.013090      0.513440   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.666364    0.785358      0.382773   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.699107    0.581294      0.926911   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.779132   -1.442906      0.643658   \n",
       "\n",
       "                                      spect_cent_y  spect_cent_z  \\\n",
       "healthCode                                                         \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.484718      0.891400   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.206965      0.505872   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.608516      0.523008   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.664331      1.269846   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.922528      1.160783   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.966315      1.395159   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.678090      1.303551   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.792449      0.934569   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.415980      1.094721   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.729889      0.550284   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.304298      0.444606   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.193399      0.262078   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.192182      0.622840   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.538247      1.142288   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.678696      0.906691   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.915445      1.258717   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.755275      1.117008   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.931416      0.519440   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.695264      0.405988   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.415603      0.624520   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.081796      0.347779   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.102864      0.831110   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.621358      1.191681   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.786356      1.240218   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.789743      0.669656   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      1.141195      0.276229   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.693736      0.076705   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.481171      0.062616   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.496770      0.170647   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.454449      0.040465   \n",
       "...                                            ...           ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.591215      0.036640   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.262477      0.033367   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.439522      0.092253   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.200665      0.017361   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.113958      0.019837   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.163031      0.074937   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.167767      0.020826   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.077944      0.020183   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.055813      0.030208   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.013184      0.002369   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.058674      0.025675   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.046153      0.068277   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.064596      0.041588   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      1.360654      0.701078   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      1.597249      0.434970   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      1.417420      0.700633   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.814258      0.195182   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.187069      0.012596   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.398723      0.020272   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.242931      0.013952   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.631294      0.059678   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.231336      0.015047   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.140482      0.023202   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.199524      0.041826   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.300684      0.022210   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.314835      0.032902   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      1.006450      0.003416   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.100276      0.231170   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      1.080601      0.117749   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.127020      0.128023   \n",
       "\n",
       "                                      average_dist_meanx  average_dist_meany  \\\n",
       "healthCode                                                                     \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.240233            0.241233   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.215864            0.247436   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.192852            0.216332   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.169978            0.200500   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.156258            0.195590   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.147237            0.194389   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.139344            0.190995   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.135015            0.185874   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.131864            0.181516   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.129255            0.177092   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.129458            0.175094   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.128364            0.174815   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.126270            0.173775   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.125267            0.172130   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.124248            0.171290   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.123298            0.170575   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.122566            0.170022   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.120759            0.169525   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.119078            0.168535   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.118110            0.167335   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.117879            0.166682   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.118133            0.166568   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.117878            0.166404   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.119135            0.166836   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.130391            0.174915   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.140732            0.186457   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.147303            0.189583   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.154285            0.193580   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.156555            0.195372   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.161543            0.197066   \n",
       "...                                                  ...                 ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283205            0.207867   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283366            0.207964   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283636            0.208019   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283847            0.208008   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283988            0.207988   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.284105            0.207942   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.284131            0.207921   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283994            0.207949   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283855            0.207907   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283832            0.207777   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283891            0.207667   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283968            0.207623   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.284096            0.207568   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.284697            0.208582   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.284928            0.209312   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.285448            0.210122   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.285778            0.210579   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.285859            0.210689   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.285814            0.210847   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.285831            0.210763   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.286101            0.210636   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.286480            0.210557   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.286942            0.210523   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.287370            0.210571   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.287790            0.210652   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.288108            0.210628   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.288429            0.210976   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.289133            0.212087   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.289590            0.213048   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.289851            0.213211   \n",
       "\n",
       "                                      average_dist_meanz  \n",
       "healthCode                                                \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.312021  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.306005  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.278009  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.262656  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.256213  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.253153  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.248046  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.242997  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.239425  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.233075  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.225587  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.222414  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.221624  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.219561  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.217375  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.216757  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.217175  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.218042  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.219156  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.220526  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.220755  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.219411  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.220085  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.223415  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.228530  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.231050  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.231789  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.230438  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.231140  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.231756  \n",
       "...                                                  ...  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134309  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134221  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134122  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134009  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133984  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133973  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133917  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133869  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133806  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133723  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133650  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133653  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133740  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134190  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134474  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134747  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134944  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134856  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134881  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134990  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135071  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135106  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135128  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135136  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135053  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134981  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135117  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135395  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135599  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135550  \n",
       "\n",
       "[60896 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything_no_demog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BMI = []\n",
    "for q in list(set(everything_no_demog.index.values)):\n",
    "    temp = []\n",
    "    temp.append(((everything.loc[q].weight.values) / (((everything.loc[q].height.values)**2))) * 703)\n",
    "    BMI.append(temp)\n",
    "    \n",
    "BMI = np.array(BMI)\n",
    "BMI = BMI.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code inserts BMI directly\n",
    "#everything_no_demog.insert(25, 'BMI', BMI)\n",
    "\n",
    "# This code inserts sex into the no demog df so that it can be used for training/testing\n",
    "everything_no_demog.insert(25, 'sex', everything.sex.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  22.9s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  23.2s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  23.4s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  23.2s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  24.5s\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  3.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.2min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.2min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 1.9min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 1.9min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 1.9min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 1.9min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 1.9min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.1min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  18.2s\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  18.5s\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.1min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.1min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.1min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.1min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  18.5s\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  18.2s\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  18.0s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.8min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.8min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.8min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.9min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.9min\n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 6.2min\n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 6.0min\n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=10.0min\n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 4.7min\n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 4.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  50 | elapsed: 13.9min remaining:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 4.7min\n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total= 8.9min\n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total= 8.9min\n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total= 8.8min\n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total= 8.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 14.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [10, 31, 52, 73, 94, 115, 136, 157, 178, 200], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower the number of trees to reduce overfitting\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "numOfTotalHC = 173\n",
    "numOfTrainHC = 103\n",
    "numOfTestHC = 70\n",
    "\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "# One-hot encode ouput\n",
    "training = everything_no_demog.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = everything_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(newtotal_df)):]\n",
    "\n",
    "#uniques, labelings = pd.factorize(training.sex.values)\n",
    "#training.drop(['sex'], axis=1, inplace=True)\n",
    "#training.insert(25, 'sex_encoded', uniques)\n",
    "\n",
    "X = np.array(training.iloc[:, 0:25])\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y = np.array(training.iloc[:, 25])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_mixed = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixed = np.concatenate((y_train, y_test), axis=0)\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfopts = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rfopts, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 80,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 94}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "numOfTotalHC = 173\n",
    "numOfTrainHC = 103\n",
    "numOfTestHC = 70\n",
    "\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "# One-hot encode ouput\n",
    "training = everything_no_demog.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = everything_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(newtotal_df)):]\n",
    "\n",
    "#uniques, labelings = pd.factorize(training.sex.values)\n",
    "#training.drop(['sex'], axis=1, inplace=True)\n",
    "#training.insert(25, 'sex_encoded', uniques)\n",
    "\n",
    "X = np.array(training.iloc[:, 0:25])\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y = np.array(training.iloc[:, 25])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "newrf = RandomForestClassifier(n_estimators=200, max_depth=50, min_samples_split=2, min_samples_leaf=2, bootstrap=False)\n",
    "scores_old = cross_val_score(newrf, X_scaled, y, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (24640, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-42b493d576fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#cohen_kappa_score(testing.iloc[:, 25], newrf.predict(testing.iloc[:, 0:25]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#confusion_matrix(testing.iloc[:, 25], newrf.predict(testing.iloc[:, 0:25]), sample_weight=sample_weight)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m     return _average_binary_score(_binary_uninterpolated_average_precision,\n\u001b[1;32m    198\u001b[0m                                  \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_uninterpolated_average_precision\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    189\u001b[0m             y_true, y_score, sample_weight=None):\n\u001b[1;32m    190\u001b[0m         precision, recall, thresholds = precision_recall_curve(\n\u001b[0;32m--> 191\u001b[0;31m             y_true, y_score, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Return the step function integral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# The following works because the last entry of precision is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[1;32m    440\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                                              sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (24640, 2)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "sample_weight = np.array([4 if i == 'Female' else 1 for i in list(testing.iloc[:, 25])])\n",
    "newrf.score(testing.iloc[:, 0:25], testing.iloc[:, 25], sample_weight=sample_weight)\n",
    "#cohen_kappa_score(testing.iloc[:, 25], newrf.predict(testing.iloc[:, 0:25]))\n",
    "#confusion_matrix(testing.iloc[:, 25], newrf.predict(testing.iloc[:, 0:25]), sample_weight=sample_weight) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling the males (old data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numOfTotalHC = 173\n",
    "numOfTrainHC = 103\n",
    "numOfTestHC = 70\n",
    "\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "# One-hot encode ouput\n",
    "training = everything_no_demog.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = everything_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(newtotal_df)):]\n",
    "\n",
    "Xmale = np.array(choppedmale_train.iloc[:, 0:25])\n",
    "Xfemale = np.array(female_train.iloc[:, 0:25])\n",
    "X_scaledmale = preprocessing.scale(Xmale)\n",
    "X_scaledfemale = preprocessing.scale(Xfemale)\n",
    "\n",
    "X_scaledtotal = np.array(list(X_scaledmale)+list(X_scaledfemale))\n",
    "y_total = np.array(list(choppedmale_train.iloc[:, 25]) + list(female_train.iloc[:, 25]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaledtotal, y_total, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "X_mixedequal = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixedequal = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "\n",
    "# Taking from the training \n",
    "female_train = training.loc[training['sex'] == 'Female']\n",
    "male_train = training.loc[training['sex'] == 'Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframe with the downsampled males\n",
    "choppedmale_train = male_train.iloc[0:9000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_zero, label = pd.factorize(y_mixedequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9152"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(male_zero).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11152"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(choppedmale_train))\n",
    "len(female_train)\n",
    "len(male_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18152"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_mixedequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [18152, 11152]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-800fc21cb919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mrf_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'average_precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Fit the random search model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_mixedequal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmale_zero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# Regenerate parameter iterable for each fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [18152, 11152]"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "numOfTotalHC = 173\n",
    "numOfTrainHC = 103\n",
    "numOfTestHC = 70\n",
    "\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "# One-hot encode ouput\n",
    "training = everything_no_demog.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = everything_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(newtotal_df)):]\n",
    "\n",
    "#uniques, labelings = pd.factorize(training.sex.values)\n",
    "#training.drop(['sex'], axis=1, inplace=True)\n",
    "#training.insert(25, 'sex_encoded', uniques)\n",
    "\n",
    "Xmale = np.array(choppedmale_train.iloc[:, 0:25])\n",
    "Xfemale = np.array(female_train.iloc[:, 0:25])\n",
    "X_scaledmale = preprocessing.scale(Xmale)\n",
    "X_scaledfemale = preprocessing.scale(Xfemale)\n",
    "\n",
    "X_scaledtotal = np.array(list(X_scaledmale)+list(X_scaledfemale))\n",
    "y_total = np.array(list(choppedmale_train.iloc[:, 25]) + list(female_train.iloc[:, 25]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaledtotal, y_total, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "X_mixedequal = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixedequal = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "dsrf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = dsrf, param_distributions = random_grid, n_iter = 20, scoring='average_precision', cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_mixedequal, male_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 50,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsrf = RandomForestClassifier(n_estimators=200, max_depth=50, min_samples_split=2, min_samples_leaf=2, bootstrap=False, random_state=42)\n",
    "dsrf.fit(X_mixedequal, male_zero)\n",
    "scores = cross_val_score(dsrf, X_mixedequal, male_zero, cv=5, scoring='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99992559, 0.99997768, 0.99994408, 0.9998837 , 0.99998214])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9152"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(female_train.iloc[:, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_one = [1 for x in range(0, 5632)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7959872159090909"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrf.score(female.iloc[:, 0:25], female_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(male.iloc[:, 25])\n",
    "male_zero_test = [0 for y in range(0, 19008)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19681186868686867"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrf.score(male.iloc[:, 0:25], male_zero_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24640"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totallabel = [1 if x=='Female' else 0 for x in testing.iloc[:, 25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5632"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(totallabel).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33376623376623377"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrf.score(testing.iloc[:, 0:25], totallabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.009267840593141896"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "#sample_weight = np.array([4 if i == 'Female' else 1 for i in list(testing.iloc[:, 25])])\n",
    "#newrf.score(testing.iloc[:, 0:25], testing.iloc[:, 25], sample_weight=sample_weight)\n",
    "cohen_kappa_score(testing.iloc[:, 25], dsrf.predict(testing.iloc[:, 0:25]))\n",
    "#confusion_matrix(testing.iloc[:, 25], dsrf.predict(testing.iloc[:, 0:25])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numOfTotalHC = 173\n",
    "numOfTrainHC = 103\n",
    "numOfTestHC = 70\n",
    "testing = everything_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(newtotal_df)):]\n",
    "\n",
    "female = testing.loc[testing['sex'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fundamental_freq</th>\n",
       "      <th>average_accel</th>\n",
       "      <th>peakcount</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mut_x</th>\n",
       "      <th>mut_y</th>\n",
       "      <th>mut_z</th>\n",
       "      <th>muf_x</th>\n",
       "      <th>muf_y</th>\n",
       "      <th>...</th>\n",
       "      <th>medf_z</th>\n",
       "      <th>cross_xz</th>\n",
       "      <th>cross_yz</th>\n",
       "      <th>spect_cent_x</th>\n",
       "      <th>spect_cent_y</th>\n",
       "      <th>spect_cent_z</th>\n",
       "      <th>average_dist_meanx</th>\n",
       "      <th>average_dist_meany</th>\n",
       "      <th>average_dist_meanz</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1a254ea6-2875-4394-9b92-515f89aac1c0</th>\n",
       "      <td>123.003682</td>\n",
       "      <td>1.761073</td>\n",
       "      <td>10</td>\n",
       "      <td>2.644966</td>\n",
       "      <td>0.265567</td>\n",
       "      <td>-0.220573</td>\n",
       "      <td>-1.519599</td>\n",
       "      <td>-0.739240</td>\n",
       "      <td>1.983707</td>\n",
       "      <td>3.083983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282210</td>\n",
       "      <td>0.298378</td>\n",
       "      <td>2.055623</td>\n",
       "      <td>0.229315</td>\n",
       "      <td>1.465557</td>\n",
       "      <td>0.832902</td>\n",
       "      <td>0.230915</td>\n",
       "      <td>0.189005</td>\n",
       "      <td>0.264621</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1a254ea6-2875-4394-9b92-515f89aac1c0</th>\n",
       "      <td>120.408201</td>\n",
       "      <td>1.742037</td>\n",
       "      <td>13</td>\n",
       "      <td>2.644966</td>\n",
       "      <td>0.143988</td>\n",
       "      <td>-0.270648</td>\n",
       "      <td>-1.482989</td>\n",
       "      <td>-0.726592</td>\n",
       "      <td>1.983050</td>\n",
       "      <td>2.995173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284106</td>\n",
       "      <td>0.372490</td>\n",
       "      <td>2.041019</td>\n",
       "      <td>0.087680</td>\n",
       "      <td>1.637327</td>\n",
       "      <td>0.897205</td>\n",
       "      <td>0.230161</td>\n",
       "      <td>0.202340</td>\n",
       "      <td>0.301559</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1a254ea6-2875-4394-9b92-515f89aac1c0</th>\n",
       "      <td>112.320329</td>\n",
       "      <td>1.638993</td>\n",
       "      <td>12</td>\n",
       "      <td>2.506517</td>\n",
       "      <td>0.143988</td>\n",
       "      <td>-0.210871</td>\n",
       "      <td>-1.288581</td>\n",
       "      <td>-0.883986</td>\n",
       "      <td>1.580715</td>\n",
       "      <td>3.059265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478444</td>\n",
       "      <td>0.238546</td>\n",
       "      <td>1.457694</td>\n",
       "      <td>0.282907</td>\n",
       "      <td>2.576500</td>\n",
       "      <td>0.348468</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>0.184547</td>\n",
       "      <td>0.315410</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1a254ea6-2875-4394-9b92-515f89aac1c0</th>\n",
       "      <td>111.140727</td>\n",
       "      <td>1.565864</td>\n",
       "      <td>20</td>\n",
       "      <td>3.112473</td>\n",
       "      <td>-0.430623</td>\n",
       "      <td>-0.600329</td>\n",
       "      <td>-0.939812</td>\n",
       "      <td>-0.573548</td>\n",
       "      <td>3.857549</td>\n",
       "      <td>4.052695</td>\n",
       "      <td>...</td>\n",
       "      <td>2.647426</td>\n",
       "      <td>1.046692</td>\n",
       "      <td>1.638592</td>\n",
       "      <td>0.613110</td>\n",
       "      <td>1.370520</td>\n",
       "      <td>1.541681</td>\n",
       "      <td>0.274628</td>\n",
       "      <td>0.239210</td>\n",
       "      <td>0.362077</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1a254ea6-2875-4394-9b92-515f89aac1c0</th>\n",
       "      <td>104.537138</td>\n",
       "      <td>1.232072</td>\n",
       "      <td>19</td>\n",
       "      <td>3.112473</td>\n",
       "      <td>-1.048801</td>\n",
       "      <td>-0.729662</td>\n",
       "      <td>-0.353179</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>4.181419</td>\n",
       "      <td>4.843472</td>\n",
       "      <td>...</td>\n",
       "      <td>3.211494</td>\n",
       "      <td>2245.883523</td>\n",
       "      <td>1087.078214</td>\n",
       "      <td>0.209053</td>\n",
       "      <td>0.661385</td>\n",
       "      <td>1.787723</td>\n",
       "      <td>0.312203</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>0.382888</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fundamental_freq  average_accel  \\\n",
       "healthCode                                                              \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0        123.003682       1.761073   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0        120.408201       1.742037   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0        112.320329       1.638993   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0        111.140727       1.565864   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0        104.537138       1.232072   \n",
       "\n",
       "                                      peakcount       max       min     mut_x  \\\n",
       "healthCode                                                                      \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0         10  2.644966  0.265567 -0.220573   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0         13  2.644966  0.143988 -0.270648   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0         12  2.506517  0.143988 -0.210871   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0         20  3.112473 -0.430623 -0.600329   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0         19  3.112473 -1.048801 -0.729662   \n",
       "\n",
       "                                         mut_y     mut_z     muf_x     muf_y  \\\n",
       "healthCode                                                                     \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0 -1.519599 -0.739240  1.983707  3.083983   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0 -1.482989 -0.726592  1.983050  2.995173   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0 -1.288581 -0.883986  1.580715  3.059265   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0 -0.939812 -0.573548  3.857549  4.052695   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0 -0.353179 -0.000325  4.181419  4.843472   \n",
       "\n",
       "                                       ...      medf_z     cross_xz  \\\n",
       "healthCode                             ...                            \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0   ...    0.282210     0.298378   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0   ...    0.284106     0.372490   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0   ...    0.478444     0.238546   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0   ...    2.647426     1.046692   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0   ...    3.211494  2245.883523   \n",
       "\n",
       "                                         cross_yz  spect_cent_x  spect_cent_y  \\\n",
       "healthCode                                                                      \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0     2.055623      0.229315      1.465557   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0     2.041019      0.087680      1.637327   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0     1.457694      0.282907      2.576500   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0     1.638592      0.613110      1.370520   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  1087.078214      0.209053      0.661385   \n",
       "\n",
       "                                      spect_cent_z  average_dist_meanx  \\\n",
       "healthCode                                                               \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0      0.832902            0.230915   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0      0.897205            0.230161   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0      0.348468            0.214125   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0      1.541681            0.274628   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0      1.787723            0.312203   \n",
       "\n",
       "                                      average_dist_meany  average_dist_meanz  \\\n",
       "healthCode                                                                     \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0            0.189005            0.264621   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0            0.202340            0.301559   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0            0.184547            0.315410   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0            0.239210            0.362077   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0            0.297326            0.382888   \n",
       "\n",
       "                                         sex  \n",
       "healthCode                                    \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  Female  \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  Female  \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  Female  \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  Female  \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  Female  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fundamental_freq</th>\n",
       "      <th>average_accel</th>\n",
       "      <th>peakcount</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mut_x</th>\n",
       "      <th>mut_y</th>\n",
       "      <th>mut_z</th>\n",
       "      <th>muf_x</th>\n",
       "      <th>muf_y</th>\n",
       "      <th>...</th>\n",
       "      <th>medf_z</th>\n",
       "      <th>cross_xz</th>\n",
       "      <th>cross_yz</th>\n",
       "      <th>spect_cent_x</th>\n",
       "      <th>spect_cent_y</th>\n",
       "      <th>spect_cent_z</th>\n",
       "      <th>average_dist_meanx</th>\n",
       "      <th>average_dist_meany</th>\n",
       "      <th>average_dist_meanz</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>84.093790</td>\n",
       "      <td>1.183311</td>\n",
       "      <td>17</td>\n",
       "      <td>1.735415</td>\n",
       "      <td>-0.093085</td>\n",
       "      <td>0.544209</td>\n",
       "      <td>-0.835330</td>\n",
       "      <td>-0.556319</td>\n",
       "      <td>1.711133</td>\n",
       "      <td>1.428328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345499</td>\n",
       "      <td>-0.978232</td>\n",
       "      <td>1.501529</td>\n",
       "      <td>0.401588</td>\n",
       "      <td>0.635471</td>\n",
       "      <td>0.261587</td>\n",
       "      <td>0.189971</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>0.219167</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>92.089151</td>\n",
       "      <td>1.342022</td>\n",
       "      <td>22</td>\n",
       "      <td>1.903300</td>\n",
       "      <td>-0.093085</td>\n",
       "      <td>0.839665</td>\n",
       "      <td>-0.898862</td>\n",
       "      <td>-0.440043</td>\n",
       "      <td>2.086170</td>\n",
       "      <td>1.598540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399225</td>\n",
       "      <td>-1.908143</td>\n",
       "      <td>2.042669</td>\n",
       "      <td>0.079886</td>\n",
       "      <td>0.668962</td>\n",
       "      <td>0.220937</td>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.070069</td>\n",
       "      <td>0.225696</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>104.641810</td>\n",
       "      <td>1.389768</td>\n",
       "      <td>21</td>\n",
       "      <td>2.007266</td>\n",
       "      <td>-0.088764</td>\n",
       "      <td>0.942869</td>\n",
       "      <td>-0.922103</td>\n",
       "      <td>-0.364584</td>\n",
       "      <td>2.173094</td>\n",
       "      <td>1.834422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400768</td>\n",
       "      <td>-2.586148</td>\n",
       "      <td>2.529189</td>\n",
       "      <td>1.086869</td>\n",
       "      <td>1.027991</td>\n",
       "      <td>0.568184</td>\n",
       "      <td>0.182744</td>\n",
       "      <td>0.078027</td>\n",
       "      <td>0.211303</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>79.819556</td>\n",
       "      <td>1.157167</td>\n",
       "      <td>19</td>\n",
       "      <td>2.007266</td>\n",
       "      <td>-0.781718</td>\n",
       "      <td>0.769605</td>\n",
       "      <td>-0.632780</td>\n",
       "      <td>-0.461603</td>\n",
       "      <td>2.016581</td>\n",
       "      <td>2.401082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201667</td>\n",
       "      <td>-1.667245</td>\n",
       "      <td>1.370832</td>\n",
       "      <td>0.607490</td>\n",
       "      <td>1.018372</td>\n",
       "      <td>0.019616</td>\n",
       "      <td>0.183512</td>\n",
       "      <td>0.128274</td>\n",
       "      <td>0.214012</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>72.891574</td>\n",
       "      <td>0.944486</td>\n",
       "      <td>17</td>\n",
       "      <td>1.329425</td>\n",
       "      <td>-0.781718</td>\n",
       "      <td>0.599926</td>\n",
       "      <td>-0.339092</td>\n",
       "      <td>-0.584421</td>\n",
       "      <td>1.330641</td>\n",
       "      <td>1.309831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291241</td>\n",
       "      <td>-1.026531</td>\n",
       "      <td>0.580219</td>\n",
       "      <td>0.715500</td>\n",
       "      <td>0.188665</td>\n",
       "      <td>0.331627</td>\n",
       "      <td>0.165407</td>\n",
       "      <td>0.136041</td>\n",
       "      <td>0.215774</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>66.836892</td>\n",
       "      <td>0.906129</td>\n",
       "      <td>14</td>\n",
       "      <td>1.276772</td>\n",
       "      <td>-0.666723</td>\n",
       "      <td>0.567256</td>\n",
       "      <td>-0.304049</td>\n",
       "      <td>-0.560532</td>\n",
       "      <td>1.236783</td>\n",
       "      <td>1.375709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192802</td>\n",
       "      <td>-1.011996</td>\n",
       "      <td>0.542428</td>\n",
       "      <td>0.214774</td>\n",
       "      <td>0.047958</td>\n",
       "      <td>0.079783</td>\n",
       "      <td>0.154599</td>\n",
       "      <td>0.144718</td>\n",
       "      <td>0.214896</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>60.719927</td>\n",
       "      <td>0.850874</td>\n",
       "      <td>13</td>\n",
       "      <td>1.276772</td>\n",
       "      <td>-0.666723</td>\n",
       "      <td>0.552406</td>\n",
       "      <td>-0.296679</td>\n",
       "      <td>-0.490727</td>\n",
       "      <td>1.277836</td>\n",
       "      <td>1.575615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546107</td>\n",
       "      <td>-1.125689</td>\n",
       "      <td>0.604570</td>\n",
       "      <td>0.264018</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.212707</td>\n",
       "      <td>0.145825</td>\n",
       "      <td>0.149558</td>\n",
       "      <td>0.212353</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>61.370547</td>\n",
       "      <td>0.831472</td>\n",
       "      <td>13</td>\n",
       "      <td>1.254676</td>\n",
       "      <td>-0.550120</td>\n",
       "      <td>0.580600</td>\n",
       "      <td>-0.250549</td>\n",
       "      <td>-0.453239</td>\n",
       "      <td>1.327007</td>\n",
       "      <td>1.598099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084389</td>\n",
       "      <td>-1.281004</td>\n",
       "      <td>0.552797</td>\n",
       "      <td>0.473761</td>\n",
       "      <td>0.030326</td>\n",
       "      <td>0.220903</td>\n",
       "      <td>0.140423</td>\n",
       "      <td>0.153129</td>\n",
       "      <td>0.207136</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>66.212932</td>\n",
       "      <td>0.831623</td>\n",
       "      <td>9</td>\n",
       "      <td>1.254676</td>\n",
       "      <td>-0.526269</td>\n",
       "      <td>0.601940</td>\n",
       "      <td>-0.178678</td>\n",
       "      <td>-0.460331</td>\n",
       "      <td>1.289884</td>\n",
       "      <td>1.665117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340095</td>\n",
       "      <td>-1.307624</td>\n",
       "      <td>0.388151</td>\n",
       "      <td>0.556822</td>\n",
       "      <td>0.106259</td>\n",
       "      <td>0.624609</td>\n",
       "      <td>0.135938</td>\n",
       "      <td>0.155627</td>\n",
       "      <td>0.203303</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>60.579467</td>\n",
       "      <td>0.815940</td>\n",
       "      <td>11</td>\n",
       "      <td>1.154157</td>\n",
       "      <td>-0.667954</td>\n",
       "      <td>0.588794</td>\n",
       "      <td>-0.176729</td>\n",
       "      <td>-0.457068</td>\n",
       "      <td>1.148517</td>\n",
       "      <td>1.491882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150211</td>\n",
       "      <td>-1.288199</td>\n",
       "      <td>0.386658</td>\n",
       "      <td>0.185172</td>\n",
       "      <td>0.123464</td>\n",
       "      <td>0.379450</td>\n",
       "      <td>0.129763</td>\n",
       "      <td>0.156769</td>\n",
       "      <td>0.201240</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>59.077575</td>\n",
       "      <td>0.817936</td>\n",
       "      <td>15</td>\n",
       "      <td>1.128464</td>\n",
       "      <td>-0.667954</td>\n",
       "      <td>0.583666</td>\n",
       "      <td>-0.220211</td>\n",
       "      <td>-0.465978</td>\n",
       "      <td>1.111319</td>\n",
       "      <td>1.302529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254868</td>\n",
       "      <td>-1.252562</td>\n",
       "      <td>0.472578</td>\n",
       "      <td>0.467362</td>\n",
       "      <td>0.184988</td>\n",
       "      <td>0.248037</td>\n",
       "      <td>0.123476</td>\n",
       "      <td>0.155946</td>\n",
       "      <td>0.198892</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>60.646997</td>\n",
       "      <td>0.820878</td>\n",
       "      <td>18</td>\n",
       "      <td>1.090094</td>\n",
       "      <td>-0.776631</td>\n",
       "      <td>0.567537</td>\n",
       "      <td>-0.219909</td>\n",
       "      <td>-0.496696</td>\n",
       "      <td>0.940857</td>\n",
       "      <td>1.216790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180884</td>\n",
       "      <td>-1.142624</td>\n",
       "      <td>0.442744</td>\n",
       "      <td>0.285164</td>\n",
       "      <td>0.018012</td>\n",
       "      <td>0.440142</td>\n",
       "      <td>0.117182</td>\n",
       "      <td>0.155380</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>54.489166</td>\n",
       "      <td>0.782678</td>\n",
       "      <td>12</td>\n",
       "      <td>1.090094</td>\n",
       "      <td>-0.776631</td>\n",
       "      <td>0.514440</td>\n",
       "      <td>-0.207049</td>\n",
       "      <td>-0.481604</td>\n",
       "      <td>0.916877</td>\n",
       "      <td>1.300558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525174</td>\n",
       "      <td>-1.068182</td>\n",
       "      <td>0.429917</td>\n",
       "      <td>0.238048</td>\n",
       "      <td>0.094047</td>\n",
       "      <td>0.231297</td>\n",
       "      <td>0.112997</td>\n",
       "      <td>0.156545</td>\n",
       "      <td>0.195434</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>52.910412</td>\n",
       "      <td>0.729400</td>\n",
       "      <td>8</td>\n",
       "      <td>1.028011</td>\n",
       "      <td>-0.703446</td>\n",
       "      <td>0.483433</td>\n",
       "      <td>-0.197842</td>\n",
       "      <td>-0.438156</td>\n",
       "      <td>0.964371</td>\n",
       "      <td>1.275265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063238</td>\n",
       "      <td>-1.103335</td>\n",
       "      <td>0.451534</td>\n",
       "      <td>0.302710</td>\n",
       "      <td>0.072282</td>\n",
       "      <td>0.178837</td>\n",
       "      <td>0.109271</td>\n",
       "      <td>0.156524</td>\n",
       "      <td>0.193544</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>57.266872</td>\n",
       "      <td>0.728959</td>\n",
       "      <td>8</td>\n",
       "      <td>1.081256</td>\n",
       "      <td>-0.823816</td>\n",
       "      <td>0.488750</td>\n",
       "      <td>-0.157379</td>\n",
       "      <td>-0.452355</td>\n",
       "      <td>0.925394</td>\n",
       "      <td>1.333243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264525</td>\n",
       "      <td>-1.080458</td>\n",
       "      <td>0.347910</td>\n",
       "      <td>0.304506</td>\n",
       "      <td>0.086258</td>\n",
       "      <td>0.551066</td>\n",
       "      <td>0.105975</td>\n",
       "      <td>0.155633</td>\n",
       "      <td>0.191828</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>50.170137</td>\n",
       "      <td>0.727835</td>\n",
       "      <td>8</td>\n",
       "      <td>1.081256</td>\n",
       "      <td>-0.839114</td>\n",
       "      <td>0.467077</td>\n",
       "      <td>-0.154210</td>\n",
       "      <td>-0.459784</td>\n",
       "      <td>0.908797</td>\n",
       "      <td>1.585312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093361</td>\n",
       "      <td>-1.015863</td>\n",
       "      <td>0.335398</td>\n",
       "      <td>0.151139</td>\n",
       "      <td>0.141883</td>\n",
       "      <td>0.227174</td>\n",
       "      <td>0.103199</td>\n",
       "      <td>0.155599</td>\n",
       "      <td>0.191978</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>52.340432</td>\n",
       "      <td>0.732129</td>\n",
       "      <td>12</td>\n",
       "      <td>1.093421</td>\n",
       "      <td>-0.839114</td>\n",
       "      <td>0.449070</td>\n",
       "      <td>-0.183110</td>\n",
       "      <td>-0.469360</td>\n",
       "      <td>0.922036</td>\n",
       "      <td>1.193293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318459</td>\n",
       "      <td>-0.956771</td>\n",
       "      <td>0.390128</td>\n",
       "      <td>0.239547</td>\n",
       "      <td>0.074789</td>\n",
       "      <td>0.281503</td>\n",
       "      <td>0.101150</td>\n",
       "      <td>0.156027</td>\n",
       "      <td>0.191443</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>56.027040</td>\n",
       "      <td>0.753457</td>\n",
       "      <td>15</td>\n",
       "      <td>1.093421</td>\n",
       "      <td>-0.792955</td>\n",
       "      <td>0.443907</td>\n",
       "      <td>-0.184973</td>\n",
       "      <td>-0.508436</td>\n",
       "      <td>0.917616</td>\n",
       "      <td>1.457874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136323</td>\n",
       "      <td>-0.873083</td>\n",
       "      <td>0.363809</td>\n",
       "      <td>0.212675</td>\n",
       "      <td>0.130208</td>\n",
       "      <td>0.357410</td>\n",
       "      <td>0.099332</td>\n",
       "      <td>0.157155</td>\n",
       "      <td>0.189383</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>49.949909</td>\n",
       "      <td>0.724066</td>\n",
       "      <td>12</td>\n",
       "      <td>1.043737</td>\n",
       "      <td>-0.841776</td>\n",
       "      <td>0.426953</td>\n",
       "      <td>-0.188452</td>\n",
       "      <td>-0.476689</td>\n",
       "      <td>0.811547</td>\n",
       "      <td>1.381015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602169</td>\n",
       "      <td>-0.895665</td>\n",
       "      <td>0.395335</td>\n",
       "      <td>0.221417</td>\n",
       "      <td>0.097678</td>\n",
       "      <td>0.257579</td>\n",
       "      <td>0.097011</td>\n",
       "      <td>0.158279</td>\n",
       "      <td>0.188860</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>51.389303</td>\n",
       "      <td>0.682249</td>\n",
       "      <td>9</td>\n",
       "      <td>1.043737</td>\n",
       "      <td>-0.841776</td>\n",
       "      <td>0.436159</td>\n",
       "      <td>-0.178748</td>\n",
       "      <td>-0.413089</td>\n",
       "      <td>0.818255</td>\n",
       "      <td>1.254024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071291</td>\n",
       "      <td>-1.055849</td>\n",
       "      <td>0.432710</td>\n",
       "      <td>0.207117</td>\n",
       "      <td>0.048559</td>\n",
       "      <td>0.149732</td>\n",
       "      <td>0.094774</td>\n",
       "      <td>0.158338</td>\n",
       "      <td>0.188561</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>52.732006</td>\n",
       "      <td>0.693535</td>\n",
       "      <td>10</td>\n",
       "      <td>0.977790</td>\n",
       "      <td>-0.806267</td>\n",
       "      <td>0.470510</td>\n",
       "      <td>-0.110734</td>\n",
       "      <td>-0.412024</td>\n",
       "      <td>0.926819</td>\n",
       "      <td>1.352405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325562</td>\n",
       "      <td>-1.141947</td>\n",
       "      <td>0.268755</td>\n",
       "      <td>0.216126</td>\n",
       "      <td>0.085050</td>\n",
       "      <td>0.557988</td>\n",
       "      <td>0.093004</td>\n",
       "      <td>0.158651</td>\n",
       "      <td>0.188337</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>47.317359</td>\n",
       "      <td>0.690296</td>\n",
       "      <td>13</td>\n",
       "      <td>0.965234</td>\n",
       "      <td>-0.817927</td>\n",
       "      <td>0.473044</td>\n",
       "      <td>-0.083274</td>\n",
       "      <td>-0.405087</td>\n",
       "      <td>1.023133</td>\n",
       "      <td>1.492721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079998</td>\n",
       "      <td>-1.167761</td>\n",
       "      <td>0.205571</td>\n",
       "      <td>0.114224</td>\n",
       "      <td>0.079382</td>\n",
       "      <td>0.181422</td>\n",
       "      <td>0.091857</td>\n",
       "      <td>0.159138</td>\n",
       "      <td>0.188416</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>47.524138</td>\n",
       "      <td>0.677049</td>\n",
       "      <td>14</td>\n",
       "      <td>0.984435</td>\n",
       "      <td>-0.817927</td>\n",
       "      <td>0.443769</td>\n",
       "      <td>-0.127068</td>\n",
       "      <td>-0.410505</td>\n",
       "      <td>0.975527</td>\n",
       "      <td>1.161857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232476</td>\n",
       "      <td>-1.081033</td>\n",
       "      <td>0.309542</td>\n",
       "      <td>0.250347</td>\n",
       "      <td>0.047741</td>\n",
       "      <td>0.199895</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.159051</td>\n",
       "      <td>0.187830</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>50.222342</td>\n",
       "      <td>0.693170</td>\n",
       "      <td>12</td>\n",
       "      <td>1.009179</td>\n",
       "      <td>-0.753237</td>\n",
       "      <td>0.417634</td>\n",
       "      <td>-0.112645</td>\n",
       "      <td>-0.461099</td>\n",
       "      <td>0.953749</td>\n",
       "      <td>1.378508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114812</td>\n",
       "      <td>-0.905737</td>\n",
       "      <td>0.244297</td>\n",
       "      <td>0.225142</td>\n",
       "      <td>0.087129</td>\n",
       "      <td>0.188352</td>\n",
       "      <td>0.090826</td>\n",
       "      <td>0.159677</td>\n",
       "      <td>0.186687</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>47.562180</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>16</td>\n",
       "      <td>1.009179</td>\n",
       "      <td>-0.879924</td>\n",
       "      <td>0.412683</td>\n",
       "      <td>-0.096128</td>\n",
       "      <td>-0.440835</td>\n",
       "      <td>0.919188</td>\n",
       "      <td>1.372138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447942</td>\n",
       "      <td>-0.936138</td>\n",
       "      <td>0.218059</td>\n",
       "      <td>0.223929</td>\n",
       "      <td>0.139713</td>\n",
       "      <td>0.210784</td>\n",
       "      <td>0.090084</td>\n",
       "      <td>0.160999</td>\n",
       "      <td>0.186059</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>48.086073</td>\n",
       "      <td>0.652171</td>\n",
       "      <td>13</td>\n",
       "      <td>0.928534</td>\n",
       "      <td>-0.974157</td>\n",
       "      <td>0.424066</td>\n",
       "      <td>-0.106277</td>\n",
       "      <td>-0.392351</td>\n",
       "      <td>0.985433</td>\n",
       "      <td>1.305142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223360</td>\n",
       "      <td>-1.080833</td>\n",
       "      <td>0.270873</td>\n",
       "      <td>0.262044</td>\n",
       "      <td>0.051334</td>\n",
       "      <td>0.082530</td>\n",
       "      <td>0.089379</td>\n",
       "      <td>0.161034</td>\n",
       "      <td>0.186297</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>53.161722</td>\n",
       "      <td>0.655214</td>\n",
       "      <td>11</td>\n",
       "      <td>0.981923</td>\n",
       "      <td>-0.974157</td>\n",
       "      <td>0.428843</td>\n",
       "      <td>-0.068646</td>\n",
       "      <td>-0.403066</td>\n",
       "      <td>0.891935</td>\n",
       "      <td>1.289719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165922</td>\n",
       "      <td>-1.063952</td>\n",
       "      <td>0.170308</td>\n",
       "      <td>0.292010</td>\n",
       "      <td>0.064838</td>\n",
       "      <td>0.321055</td>\n",
       "      <td>0.088590</td>\n",
       "      <td>0.160524</td>\n",
       "      <td>0.186907</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>47.851912</td>\n",
       "      <td>0.663243</td>\n",
       "      <td>14</td>\n",
       "      <td>0.981923</td>\n",
       "      <td>-0.846179</td>\n",
       "      <td>0.427271</td>\n",
       "      <td>-0.063014</td>\n",
       "      <td>-0.412555</td>\n",
       "      <td>0.888985</td>\n",
       "      <td>1.505170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118265</td>\n",
       "      <td>-1.035671</td>\n",
       "      <td>0.152741</td>\n",
       "      <td>0.081480</td>\n",
       "      <td>0.075957</td>\n",
       "      <td>0.337841</td>\n",
       "      <td>0.087782</td>\n",
       "      <td>0.160868</td>\n",
       "      <td>0.186899</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>47.062869</td>\n",
       "      <td>0.653979</td>\n",
       "      <td>13</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>-0.879855</td>\n",
       "      <td>0.414558</td>\n",
       "      <td>-0.109252</td>\n",
       "      <td>-0.419064</td>\n",
       "      <td>0.916248</td>\n",
       "      <td>1.151151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216568</td>\n",
       "      <td>-0.989248</td>\n",
       "      <td>0.260706</td>\n",
       "      <td>0.292007</td>\n",
       "      <td>0.045208</td>\n",
       "      <td>0.205164</td>\n",
       "      <td>0.087120</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.185676</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>48.359012</td>\n",
       "      <td>0.666127</td>\n",
       "      <td>11</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>-0.916209</td>\n",
       "      <td>0.401627</td>\n",
       "      <td>-0.105635</td>\n",
       "      <td>-0.447256</td>\n",
       "      <td>0.897409</td>\n",
       "      <td>1.341643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132778</td>\n",
       "      <td>-0.897979</td>\n",
       "      <td>0.236184</td>\n",
       "      <td>0.139868</td>\n",
       "      <td>0.047521</td>\n",
       "      <td>0.196802</td>\n",
       "      <td>0.086639</td>\n",
       "      <td>0.161122</td>\n",
       "      <td>0.184212</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>33.699412</td>\n",
       "      <td>0.394525</td>\n",
       "      <td>4</td>\n",
       "      <td>2.488131</td>\n",
       "      <td>-4.740152</td>\n",
       "      <td>-0.000945</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.018906</td>\n",
       "      <td>2.201475</td>\n",
       "      <td>2.853616</td>\n",
       "      <td>...</td>\n",
       "      <td>1.349337</td>\n",
       "      <td>-0.050001</td>\n",
       "      <td>1.409520</td>\n",
       "      <td>0.060396</td>\n",
       "      <td>0.090188</td>\n",
       "      <td>0.086844</td>\n",
       "      <td>0.176555</td>\n",
       "      <td>0.270928</td>\n",
       "      <td>0.195683</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>41.092642</td>\n",
       "      <td>0.426695</td>\n",
       "      <td>5</td>\n",
       "      <td>2.553589</td>\n",
       "      <td>-4.605173</td>\n",
       "      <td>0.023754</td>\n",
       "      <td>0.024253</td>\n",
       "      <td>0.011580</td>\n",
       "      <td>2.444617</td>\n",
       "      <td>3.040302</td>\n",
       "      <td>...</td>\n",
       "      <td>1.424939</td>\n",
       "      <td>2.051249</td>\n",
       "      <td>2.094354</td>\n",
       "      <td>0.032865</td>\n",
       "      <td>0.070991</td>\n",
       "      <td>0.046991</td>\n",
       "      <td>0.176612</td>\n",
       "      <td>0.270914</td>\n",
       "      <td>0.195651</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>39.844115</td>\n",
       "      <td>0.441173</td>\n",
       "      <td>5</td>\n",
       "      <td>2.553589</td>\n",
       "      <td>-3.488670</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>0.046437</td>\n",
       "      <td>0.048633</td>\n",
       "      <td>2.228174</td>\n",
       "      <td>3.038582</td>\n",
       "      <td>...</td>\n",
       "      <td>1.823158</td>\n",
       "      <td>0.507656</td>\n",
       "      <td>0.954833</td>\n",
       "      <td>0.090202</td>\n",
       "      <td>0.163323</td>\n",
       "      <td>0.065669</td>\n",
       "      <td>0.176631</td>\n",
       "      <td>0.270953</td>\n",
       "      <td>0.195694</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>33.990233</td>\n",
       "      <td>0.381190</td>\n",
       "      <td>3</td>\n",
       "      <td>2.456892</td>\n",
       "      <td>-3.488670</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.042064</td>\n",
       "      <td>0.042018</td>\n",
       "      <td>2.194068</td>\n",
       "      <td>3.174564</td>\n",
       "      <td>...</td>\n",
       "      <td>1.538098</td>\n",
       "      <td>0.202440</td>\n",
       "      <td>1.001080</td>\n",
       "      <td>0.065904</td>\n",
       "      <td>0.421853</td>\n",
       "      <td>0.153407</td>\n",
       "      <td>0.176540</td>\n",
       "      <td>0.270885</td>\n",
       "      <td>0.195670</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>36.596536</td>\n",
       "      <td>0.351145</td>\n",
       "      <td>6</td>\n",
       "      <td>2.256753</td>\n",
       "      <td>-3.753878</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.047136</td>\n",
       "      <td>-0.008704</td>\n",
       "      <td>1.982170</td>\n",
       "      <td>2.458227</td>\n",
       "      <td>...</td>\n",
       "      <td>1.996064</td>\n",
       "      <td>-1.000267</td>\n",
       "      <td>-5.415576</td>\n",
       "      <td>0.021555</td>\n",
       "      <td>0.066779</td>\n",
       "      <td>0.097862</td>\n",
       "      <td>0.176476</td>\n",
       "      <td>0.270659</td>\n",
       "      <td>0.195627</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>46.962502</td>\n",
       "      <td>0.399457</td>\n",
       "      <td>6</td>\n",
       "      <td>3.179257</td>\n",
       "      <td>-3.753878</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.057871</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>2.865049</td>\n",
       "      <td>3.056349</td>\n",
       "      <td>...</td>\n",
       "      <td>2.249411</td>\n",
       "      <td>0.605059</td>\n",
       "      <td>2.495986</td>\n",
       "      <td>0.195102</td>\n",
       "      <td>0.134399</td>\n",
       "      <td>0.081127</td>\n",
       "      <td>0.176452</td>\n",
       "      <td>0.270530</td>\n",
       "      <td>0.195676</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>42.504275</td>\n",
       "      <td>0.483105</td>\n",
       "      <td>5</td>\n",
       "      <td>3.179257</td>\n",
       "      <td>-3.312276</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.031497</td>\n",
       "      <td>0.012761</td>\n",
       "      <td>2.412987</td>\n",
       "      <td>3.478398</td>\n",
       "      <td>...</td>\n",
       "      <td>2.028575</td>\n",
       "      <td>0.293017</td>\n",
       "      <td>2.468202</td>\n",
       "      <td>0.123892</td>\n",
       "      <td>0.460889</td>\n",
       "      <td>0.430166</td>\n",
       "      <td>0.176563</td>\n",
       "      <td>0.270572</td>\n",
       "      <td>0.195783</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>44.011560</td>\n",
       "      <td>0.523093</td>\n",
       "      <td>7</td>\n",
       "      <td>2.874730</td>\n",
       "      <td>-2.809744</td>\n",
       "      <td>0.030977</td>\n",
       "      <td>0.020090</td>\n",
       "      <td>-0.005138</td>\n",
       "      <td>2.601326</td>\n",
       "      <td>3.438861</td>\n",
       "      <td>...</td>\n",
       "      <td>2.278638</td>\n",
       "      <td>-6.029174</td>\n",
       "      <td>-3.910174</td>\n",
       "      <td>0.064946</td>\n",
       "      <td>0.081196</td>\n",
       "      <td>0.084503</td>\n",
       "      <td>0.176798</td>\n",
       "      <td>0.270627</td>\n",
       "      <td>0.195907</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>40.760349</td>\n",
       "      <td>0.478213</td>\n",
       "      <td>7</td>\n",
       "      <td>2.449592</td>\n",
       "      <td>-2.805747</td>\n",
       "      <td>0.024132</td>\n",
       "      <td>0.051986</td>\n",
       "      <td>0.056283</td>\n",
       "      <td>2.393157</td>\n",
       "      <td>3.091913</td>\n",
       "      <td>...</td>\n",
       "      <td>2.704538</td>\n",
       "      <td>0.428764</td>\n",
       "      <td>0.923661</td>\n",
       "      <td>0.206964</td>\n",
       "      <td>0.177844</td>\n",
       "      <td>0.298659</td>\n",
       "      <td>0.176897</td>\n",
       "      <td>0.270645</td>\n",
       "      <td>0.196057</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>34.206680</td>\n",
       "      <td>0.386189</td>\n",
       "      <td>4</td>\n",
       "      <td>2.034640</td>\n",
       "      <td>-3.463871</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.044637</td>\n",
       "      <td>0.022708</td>\n",
       "      <td>1.893155</td>\n",
       "      <td>2.868716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.957451</td>\n",
       "      <td>0.193689</td>\n",
       "      <td>1.965734</td>\n",
       "      <td>0.033526</td>\n",
       "      <td>0.214497</td>\n",
       "      <td>0.135096</td>\n",
       "      <td>0.176834</td>\n",
       "      <td>0.270527</td>\n",
       "      <td>0.196081</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>33.121097</td>\n",
       "      <td>0.331535</td>\n",
       "      <td>4</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>-3.686302</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>0.048679</td>\n",
       "      <td>-0.021680</td>\n",
       "      <td>1.758883</td>\n",
       "      <td>2.096453</td>\n",
       "      <td>...</td>\n",
       "      <td>1.101897</td>\n",
       "      <td>-0.786310</td>\n",
       "      <td>-2.245372</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0.014297</td>\n",
       "      <td>0.176741</td>\n",
       "      <td>0.270250</td>\n",
       "      <td>0.196026</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>42.131904</td>\n",
       "      <td>0.387436</td>\n",
       "      <td>5</td>\n",
       "      <td>2.340950</td>\n",
       "      <td>-3.686302</td>\n",
       "      <td>-0.002789</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>0.012354</td>\n",
       "      <td>2.512638</td>\n",
       "      <td>3.057120</td>\n",
       "      <td>...</td>\n",
       "      <td>2.047413</td>\n",
       "      <td>-0.225721</td>\n",
       "      <td>4.744701</td>\n",
       "      <td>0.130985</td>\n",
       "      <td>0.156075</td>\n",
       "      <td>0.107059</td>\n",
       "      <td>0.176718</td>\n",
       "      <td>0.270115</td>\n",
       "      <td>0.196026</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>35.837287</td>\n",
       "      <td>0.423619</td>\n",
       "      <td>5</td>\n",
       "      <td>2.946559</td>\n",
       "      <td>-4.821471</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>0.025583</td>\n",
       "      <td>0.026002</td>\n",
       "      <td>2.520030</td>\n",
       "      <td>3.255887</td>\n",
       "      <td>...</td>\n",
       "      <td>2.140077</td>\n",
       "      <td>-0.068661</td>\n",
       "      <td>0.983882</td>\n",
       "      <td>0.049802</td>\n",
       "      <td>0.172835</td>\n",
       "      <td>0.020812</td>\n",
       "      <td>0.176716</td>\n",
       "      <td>0.270117</td>\n",
       "      <td>0.196030</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>44.604078</td>\n",
       "      <td>0.450639</td>\n",
       "      <td>6</td>\n",
       "      <td>2.946559</td>\n",
       "      <td>-4.821471</td>\n",
       "      <td>0.025081</td>\n",
       "      <td>0.029632</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>2.571582</td>\n",
       "      <td>3.331263</td>\n",
       "      <td>...</td>\n",
       "      <td>2.457532</td>\n",
       "      <td>2.612058</td>\n",
       "      <td>3.086060</td>\n",
       "      <td>0.027734</td>\n",
       "      <td>0.040254</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>0.176784</td>\n",
       "      <td>0.270142</td>\n",
       "      <td>0.196064</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>38.768165</td>\n",
       "      <td>0.450894</td>\n",
       "      <td>8</td>\n",
       "      <td>2.479426</td>\n",
       "      <td>-2.544354</td>\n",
       "      <td>0.027490</td>\n",
       "      <td>0.049789</td>\n",
       "      <td>0.033054</td>\n",
       "      <td>2.303296</td>\n",
       "      <td>3.019905</td>\n",
       "      <td>...</td>\n",
       "      <td>1.954176</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>1.506296</td>\n",
       "      <td>0.151709</td>\n",
       "      <td>0.070110</td>\n",
       "      <td>0.197753</td>\n",
       "      <td>0.176865</td>\n",
       "      <td>0.270140</td>\n",
       "      <td>0.196128</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>38.400170</td>\n",
       "      <td>0.402072</td>\n",
       "      <td>6</td>\n",
       "      <td>2.296475</td>\n",
       "      <td>-3.080866</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.050558</td>\n",
       "      <td>0.044784</td>\n",
       "      <td>2.307597</td>\n",
       "      <td>2.790476</td>\n",
       "      <td>...</td>\n",
       "      <td>1.898310</td>\n",
       "      <td>0.156283</td>\n",
       "      <td>1.128940</td>\n",
       "      <td>0.141662</td>\n",
       "      <td>0.412233</td>\n",
       "      <td>0.141182</td>\n",
       "      <td>0.176873</td>\n",
       "      <td>0.270060</td>\n",
       "      <td>0.196115</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>37.907620</td>\n",
       "      <td>0.373443</td>\n",
       "      <td>7</td>\n",
       "      <td>2.296475</td>\n",
       "      <td>-3.685416</td>\n",
       "      <td>0.043849</td>\n",
       "      <td>0.027390</td>\n",
       "      <td>-0.000979</td>\n",
       "      <td>2.134161</td>\n",
       "      <td>2.584280</td>\n",
       "      <td>...</td>\n",
       "      <td>1.767748</td>\n",
       "      <td>-44.786502</td>\n",
       "      <td>-27.975977</td>\n",
       "      <td>0.010990</td>\n",
       "      <td>0.072177</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>0.176878</td>\n",
       "      <td>0.269877</td>\n",
       "      <td>0.196059</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>43.837148</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>8</td>\n",
       "      <td>2.093182</td>\n",
       "      <td>-3.685416</td>\n",
       "      <td>0.058329</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>0.020193</td>\n",
       "      <td>2.346901</td>\n",
       "      <td>2.551869</td>\n",
       "      <td>...</td>\n",
       "      <td>1.338291</td>\n",
       "      <td>2.888614</td>\n",
       "      <td>2.157031</td>\n",
       "      <td>0.103010</td>\n",
       "      <td>0.081799</td>\n",
       "      <td>0.079521</td>\n",
       "      <td>0.176909</td>\n",
       "      <td>0.269724</td>\n",
       "      <td>0.196025</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>35.613878</td>\n",
       "      <td>0.403518</td>\n",
       "      <td>6</td>\n",
       "      <td>2.601856</td>\n",
       "      <td>-3.605283</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>0.046148</td>\n",
       "      <td>0.039193</td>\n",
       "      <td>1.945042</td>\n",
       "      <td>3.280692</td>\n",
       "      <td>...</td>\n",
       "      <td>1.423864</td>\n",
       "      <td>0.097612</td>\n",
       "      <td>1.177461</td>\n",
       "      <td>0.060015</td>\n",
       "      <td>0.163271</td>\n",
       "      <td>0.041792</td>\n",
       "      <td>0.176881</td>\n",
       "      <td>0.269703</td>\n",
       "      <td>0.195995</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>38.432927</td>\n",
       "      <td>0.433664</td>\n",
       "      <td>4</td>\n",
       "      <td>3.099438</td>\n",
       "      <td>-3.605283</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>2.383460</td>\n",
       "      <td>3.544895</td>\n",
       "      <td>...</td>\n",
       "      <td>1.749727</td>\n",
       "      <td>0.442626</td>\n",
       "      <td>0.585848</td>\n",
       "      <td>0.037062</td>\n",
       "      <td>0.036308</td>\n",
       "      <td>0.067015</td>\n",
       "      <td>0.176874</td>\n",
       "      <td>0.269750</td>\n",
       "      <td>0.195981</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>45.038068</td>\n",
       "      <td>0.506678</td>\n",
       "      <td>5</td>\n",
       "      <td>3.156926</td>\n",
       "      <td>-2.732547</td>\n",
       "      <td>0.036037</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.033509</td>\n",
       "      <td>2.596333</td>\n",
       "      <td>3.866258</td>\n",
       "      <td>...</td>\n",
       "      <td>2.602581</td>\n",
       "      <td>1.075424</td>\n",
       "      <td>1.006128</td>\n",
       "      <td>0.092786</td>\n",
       "      <td>0.085866</td>\n",
       "      <td>0.354102</td>\n",
       "      <td>0.176939</td>\n",
       "      <td>0.269931</td>\n",
       "      <td>0.196098</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>47.077936</td>\n",
       "      <td>0.514612</td>\n",
       "      <td>5</td>\n",
       "      <td>3.504014</td>\n",
       "      <td>-2.931715</td>\n",
       "      <td>0.036455</td>\n",
       "      <td>0.054035</td>\n",
       "      <td>0.040633</td>\n",
       "      <td>2.569577</td>\n",
       "      <td>3.968068</td>\n",
       "      <td>...</td>\n",
       "      <td>3.372458</td>\n",
       "      <td>0.897183</td>\n",
       "      <td>1.329817</td>\n",
       "      <td>0.135340</td>\n",
       "      <td>0.242441</td>\n",
       "      <td>0.373736</td>\n",
       "      <td>0.177003</td>\n",
       "      <td>0.270140</td>\n",
       "      <td>0.196198</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>42.204691</td>\n",
       "      <td>0.461851</td>\n",
       "      <td>3</td>\n",
       "      <td>3.504014</td>\n",
       "      <td>-2.931715</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>0.055554</td>\n",
       "      <td>0.057810</td>\n",
       "      <td>2.471465</td>\n",
       "      <td>3.920354</td>\n",
       "      <td>...</td>\n",
       "      <td>2.169439</td>\n",
       "      <td>0.203499</td>\n",
       "      <td>0.960981</td>\n",
       "      <td>0.137618</td>\n",
       "      <td>0.543534</td>\n",
       "      <td>0.081059</td>\n",
       "      <td>0.177006</td>\n",
       "      <td>0.270260</td>\n",
       "      <td>0.196207</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>35.286031</td>\n",
       "      <td>0.391984</td>\n",
       "      <td>3</td>\n",
       "      <td>3.038900</td>\n",
       "      <td>-2.727730</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>0.010647</td>\n",
       "      <td>0.024240</td>\n",
       "      <td>1.808518</td>\n",
       "      <td>3.115942</td>\n",
       "      <td>...</td>\n",
       "      <td>1.992673</td>\n",
       "      <td>0.718040</td>\n",
       "      <td>0.439226</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.134739</td>\n",
       "      <td>0.068655</td>\n",
       "      <td>0.176909</td>\n",
       "      <td>0.270229</td>\n",
       "      <td>0.196146</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>44.773859</td>\n",
       "      <td>0.403493</td>\n",
       "      <td>3</td>\n",
       "      <td>3.591787</td>\n",
       "      <td>-2.727730</td>\n",
       "      <td>0.038813</td>\n",
       "      <td>0.037128</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>2.368200</td>\n",
       "      <td>3.426757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.054065</td>\n",
       "      <td>4.526310</td>\n",
       "      <td>4.329802</td>\n",
       "      <td>0.108537</td>\n",
       "      <td>0.202708</td>\n",
       "      <td>0.029745</td>\n",
       "      <td>0.176882</td>\n",
       "      <td>0.270191</td>\n",
       "      <td>0.196112</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>54.725356</td>\n",
       "      <td>0.476077</td>\n",
       "      <td>4</td>\n",
       "      <td>3.631156</td>\n",
       "      <td>-2.773240</td>\n",
       "      <td>0.029824</td>\n",
       "      <td>0.093349</td>\n",
       "      <td>0.033430</td>\n",
       "      <td>2.328272</td>\n",
       "      <td>3.838714</td>\n",
       "      <td>...</td>\n",
       "      <td>3.001195</td>\n",
       "      <td>0.892145</td>\n",
       "      <td>2.792374</td>\n",
       "      <td>0.139531</td>\n",
       "      <td>0.580975</td>\n",
       "      <td>0.204056</td>\n",
       "      <td>0.176971</td>\n",
       "      <td>0.270296</td>\n",
       "      <td>0.196161</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>44.990705</td>\n",
       "      <td>0.482222</td>\n",
       "      <td>5</td>\n",
       "      <td>3.631156</td>\n",
       "      <td>-2.902449</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>0.045467</td>\n",
       "      <td>0.020995</td>\n",
       "      <td>2.484590</td>\n",
       "      <td>4.231413</td>\n",
       "      <td>...</td>\n",
       "      <td>2.279981</td>\n",
       "      <td>0.738450</td>\n",
       "      <td>2.165646</td>\n",
       "      <td>0.109443</td>\n",
       "      <td>0.435058</td>\n",
       "      <td>0.394613</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.270468</td>\n",
       "      <td>0.196197</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>45.635983</td>\n",
       "      <td>0.483523</td>\n",
       "      <td>5</td>\n",
       "      <td>3.346397</td>\n",
       "      <td>-4.063206</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>2.591126</td>\n",
       "      <td>4.092937</td>\n",
       "      <td>...</td>\n",
       "      <td>2.140551</td>\n",
       "      <td>2.471754</td>\n",
       "      <td>0.621104</td>\n",
       "      <td>0.057675</td>\n",
       "      <td>0.032472</td>\n",
       "      <td>0.248053</td>\n",
       "      <td>0.176982</td>\n",
       "      <td>0.270639</td>\n",
       "      <td>0.196220</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>47.204448</td>\n",
       "      <td>0.516681</td>\n",
       "      <td>4</td>\n",
       "      <td>3.556607</td>\n",
       "      <td>-4.063206</td>\n",
       "      <td>0.038955</td>\n",
       "      <td>0.022661</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>2.612172</td>\n",
       "      <td>4.130016</td>\n",
       "      <td>...</td>\n",
       "      <td>2.342015</td>\n",
       "      <td>1.389024</td>\n",
       "      <td>0.808022</td>\n",
       "      <td>0.060645</td>\n",
       "      <td>0.051170</td>\n",
       "      <td>0.260613</td>\n",
       "      <td>0.177037</td>\n",
       "      <td>0.270865</td>\n",
       "      <td>0.196286</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>42.683070</td>\n",
       "      <td>0.513878</td>\n",
       "      <td>4</td>\n",
       "      <td>3.556607</td>\n",
       "      <td>-2.874092</td>\n",
       "      <td>0.043061</td>\n",
       "      <td>0.049850</td>\n",
       "      <td>0.044573</td>\n",
       "      <td>2.478109</td>\n",
       "      <td>4.003384</td>\n",
       "      <td>...</td>\n",
       "      <td>2.310064</td>\n",
       "      <td>0.966067</td>\n",
       "      <td>1.118379</td>\n",
       "      <td>0.027444</td>\n",
       "      <td>0.249147</td>\n",
       "      <td>0.086739</td>\n",
       "      <td>0.177081</td>\n",
       "      <td>0.271091</td>\n",
       "      <td>0.196358</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19008 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fundamental_freq  average_accel  \\\n",
       "healthCode                                                              \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         84.093790       1.183311   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         92.089151       1.342022   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149        104.641810       1.389768   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         79.819556       1.157167   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         72.891574       0.944486   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         66.836892       0.906129   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         60.719927       0.850874   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         61.370547       0.831472   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         66.212932       0.831623   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         60.579467       0.815940   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         59.077575       0.817936   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         60.646997       0.820878   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         54.489166       0.782678   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         52.910412       0.729400   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         57.266872       0.728959   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         50.170137       0.727835   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         52.340432       0.732129   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         56.027040       0.753457   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         49.949909       0.724066   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         51.389303       0.682249   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         52.732006       0.693535   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         47.317359       0.690296   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         47.524138       0.677049   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         50.222342       0.693170   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         47.562180       0.680756   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         48.086073       0.652171   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         53.161722       0.655214   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         47.851912       0.663243   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         47.062869       0.653979   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         48.359012       0.666127   \n",
       "...                                                ...            ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         33.699412       0.394525   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         41.092642       0.426695   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         39.844115       0.441173   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         33.990233       0.381190   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         36.596536       0.351145   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         46.962502       0.399457   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         42.504275       0.483105   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         44.011560       0.523093   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         40.760349       0.478213   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         34.206680       0.386189   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         33.121097       0.331535   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         42.131904       0.387436   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         35.837287       0.423619   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         44.604078       0.450639   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         38.768165       0.450894   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         38.400170       0.402072   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         37.907620       0.373443   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         43.837148       0.387100   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         35.613878       0.403518   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         38.432927       0.433664   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         45.038068       0.506678   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         47.077936       0.514612   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         42.204691       0.461851   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         35.286031       0.391984   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         44.773859       0.403493   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         54.725356       0.476077   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         44.990705       0.482222   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         45.635983       0.483523   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         47.204448       0.516681   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         42.683070       0.513878   \n",
       "\n",
       "                                      peakcount       max       min     mut_x  \\\n",
       "healthCode                                                                      \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         17  1.735415 -0.093085  0.544209   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         22  1.903300 -0.093085  0.839665   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         21  2.007266 -0.088764  0.942869   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         19  2.007266 -0.781718  0.769605   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         17  1.329425 -0.781718  0.599926   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         14  1.276772 -0.666723  0.567256   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         13  1.276772 -0.666723  0.552406   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         13  1.254676 -0.550120  0.580600   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149          9  1.254676 -0.526269  0.601940   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         11  1.154157 -0.667954  0.588794   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         15  1.128464 -0.667954  0.583666   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         18  1.090094 -0.776631  0.567537   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         12  1.090094 -0.776631  0.514440   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149          8  1.028011 -0.703446  0.483433   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149          8  1.081256 -0.823816  0.488750   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149          8  1.081256 -0.839114  0.467077   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         12  1.093421 -0.839114  0.449070   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         15  1.093421 -0.792955  0.443907   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         12  1.043737 -0.841776  0.426953   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149          9  1.043737 -0.841776  0.436159   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         10  0.977790 -0.806267  0.470510   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         13  0.965234 -0.817927  0.473044   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         14  0.984435 -0.817927  0.443769   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         12  1.009179 -0.753237  0.417634   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         16  1.009179 -0.879924  0.412683   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         13  0.928534 -0.974157  0.424066   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         11  0.981923 -0.974157  0.428843   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         14  0.981923 -0.846179  0.427271   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         13  0.996672 -0.879855  0.414558   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         11  0.996672 -0.916209  0.401627   \n",
       "...                                         ...       ...       ...       ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  2.488131 -4.740152 -0.000945   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  2.553589 -4.605173  0.023754   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  2.553589 -3.488670  0.024689   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          3  2.456892 -3.488670  0.008506   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          6  2.256753 -3.753878  0.008706   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          6  3.179257 -3.753878  0.014029   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  3.179257 -3.312276  0.003739   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          7  2.874730 -2.809744  0.030977   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          7  2.449592 -2.805747  0.024132   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  2.034640 -3.463871  0.004398   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  2.153820 -3.686302  0.017047   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  2.340950 -3.686302 -0.002789   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  2.946559 -4.821471 -0.001785   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          6  2.946559 -4.821471  0.025081   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          8  2.479426 -2.544354  0.027490   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          6  2.296475 -3.080866  0.006999   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          7  2.296475 -3.685416  0.043849   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          8  2.093182 -3.685416  0.058329   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          6  2.601856 -3.605283  0.003826   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  3.099438 -3.605283  0.010333   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  3.156926 -2.732547  0.036037   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  3.504014 -2.931715  0.036455   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          3  3.504014 -2.931715  0.011764   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          3  3.038900 -2.727730  0.017405   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          3  3.591787 -2.727730  0.038813   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  3.631156 -2.773240  0.029824   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  3.631156 -2.902449  0.015503   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  3.346397 -4.063206  0.025547   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  3.556607 -4.063206  0.038955   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  3.556607 -2.874092  0.043061   \n",
       "\n",
       "                                         mut_y     mut_z     muf_x     muf_y  \\\n",
       "healthCode                                                                     \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.835330 -0.556319  1.711133  1.428328   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.898862 -0.440043  2.086170  1.598540   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.922103 -0.364584  2.173094  1.834422   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.632780 -0.461603  2.016581  2.401082   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.339092 -0.584421  1.330641  1.309831   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.304049 -0.560532  1.236783  1.375709   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.296679 -0.490727  1.277836  1.575615   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.250549 -0.453239  1.327007  1.598099   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.178678 -0.460331  1.289884  1.665117   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.176729 -0.457068  1.148517  1.491882   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.220211 -0.465978  1.111319  1.302529   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.219909 -0.496696  0.940857  1.216790   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.207049 -0.481604  0.916877  1.300558   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.197842 -0.438156  0.964371  1.275265   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.157379 -0.452355  0.925394  1.333243   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.154210 -0.459784  0.908797  1.585312   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.183110 -0.469360  0.922036  1.193293   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.184973 -0.508436  0.917616  1.457874   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.188452 -0.476689  0.811547  1.381015   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.178748 -0.413089  0.818255  1.254024   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.110734 -0.412024  0.926819  1.352405   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.083274 -0.405087  1.023133  1.492721   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.127068 -0.410505  0.975527  1.161857   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.112645 -0.461099  0.953749  1.378508   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.096128 -0.440835  0.919188  1.372138   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.106277 -0.392351  0.985433  1.305142   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.068646 -0.403066  0.891935  1.289719   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.063014 -0.412555  0.888985  1.505170   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.109252 -0.419064  0.916248  1.151151   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.105635 -0.447256  0.897409  1.341643   \n",
       "...                                        ...       ...       ...       ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.026649  0.018906  2.201475  2.853616   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.024253  0.011580  2.444617  3.040302   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.046437  0.048633  2.228174  3.038582   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.042064  0.042018  2.194068  3.174564   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.047136 -0.008704  1.982170  2.458227   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.057871  0.023185  2.865049  3.056349   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.031497  0.012761  2.412987  3.478398   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.020090 -0.005138  2.601326  3.438861   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.051986  0.056283  2.393157  3.091913   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.044637  0.022708  1.893155  2.868716   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.048679 -0.021680  1.758883  2.096453   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.058617  0.012354  2.512638  3.057120   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.025583  0.026002  2.520030  3.255887   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.029632  0.009602  2.571582  3.331263   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.049789  0.033054  2.303296  3.019905   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.050558  0.044784  2.307597  2.790476   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.027390 -0.000979  2.134161  2.584280   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.043556  0.020193  2.346901  2.551869   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.046148  0.039193  1.945042  3.280692   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.013677  0.023345  2.383460  3.544895   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.033715  0.033509  2.596333  3.866258   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.054035  0.040633  2.569577  3.968068   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.055554  0.057810  2.471465  3.920354   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.010647  0.024240  1.808518  3.115942   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.037128  0.008575  2.368200  3.426757   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.093349  0.033430  2.328272  3.838714   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.045467  0.020995  2.484590  4.231413   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.006419  0.010335  2.591126  4.092937   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.022661  0.028045  2.612172  4.130016   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.049850  0.044573  2.478109  4.003384   \n",
       "\n",
       "                                      ...     medf_z   cross_xz   cross_yz  \\\n",
       "healthCode                            ...                                    \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.345499  -0.978232   1.501529   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.399225  -1.908143   2.042669   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.400768  -2.586148   2.529189   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.201667  -1.667245   1.370832   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.291241  -1.026531   0.580219   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.192802  -1.011996   0.542428   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.546107  -1.125689   0.604570   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.084389  -1.281004   0.552797   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.340095  -1.307624   0.388151   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.150211  -1.288199   0.386658   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.254868  -1.252562   0.472578   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.180884  -1.142624   0.442744   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.525174  -1.068182   0.429917   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.063238  -1.103335   0.451534   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.264525  -1.080458   0.347910   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.093361  -1.015863   0.335398   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.318459  -0.956771   0.390128   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.136323  -0.873083   0.363809   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.602169  -0.895665   0.395335   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.071291  -1.055849   0.432710   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.325562  -1.141947   0.268755   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.079998  -1.167761   0.205571   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.232476  -1.081033   0.309542   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.114812  -0.905737   0.244297   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.447942  -0.936138   0.218059   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.223360  -1.080833   0.270873   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.165922  -1.063952   0.170308   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.118265  -1.035671   0.152741   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.216568  -0.989248   0.260706   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.132778  -0.897979   0.236184   \n",
       "...                                   ...        ...        ...        ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.349337  -0.050001   1.409520   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.424939   2.051249   2.094354   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.823158   0.507656   0.954833   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.538098   0.202440   1.001080   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.996064  -1.000267  -5.415576   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.249411   0.605059   2.495986   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.028575   0.293017   2.468202   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.278638  -6.029174  -3.910174   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.704538   0.428764   0.923661   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.957451   0.193689   1.965734   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.101897  -0.786310  -2.245372   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.047413  -0.225721   4.744701   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.140077  -0.068661   0.983882   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.457532   2.612058   3.086060   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.954176   0.831683   1.506296   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.898310   0.156283   1.128940   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.767748 -44.786502 -27.975977   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.338291   2.888614   2.157031   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.423864   0.097612   1.177461   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.749727   0.442626   0.585848   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.602581   1.075424   1.006128   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   3.372458   0.897183   1.329817   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.169439   0.203499   0.960981   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.992673   0.718040   0.439226   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.054065   4.526310   4.329802   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   3.001195   0.892145   2.792374   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.279981   0.738450   2.165646   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.140551   2.471754   0.621104   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.342015   1.389024   0.808022   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.310064   0.966067   1.118379   \n",
       "\n",
       "                                      spect_cent_x  spect_cent_y  \\\n",
       "healthCode                                                         \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.401588      0.635471   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.079886      0.668962   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      1.086869      1.027991   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.607490      1.018372   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.715500      0.188665   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.214774      0.047958   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.264018      0.079070   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.473761      0.030326   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.556822      0.106259   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.185172      0.123464   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.467362      0.184988   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.285164      0.018012   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.238048      0.094047   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.302710      0.072282   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.304506      0.086258   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.151139      0.141883   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.239547      0.074789   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.212675      0.130208   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.221417      0.097678   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.207117      0.048559   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.216126      0.085050   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.114224      0.079382   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.250347      0.047741   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.225142      0.087129   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.223929      0.139713   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.262044      0.051334   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.292010      0.064838   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.081480      0.075957   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.292007      0.045208   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.139868      0.047521   \n",
       "...                                            ...           ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.060396      0.090188   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.032865      0.070991   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.090202      0.163323   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.065904      0.421853   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.021555      0.066779   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.195102      0.134399   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.123892      0.460889   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.064946      0.081196   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.206964      0.177844   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.033526      0.214497   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.009352      0.017789   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.130985      0.156075   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.049802      0.172835   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.027734      0.040254   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.151709      0.070110   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.141662      0.412233   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.010990      0.072177   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.103010      0.081799   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.060015      0.163271   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.037062      0.036308   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.092786      0.085866   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.135340      0.242441   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.137618      0.543534   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.002565      0.134739   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.108537      0.202708   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.139531      0.580975   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.109443      0.435058   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.057675      0.032472   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.060645      0.051170   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.027444      0.249147   \n",
       "\n",
       "                                      spect_cent_z  average_dist_meanx  \\\n",
       "healthCode                                                               \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.261587            0.189971   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.220937            0.181666   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.568184            0.182744   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.019616            0.183512   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.331627            0.165407   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.079783            0.154599   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.212707            0.145825   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.220903            0.140423   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.624609            0.135938   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.379450            0.129763   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.248037            0.123476   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.440142            0.117182   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.231297            0.112997   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.178837            0.109271   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.551066            0.105975   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.227174            0.103199   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.281503            0.101150   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.357410            0.099332   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.257579            0.097011   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.149732            0.094774   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.557988            0.093004   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.181422            0.091857   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.199895            0.091300   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.188352            0.090826   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.210784            0.090084   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.082530            0.089379   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.321055            0.088590   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.337841            0.087782   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.205164            0.087120   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.196802            0.086639   \n",
       "...                                            ...                 ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.086844            0.176555   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.046991            0.176612   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.065669            0.176631   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.153407            0.176540   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.097862            0.176476   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.081127            0.176452   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.430166            0.176563   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.084503            0.176798   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.298659            0.176897   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.135096            0.176834   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.014297            0.176741   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.107059            0.176718   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.020812            0.176716   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.131417            0.176784   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.197753            0.176865   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.141182            0.176873   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.027619            0.176878   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.079521            0.176909   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.041792            0.176881   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.067015            0.176874   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.354102            0.176939   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.373736            0.177003   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.081059            0.177006   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.068655            0.176909   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.029745            0.176882   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.204056            0.176971   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.394613            0.176991   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.248053            0.176982   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.260613            0.177037   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.086739            0.177081   \n",
       "\n",
       "                                      average_dist_meany  average_dist_meanz  \\\n",
       "healthCode                                                                     \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.066015            0.219167   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.070069            0.225696   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.078027            0.211303   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.128274            0.214012   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.136041            0.215774   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.144718            0.214896   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.149558            0.212353   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.153129            0.207136   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.155627            0.203303   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.156769            0.201240   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.155946            0.198892   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.155380            0.196078   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.156545            0.195434   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.156524            0.193544   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.155633            0.191828   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.155599            0.191978   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.156027            0.191443   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.157155            0.189383   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.158279            0.188860   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.158338            0.188561   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.158651            0.188337   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.159138            0.188416   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.159051            0.187830   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.159677            0.186687   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.160999            0.186059   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.161034            0.186297   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.160524            0.186907   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.160868            0.186899   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.160787            0.185676   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.161122            0.184212   \n",
       "...                                                  ...                 ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270928            0.195683   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270914            0.195651   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270953            0.195694   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270885            0.195670   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270659            0.195627   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270530            0.195676   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270572            0.195783   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270627            0.195907   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270645            0.196057   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270527            0.196081   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270250            0.196026   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270115            0.196026   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270117            0.196030   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270142            0.196064   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270140            0.196128   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270060            0.196115   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.269877            0.196059   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.269724            0.196025   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.269703            0.195995   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.269750            0.195981   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.269931            0.196098   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270140            0.196198   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270260            0.196207   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270229            0.196146   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270191            0.196112   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270296            0.196161   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270468            0.196197   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270639            0.196220   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270865            0.196286   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.271091            0.196358   \n",
       "\n",
       "                                       sex  \n",
       "healthCode                                  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "...                                    ...  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "\n",
       "[19008 rows x 26 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male = testing.loc[testing['sex'] == 'Male']\n",
    "male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7040"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_male=[]\n",
    "for i in range(0, len(list(male.iloc[:, 25]))):\n",
    "    if list(clf.predict(male.iloc[:, 0:25]))[i] != male.iloc[:, 25][i]:\n",
    "        results_male.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4576"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20064"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chopped_male = male_train.iloc[0:4576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4576"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chopped_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models with over 300 unique subjects\n",
    "\n",
    "1. Random Forest Classification\n",
    "2. Random Forest Regression\n",
    "2. K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO READ IN THE H5 FILE\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tengaps_total  = pd.read_hdf('tengaps_total.h5', 'df')\n",
    "\n",
    "# Min number of samples is 352... total subjects after filtering is 311\n",
    "tengaps_total = min_df(find_lowest_num_samples(tengaps_total), tengaps_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fundamental_freq</th>\n",
       "      <th>average_accel</th>\n",
       "      <th>peakcount</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mut_x</th>\n",
       "      <th>mut_y</th>\n",
       "      <th>mut_z</th>\n",
       "      <th>muf_x</th>\n",
       "      <th>muf_y</th>\n",
       "      <th>...</th>\n",
       "      <th>medf_z</th>\n",
       "      <th>cross_xz</th>\n",
       "      <th>cross_yz</th>\n",
       "      <th>spect_cent_x</th>\n",
       "      <th>spect_cent_y</th>\n",
       "      <th>spect_cent_z</th>\n",
       "      <th>average_dist_meanx</th>\n",
       "      <th>average_dist_meany</th>\n",
       "      <th>average_dist_meanz</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>80.317635</td>\n",
       "      <td>1.101210</td>\n",
       "      <td>17</td>\n",
       "      <td>2.143267</td>\n",
       "      <td>-3.015490</td>\n",
       "      <td>0.399885</td>\n",
       "      <td>-0.597875</td>\n",
       "      <td>-0.570088</td>\n",
       "      <td>2.706136</td>\n",
       "      <td>3.721300</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024757</td>\n",
       "      <td>-0.701445</td>\n",
       "      <td>1.048742</td>\n",
       "      <td>0.972882</td>\n",
       "      <td>2.182844</td>\n",
       "      <td>1.582017</td>\n",
       "      <td>0.517323</td>\n",
       "      <td>0.568784</td>\n",
       "      <td>0.386417</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>38.083914</td>\n",
       "      <td>0.427346</td>\n",
       "      <td>7</td>\n",
       "      <td>1.006866</td>\n",
       "      <td>-3.045824</td>\n",
       "      <td>-0.057948</td>\n",
       "      <td>-0.067404</td>\n",
       "      <td>-0.078100</td>\n",
       "      <td>1.599965</td>\n",
       "      <td>1.706091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243954</td>\n",
       "      <td>0.741968</td>\n",
       "      <td>0.863040</td>\n",
       "      <td>0.053480</td>\n",
       "      <td>0.077227</td>\n",
       "      <td>0.079480</td>\n",
       "      <td>0.393835</td>\n",
       "      <td>0.392307</td>\n",
       "      <td>0.277441</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>36.266223</td>\n",
       "      <td>0.414729</td>\n",
       "      <td>11</td>\n",
       "      <td>0.795667</td>\n",
       "      <td>-4.162361</td>\n",
       "      <td>0.010990</td>\n",
       "      <td>-0.121640</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>1.233173</td>\n",
       "      <td>1.099697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103315</td>\n",
       "      <td>0.669768</td>\n",
       "      <td>-7.413123</td>\n",
       "      <td>0.240560</td>\n",
       "      <td>0.035527</td>\n",
       "      <td>0.016021</td>\n",
       "      <td>0.366362</td>\n",
       "      <td>0.327574</td>\n",
       "      <td>0.209817</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>36.063199</td>\n",
       "      <td>0.403054</td>\n",
       "      <td>12</td>\n",
       "      <td>0.763178</td>\n",
       "      <td>-4.162361</td>\n",
       "      <td>0.028150</td>\n",
       "      <td>-0.134769</td>\n",
       "      <td>-0.005430</td>\n",
       "      <td>1.244109</td>\n",
       "      <td>1.140910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072295</td>\n",
       "      <td>-5.184453</td>\n",
       "      <td>24.820875</td>\n",
       "      <td>0.220195</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>0.013047</td>\n",
       "      <td>0.347282</td>\n",
       "      <td>0.293034</td>\n",
       "      <td>0.177266</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>39.833932</td>\n",
       "      <td>0.395897</td>\n",
       "      <td>12</td>\n",
       "      <td>0.805862</td>\n",
       "      <td>-3.484050</td>\n",
       "      <td>0.015722</td>\n",
       "      <td>-0.123211</td>\n",
       "      <td>-0.007962</td>\n",
       "      <td>1.277820</td>\n",
       "      <td>1.117586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111486</td>\n",
       "      <td>-1.974480</td>\n",
       "      <td>15.474189</td>\n",
       "      <td>0.322941</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>0.335096</td>\n",
       "      <td>0.271001</td>\n",
       "      <td>0.159870</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>40.572347</td>\n",
       "      <td>0.386141</td>\n",
       "      <td>11</td>\n",
       "      <td>0.805862</td>\n",
       "      <td>-3.331733</td>\n",
       "      <td>-0.009309</td>\n",
       "      <td>-0.103373</td>\n",
       "      <td>-0.015332</td>\n",
       "      <td>1.168532</td>\n",
       "      <td>1.068780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120747</td>\n",
       "      <td>0.607182</td>\n",
       "      <td>6.742411</td>\n",
       "      <td>0.332373</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0.325556</td>\n",
       "      <td>0.256530</td>\n",
       "      <td>0.148543</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>40.544675</td>\n",
       "      <td>0.389475</td>\n",
       "      <td>10</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>-3.331733</td>\n",
       "      <td>-0.013233</td>\n",
       "      <td>-0.073333</td>\n",
       "      <td>-0.019231</td>\n",
       "      <td>1.248801</td>\n",
       "      <td>1.131872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077935</td>\n",
       "      <td>0.688129</td>\n",
       "      <td>3.813308</td>\n",
       "      <td>0.301156</td>\n",
       "      <td>0.012263</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.318741</td>\n",
       "      <td>0.248437</td>\n",
       "      <td>0.140951</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>39.815055</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>9</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>-2.900933</td>\n",
       "      <td>-0.007431</td>\n",
       "      <td>-0.092426</td>\n",
       "      <td>-0.007466</td>\n",
       "      <td>1.241145</td>\n",
       "      <td>1.226106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106640</td>\n",
       "      <td>0.995236</td>\n",
       "      <td>12.378906</td>\n",
       "      <td>0.243073</td>\n",
       "      <td>0.041197</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.312888</td>\n",
       "      <td>0.242275</td>\n",
       "      <td>0.135897</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>38.169775</td>\n",
       "      <td>0.403056</td>\n",
       "      <td>10</td>\n",
       "      <td>1.031602</td>\n",
       "      <td>-2.900933</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>-0.163079</td>\n",
       "      <td>-0.011702</td>\n",
       "      <td>1.294036</td>\n",
       "      <td>1.179408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069943</td>\n",
       "      <td>-0.426892</td>\n",
       "      <td>13.936223</td>\n",
       "      <td>0.190484</td>\n",
       "      <td>0.042568</td>\n",
       "      <td>0.030016</td>\n",
       "      <td>0.306509</td>\n",
       "      <td>0.236810</td>\n",
       "      <td>0.131662</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>36.650815</td>\n",
       "      <td>0.417344</td>\n",
       "      <td>10</td>\n",
       "      <td>1.031602</td>\n",
       "      <td>-3.312742</td>\n",
       "      <td>0.023705</td>\n",
       "      <td>-0.176902</td>\n",
       "      <td>-0.043664</td>\n",
       "      <td>1.464291</td>\n",
       "      <td>1.267359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116674</td>\n",
       "      <td>-0.542889</td>\n",
       "      <td>4.051397</td>\n",
       "      <td>0.127965</td>\n",
       "      <td>0.037677</td>\n",
       "      <td>0.042539</td>\n",
       "      <td>0.301758</td>\n",
       "      <td>0.233226</td>\n",
       "      <td>0.128470</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>31.799533</td>\n",
       "      <td>0.444670</td>\n",
       "      <td>11</td>\n",
       "      <td>0.908468</td>\n",
       "      <td>-3.312742</td>\n",
       "      <td>0.030880</td>\n",
       "      <td>-0.238972</td>\n",
       "      <td>-0.081164</td>\n",
       "      <td>1.257929</td>\n",
       "      <td>1.376721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084430</td>\n",
       "      <td>-0.380467</td>\n",
       "      <td>2.944302</td>\n",
       "      <td>0.112566</td>\n",
       "      <td>0.027365</td>\n",
       "      <td>0.011348</td>\n",
       "      <td>0.296665</td>\n",
       "      <td>0.229085</td>\n",
       "      <td>0.128299</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>30.729082</td>\n",
       "      <td>0.438242</td>\n",
       "      <td>12</td>\n",
       "      <td>0.908468</td>\n",
       "      <td>-2.649798</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>-0.251979</td>\n",
       "      <td>-0.107831</td>\n",
       "      <td>1.101800</td>\n",
       "      <td>1.274881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>-0.007135</td>\n",
       "      <td>2.336798</td>\n",
       "      <td>0.096505</td>\n",
       "      <td>0.071444</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>0.292416</td>\n",
       "      <td>0.225061</td>\n",
       "      <td>0.126876</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>28.231253</td>\n",
       "      <td>0.382181</td>\n",
       "      <td>12</td>\n",
       "      <td>0.782783</td>\n",
       "      <td>-2.649798</td>\n",
       "      <td>-0.036705</td>\n",
       "      <td>-0.179970</td>\n",
       "      <td>-0.096401</td>\n",
       "      <td>1.096851</td>\n",
       "      <td>0.986436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075311</td>\n",
       "      <td>0.380751</td>\n",
       "      <td>1.866880</td>\n",
       "      <td>0.163117</td>\n",
       "      <td>0.045508</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.289043</td>\n",
       "      <td>0.220353</td>\n",
       "      <td>0.123195</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>30.228680</td>\n",
       "      <td>0.376604</td>\n",
       "      <td>12</td>\n",
       "      <td>0.799533</td>\n",
       "      <td>-2.548177</td>\n",
       "      <td>-0.025995</td>\n",
       "      <td>-0.190101</td>\n",
       "      <td>-0.060055</td>\n",
       "      <td>1.050832</td>\n",
       "      <td>1.014062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090759</td>\n",
       "      <td>0.432849</td>\n",
       "      <td>3.165455</td>\n",
       "      <td>0.088134</td>\n",
       "      <td>0.028003</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>0.286296</td>\n",
       "      <td>0.215466</td>\n",
       "      <td>0.120215</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>30.787937</td>\n",
       "      <td>0.393000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.883408</td>\n",
       "      <td>-2.548177</td>\n",
       "      <td>-0.005658</td>\n",
       "      <td>-0.199336</td>\n",
       "      <td>-0.049064</td>\n",
       "      <td>1.195186</td>\n",
       "      <td>1.091994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130118</td>\n",
       "      <td>0.115319</td>\n",
       "      <td>4.062745</td>\n",
       "      <td>0.014328</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>0.037672</td>\n",
       "      <td>0.284161</td>\n",
       "      <td>0.211626</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>29.112360</td>\n",
       "      <td>0.417368</td>\n",
       "      <td>11</td>\n",
       "      <td>0.883408</td>\n",
       "      <td>-2.276670</td>\n",
       "      <td>-0.012035</td>\n",
       "      <td>-0.202480</td>\n",
       "      <td>-0.052199</td>\n",
       "      <td>1.396775</td>\n",
       "      <td>1.235078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112999</td>\n",
       "      <td>0.230566</td>\n",
       "      <td>3.879014</td>\n",
       "      <td>0.081094</td>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.046920</td>\n",
       "      <td>0.282626</td>\n",
       "      <td>0.209953</td>\n",
       "      <td>0.118099</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>30.431357</td>\n",
       "      <td>0.423485</td>\n",
       "      <td>10</td>\n",
       "      <td>0.872848</td>\n",
       "      <td>-2.672177</td>\n",
       "      <td>-0.026599</td>\n",
       "      <td>-0.196997</td>\n",
       "      <td>-0.051949</td>\n",
       "      <td>1.396252</td>\n",
       "      <td>1.421165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228217</td>\n",
       "      <td>0.512030</td>\n",
       "      <td>3.792127</td>\n",
       "      <td>0.042021</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>0.027537</td>\n",
       "      <td>0.281763</td>\n",
       "      <td>0.209097</td>\n",
       "      <td>0.117977</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>34.216155</td>\n",
       "      <td>0.442942</td>\n",
       "      <td>10</td>\n",
       "      <td>0.991339</td>\n",
       "      <td>-2.672177</td>\n",
       "      <td>-0.053810</td>\n",
       "      <td>-0.134394</td>\n",
       "      <td>-0.095326</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>1.404973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188064</td>\n",
       "      <td>0.564488</td>\n",
       "      <td>1.409844</td>\n",
       "      <td>0.043166</td>\n",
       "      <td>0.113782</td>\n",
       "      <td>0.031045</td>\n",
       "      <td>0.281365</td>\n",
       "      <td>0.209760</td>\n",
       "      <td>0.118903</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>37.543556</td>\n",
       "      <td>0.491090</td>\n",
       "      <td>10</td>\n",
       "      <td>1.061596</td>\n",
       "      <td>-2.156044</td>\n",
       "      <td>-0.091652</td>\n",
       "      <td>-0.092010</td>\n",
       "      <td>-0.134724</td>\n",
       "      <td>1.656743</td>\n",
       "      <td>1.467439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141130</td>\n",
       "      <td>0.680297</td>\n",
       "      <td>0.682951</td>\n",
       "      <td>0.065793</td>\n",
       "      <td>0.126554</td>\n",
       "      <td>0.028939</td>\n",
       "      <td>0.281751</td>\n",
       "      <td>0.211969</td>\n",
       "      <td>0.120123</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>35.295746</td>\n",
       "      <td>0.472282</td>\n",
       "      <td>11</td>\n",
       "      <td>1.061596</td>\n",
       "      <td>-2.349747</td>\n",
       "      <td>-0.084599</td>\n",
       "      <td>-0.125710</td>\n",
       "      <td>-0.116248</td>\n",
       "      <td>1.456052</td>\n",
       "      <td>1.363617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136039</td>\n",
       "      <td>0.727749</td>\n",
       "      <td>1.081399</td>\n",
       "      <td>0.045913</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.281919</td>\n",
       "      <td>0.212941</td>\n",
       "      <td>0.121180</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>37.277198</td>\n",
       "      <td>0.443325</td>\n",
       "      <td>10</td>\n",
       "      <td>0.997225</td>\n",
       "      <td>-3.284379</td>\n",
       "      <td>-0.069377</td>\n",
       "      <td>-0.143473</td>\n",
       "      <td>-0.088805</td>\n",
       "      <td>1.470408</td>\n",
       "      <td>1.319044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116797</td>\n",
       "      <td>0.781230</td>\n",
       "      <td>1.615596</td>\n",
       "      <td>0.095510</td>\n",
       "      <td>0.056972</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.281940</td>\n",
       "      <td>0.213269</td>\n",
       "      <td>0.121459</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>36.920857</td>\n",
       "      <td>0.438088</td>\n",
       "      <td>8</td>\n",
       "      <td>0.988750</td>\n",
       "      <td>-3.284379</td>\n",
       "      <td>-0.062944</td>\n",
       "      <td>-0.127512</td>\n",
       "      <td>-0.065953</td>\n",
       "      <td>1.360357</td>\n",
       "      <td>1.348092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143937</td>\n",
       "      <td>0.954372</td>\n",
       "      <td>1.933373</td>\n",
       "      <td>0.105109</td>\n",
       "      <td>0.070946</td>\n",
       "      <td>0.026972</td>\n",
       "      <td>0.282092</td>\n",
       "      <td>0.214146</td>\n",
       "      <td>0.120520</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>40.939597</td>\n",
       "      <td>0.427087</td>\n",
       "      <td>10</td>\n",
       "      <td>0.906632</td>\n",
       "      <td>-3.552532</td>\n",
       "      <td>-0.036357</td>\n",
       "      <td>-0.123838</td>\n",
       "      <td>-0.023351</td>\n",
       "      <td>1.371916</td>\n",
       "      <td>1.264012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162345</td>\n",
       "      <td>1.557008</td>\n",
       "      <td>5.303390</td>\n",
       "      <td>0.264331</td>\n",
       "      <td>0.219571</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.282484</td>\n",
       "      <td>0.214580</td>\n",
       "      <td>0.119236</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>42.277695</td>\n",
       "      <td>0.424758</td>\n",
       "      <td>13</td>\n",
       "      <td>0.994060</td>\n",
       "      <td>-3.552532</td>\n",
       "      <td>-0.017354</td>\n",
       "      <td>-0.132121</td>\n",
       "      <td>0.027927</td>\n",
       "      <td>1.462963</td>\n",
       "      <td>1.267214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102066</td>\n",
       "      <td>-0.621410</td>\n",
       "      <td>-4.730989</td>\n",
       "      <td>0.468264</td>\n",
       "      <td>0.278955</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.283072</td>\n",
       "      <td>0.214782</td>\n",
       "      <td>0.117503</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>45.072673</td>\n",
       "      <td>0.450694</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994060</td>\n",
       "      <td>-3.038502</td>\n",
       "      <td>-0.013549</td>\n",
       "      <td>-0.128303</td>\n",
       "      <td>0.046469</td>\n",
       "      <td>1.458418</td>\n",
       "      <td>1.424103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207526</td>\n",
       "      <td>-0.291575</td>\n",
       "      <td>-2.761052</td>\n",
       "      <td>0.316256</td>\n",
       "      <td>0.170338</td>\n",
       "      <td>0.016125</td>\n",
       "      <td>0.282992</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.116387</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>40.406912</td>\n",
       "      <td>0.473828</td>\n",
       "      <td>7</td>\n",
       "      <td>1.033453</td>\n",
       "      <td>-2.315667</td>\n",
       "      <td>-0.063171</td>\n",
       "      <td>-0.114065</td>\n",
       "      <td>0.016906</td>\n",
       "      <td>1.511230</td>\n",
       "      <td>1.717430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167149</td>\n",
       "      <td>-3.736528</td>\n",
       "      <td>-6.746907</td>\n",
       "      <td>0.226604</td>\n",
       "      <td>0.229269</td>\n",
       "      <td>0.024033</td>\n",
       "      <td>0.283099</td>\n",
       "      <td>0.219502</td>\n",
       "      <td>0.115700</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>33.173641</td>\n",
       "      <td>0.437087</td>\n",
       "      <td>10</td>\n",
       "      <td>1.033453</td>\n",
       "      <td>-3.492994</td>\n",
       "      <td>-0.096032</td>\n",
       "      <td>-0.125813</td>\n",
       "      <td>-0.017080</td>\n",
       "      <td>1.393016</td>\n",
       "      <td>1.369123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080842</td>\n",
       "      <td>5.622348</td>\n",
       "      <td>7.365930</td>\n",
       "      <td>0.150547</td>\n",
       "      <td>0.082777</td>\n",
       "      <td>0.025186</td>\n",
       "      <td>0.284040</td>\n",
       "      <td>0.219318</td>\n",
       "      <td>0.114741</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>28.800481</td>\n",
       "      <td>0.402817</td>\n",
       "      <td>12</td>\n",
       "      <td>0.913586</td>\n",
       "      <td>-3.492994</td>\n",
       "      <td>-0.062323</td>\n",
       "      <td>-0.116522</td>\n",
       "      <td>-0.038545</td>\n",
       "      <td>1.446940</td>\n",
       "      <td>1.200983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120866</td>\n",
       "      <td>1.616910</td>\n",
       "      <td>3.023038</td>\n",
       "      <td>0.137144</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.045020</td>\n",
       "      <td>0.284194</td>\n",
       "      <td>0.218083</td>\n",
       "      <td>0.113999</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>29.481459</td>\n",
       "      <td>0.414416</td>\n",
       "      <td>11</td>\n",
       "      <td>0.859915</td>\n",
       "      <td>-3.226516</td>\n",
       "      <td>-0.036485</td>\n",
       "      <td>-0.104814</td>\n",
       "      <td>-0.038988</td>\n",
       "      <td>1.469317</td>\n",
       "      <td>1.249876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201264</td>\n",
       "      <td>0.935791</td>\n",
       "      <td>2.688360</td>\n",
       "      <td>0.103389</td>\n",
       "      <td>0.056073</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>0.283689</td>\n",
       "      <td>0.218032</td>\n",
       "      <td>0.113167</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2f2d4b-dd77-4084-baea-74ecbd8774b5</th>\n",
       "      <td>34.483462</td>\n",
       "      <td>0.426526</td>\n",
       "      <td>11</td>\n",
       "      <td>1.059767</td>\n",
       "      <td>-2.854564</td>\n",
       "      <td>-0.049624</td>\n",
       "      <td>-0.122114</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>1.527989</td>\n",
       "      <td>1.224401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186670</td>\n",
       "      <td>13.399140</td>\n",
       "      <td>32.972619</td>\n",
       "      <td>0.032652</td>\n",
       "      <td>0.055063</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.283866</td>\n",
       "      <td>0.218091</td>\n",
       "      <td>0.112030</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>52.828292</td>\n",
       "      <td>0.628040</td>\n",
       "      <td>11</td>\n",
       "      <td>1.417420</td>\n",
       "      <td>-1.396874</td>\n",
       "      <td>-0.304097</td>\n",
       "      <td>-0.261937</td>\n",
       "      <td>-0.062545</td>\n",
       "      <td>2.323359</td>\n",
       "      <td>1.483233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443512</td>\n",
       "      <td>4.862036</td>\n",
       "      <td>4.187972</td>\n",
       "      <td>0.855566</td>\n",
       "      <td>0.150704</td>\n",
       "      <td>0.099218</td>\n",
       "      <td>0.163946</td>\n",
       "      <td>0.133173</td>\n",
       "      <td>0.197661</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>43.350011</td>\n",
       "      <td>0.526060</td>\n",
       "      <td>11</td>\n",
       "      <td>1.143269</td>\n",
       "      <td>-1.456742</td>\n",
       "      <td>-0.162039</td>\n",
       "      <td>-0.353234</td>\n",
       "      <td>-0.021301</td>\n",
       "      <td>1.288965</td>\n",
       "      <td>1.192068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686111</td>\n",
       "      <td>7.607218</td>\n",
       "      <td>16.583156</td>\n",
       "      <td>0.026025</td>\n",
       "      <td>0.179796</td>\n",
       "      <td>0.188299</td>\n",
       "      <td>0.164028</td>\n",
       "      <td>0.133131</td>\n",
       "      <td>0.197716</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>42.592703</td>\n",
       "      <td>0.503652</td>\n",
       "      <td>6</td>\n",
       "      <td>1.321165</td>\n",
       "      <td>-1.492547</td>\n",
       "      <td>-0.182785</td>\n",
       "      <td>-0.277464</td>\n",
       "      <td>-0.060957</td>\n",
       "      <td>1.068410</td>\n",
       "      <td>1.116731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132104</td>\n",
       "      <td>2.998610</td>\n",
       "      <td>4.551815</td>\n",
       "      <td>0.022198</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>0.026499</td>\n",
       "      <td>0.163881</td>\n",
       "      <td>0.132998</td>\n",
       "      <td>0.198023</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>38.893859</td>\n",
       "      <td>0.511078</td>\n",
       "      <td>9</td>\n",
       "      <td>1.321165</td>\n",
       "      <td>-1.492547</td>\n",
       "      <td>-0.276793</td>\n",
       "      <td>-0.205265</td>\n",
       "      <td>-0.091271</td>\n",
       "      <td>1.233148</td>\n",
       "      <td>1.012058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385876</td>\n",
       "      <td>3.032660</td>\n",
       "      <td>2.248967</td>\n",
       "      <td>0.056469</td>\n",
       "      <td>0.088342</td>\n",
       "      <td>0.305038</td>\n",
       "      <td>0.163772</td>\n",
       "      <td>0.132870</td>\n",
       "      <td>0.198303</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>40.138264</td>\n",
       "      <td>0.545278</td>\n",
       "      <td>11</td>\n",
       "      <td>1.335838</td>\n",
       "      <td>-1.520989</td>\n",
       "      <td>-0.372324</td>\n",
       "      <td>-0.182913</td>\n",
       "      <td>-0.074234</td>\n",
       "      <td>1.632196</td>\n",
       "      <td>1.140853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226559</td>\n",
       "      <td>5.015548</td>\n",
       "      <td>2.464012</td>\n",
       "      <td>0.058043</td>\n",
       "      <td>0.106533</td>\n",
       "      <td>0.079211</td>\n",
       "      <td>0.163766</td>\n",
       "      <td>0.132801</td>\n",
       "      <td>0.198487</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>45.851966</td>\n",
       "      <td>0.584270</td>\n",
       "      <td>8</td>\n",
       "      <td>1.466551</td>\n",
       "      <td>-1.520989</td>\n",
       "      <td>-0.407144</td>\n",
       "      <td>-0.206234</td>\n",
       "      <td>-0.078690</td>\n",
       "      <td>1.654085</td>\n",
       "      <td>1.077577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501625</td>\n",
       "      <td>5.173995</td>\n",
       "      <td>2.620825</td>\n",
       "      <td>0.121632</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>0.175779</td>\n",
       "      <td>0.163765</td>\n",
       "      <td>0.132736</td>\n",
       "      <td>0.198751</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>49.215314</td>\n",
       "      <td>0.608076</td>\n",
       "      <td>10</td>\n",
       "      <td>1.466551</td>\n",
       "      <td>-1.665415</td>\n",
       "      <td>-0.397005</td>\n",
       "      <td>-0.260055</td>\n",
       "      <td>-0.026702</td>\n",
       "      <td>1.553447</td>\n",
       "      <td>1.028611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540165</td>\n",
       "      <td>14.868031</td>\n",
       "      <td>9.739186</td>\n",
       "      <td>0.203576</td>\n",
       "      <td>0.015886</td>\n",
       "      <td>0.181027</td>\n",
       "      <td>0.163704</td>\n",
       "      <td>0.132672</td>\n",
       "      <td>0.199057</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>52.140038</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>17</td>\n",
       "      <td>1.164793</td>\n",
       "      <td>-2.192439</td>\n",
       "      <td>-0.015552</td>\n",
       "      <td>-0.176228</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>2.806662</td>\n",
       "      <td>1.523453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651866</td>\n",
       "      <td>-2.319193</td>\n",
       "      <td>-26.280592</td>\n",
       "      <td>0.881595</td>\n",
       "      <td>0.084545</td>\n",
       "      <td>0.096796</td>\n",
       "      <td>0.164536</td>\n",
       "      <td>0.132795</td>\n",
       "      <td>0.199286</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>44.058709</td>\n",
       "      <td>0.527484</td>\n",
       "      <td>14</td>\n",
       "      <td>1.188728</td>\n",
       "      <td>-2.192439</td>\n",
       "      <td>0.169356</td>\n",
       "      <td>-0.183789</td>\n",
       "      <td>-0.053099</td>\n",
       "      <td>2.292314</td>\n",
       "      <td>1.680718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649354</td>\n",
       "      <td>-3.189464</td>\n",
       "      <td>3.461265</td>\n",
       "      <td>0.249650</td>\n",
       "      <td>0.062369</td>\n",
       "      <td>0.027808</td>\n",
       "      <td>0.164979</td>\n",
       "      <td>0.132901</td>\n",
       "      <td>0.199343</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>36.469316</td>\n",
       "      <td>0.449385</td>\n",
       "      <td>8</td>\n",
       "      <td>1.188728</td>\n",
       "      <td>-1.945671</td>\n",
       "      <td>0.014326</td>\n",
       "      <td>-0.309467</td>\n",
       "      <td>-0.073990</td>\n",
       "      <td>1.305381</td>\n",
       "      <td>1.523373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399765</td>\n",
       "      <td>-0.193619</td>\n",
       "      <td>4.182557</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.358533</td>\n",
       "      <td>0.298978</td>\n",
       "      <td>0.164886</td>\n",
       "      <td>0.132910</td>\n",
       "      <td>0.199485</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>40.573587</td>\n",
       "      <td>0.480788</td>\n",
       "      <td>13</td>\n",
       "      <td>1.053820</td>\n",
       "      <td>-2.012198</td>\n",
       "      <td>0.090739</td>\n",
       "      <td>-0.321100</td>\n",
       "      <td>-0.104128</td>\n",
       "      <td>1.428303</td>\n",
       "      <td>1.592577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156635</td>\n",
       "      <td>-0.871421</td>\n",
       "      <td>3.083707</td>\n",
       "      <td>0.178125</td>\n",
       "      <td>0.237442</td>\n",
       "      <td>0.055550</td>\n",
       "      <td>0.164844</td>\n",
       "      <td>0.133037</td>\n",
       "      <td>0.199547</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>44.435151</td>\n",
       "      <td>0.504567</td>\n",
       "      <td>8</td>\n",
       "      <td>1.279680</td>\n",
       "      <td>-2.012198</td>\n",
       "      <td>0.176145</td>\n",
       "      <td>-0.320931</td>\n",
       "      <td>-0.104129</td>\n",
       "      <td>1.600739</td>\n",
       "      <td>1.882789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580765</td>\n",
       "      <td>-1.691603</td>\n",
       "      <td>3.082039</td>\n",
       "      <td>0.193664</td>\n",
       "      <td>0.119480</td>\n",
       "      <td>0.129398</td>\n",
       "      <td>0.164844</td>\n",
       "      <td>0.133360</td>\n",
       "      <td>0.199543</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>37.267953</td>\n",
       "      <td>0.476695</td>\n",
       "      <td>8</td>\n",
       "      <td>1.279680</td>\n",
       "      <td>-2.189185</td>\n",
       "      <td>0.091312</td>\n",
       "      <td>-0.308474</td>\n",
       "      <td>-0.049599</td>\n",
       "      <td>1.227465</td>\n",
       "      <td>1.673653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151179</td>\n",
       "      <td>-1.841028</td>\n",
       "      <td>6.219411</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.155533</td>\n",
       "      <td>0.019384</td>\n",
       "      <td>0.164977</td>\n",
       "      <td>0.133590</td>\n",
       "      <td>0.199523</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>40.727379</td>\n",
       "      <td>0.465846</td>\n",
       "      <td>13</td>\n",
       "      <td>1.021091</td>\n",
       "      <td>-2.189185</td>\n",
       "      <td>0.042009</td>\n",
       "      <td>-0.350287</td>\n",
       "      <td>-0.028044</td>\n",
       "      <td>1.286258</td>\n",
       "      <td>1.284071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708002</td>\n",
       "      <td>-1.497952</td>\n",
       "      <td>12.490524</td>\n",
       "      <td>0.114106</td>\n",
       "      <td>0.253891</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>0.164965</td>\n",
       "      <td>0.133606</td>\n",
       "      <td>0.199483</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>39.500244</td>\n",
       "      <td>0.533963</td>\n",
       "      <td>16</td>\n",
       "      <td>0.992020</td>\n",
       "      <td>-1.879248</td>\n",
       "      <td>0.165353</td>\n",
       "      <td>-0.399936</td>\n",
       "      <td>-0.017014</td>\n",
       "      <td>1.303148</td>\n",
       "      <td>1.325559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145750</td>\n",
       "      <td>-9.718391</td>\n",
       "      <td>23.505754</td>\n",
       "      <td>0.004343</td>\n",
       "      <td>0.215670</td>\n",
       "      <td>0.056767</td>\n",
       "      <td>0.164872</td>\n",
       "      <td>0.133599</td>\n",
       "      <td>0.199528</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>50.379195</td>\n",
       "      <td>0.636201</td>\n",
       "      <td>13</td>\n",
       "      <td>1.421234</td>\n",
       "      <td>-1.879248</td>\n",
       "      <td>0.224477</td>\n",
       "      <td>-0.486268</td>\n",
       "      <td>0.115628</td>\n",
       "      <td>1.534682</td>\n",
       "      <td>1.466833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214852</td>\n",
       "      <td>1.941368</td>\n",
       "      <td>-4.205437</td>\n",
       "      <td>0.071769</td>\n",
       "      <td>0.158857</td>\n",
       "      <td>0.055726</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>0.133659</td>\n",
       "      <td>0.199578</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>55.911870</td>\n",
       "      <td>0.709035</td>\n",
       "      <td>5</td>\n",
       "      <td>2.396162</td>\n",
       "      <td>-2.930654</td>\n",
       "      <td>0.213971</td>\n",
       "      <td>-0.488960</td>\n",
       "      <td>0.268310</td>\n",
       "      <td>2.238686</td>\n",
       "      <td>1.977220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429207</td>\n",
       "      <td>0.797476</td>\n",
       "      <td>-1.822366</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>0.107922</td>\n",
       "      <td>0.165260</td>\n",
       "      <td>0.134016</td>\n",
       "      <td>0.199650</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>68.189933</td>\n",
       "      <td>0.768507</td>\n",
       "      <td>9</td>\n",
       "      <td>2.396162</td>\n",
       "      <td>-2.930654</td>\n",
       "      <td>0.258798</td>\n",
       "      <td>-0.389887</td>\n",
       "      <td>0.232321</td>\n",
       "      <td>2.455459</td>\n",
       "      <td>2.098580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321095</td>\n",
       "      <td>1.113967</td>\n",
       "      <td>-1.678229</td>\n",
       "      <td>0.077514</td>\n",
       "      <td>0.116841</td>\n",
       "      <td>0.034567</td>\n",
       "      <td>0.165701</td>\n",
       "      <td>0.134387</td>\n",
       "      <td>0.200221</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>51.304219</td>\n",
       "      <td>0.668618</td>\n",
       "      <td>15</td>\n",
       "      <td>1.363268</td>\n",
       "      <td>-1.571988</td>\n",
       "      <td>0.237104</td>\n",
       "      <td>-0.348492</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>1.738378</td>\n",
       "      <td>1.694238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681751</td>\n",
       "      <td>30.821006</td>\n",
       "      <td>-45.300239</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>0.076012</td>\n",
       "      <td>0.134084</td>\n",
       "      <td>0.165741</td>\n",
       "      <td>0.134629</td>\n",
       "      <td>0.200810</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>38.022984</td>\n",
       "      <td>0.476659</td>\n",
       "      <td>17</td>\n",
       "      <td>0.951322</td>\n",
       "      <td>-2.710442</td>\n",
       "      <td>0.064138</td>\n",
       "      <td>-0.309849</td>\n",
       "      <td>-0.071563</td>\n",
       "      <td>1.165461</td>\n",
       "      <td>1.228878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207464</td>\n",
       "      <td>-0.896242</td>\n",
       "      <td>4.329707</td>\n",
       "      <td>0.081460</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.038262</td>\n",
       "      <td>0.165742</td>\n",
       "      <td>0.134725</td>\n",
       "      <td>0.200893</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>39.297481</td>\n",
       "      <td>0.493623</td>\n",
       "      <td>11</td>\n",
       "      <td>1.473133</td>\n",
       "      <td>-2.710442</td>\n",
       "      <td>0.147934</td>\n",
       "      <td>-0.197785</td>\n",
       "      <td>-0.046850</td>\n",
       "      <td>1.994128</td>\n",
       "      <td>1.132264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183505</td>\n",
       "      <td>-3.157618</td>\n",
       "      <td>4.221670</td>\n",
       "      <td>0.242298</td>\n",
       "      <td>0.049221</td>\n",
       "      <td>0.084290</td>\n",
       "      <td>0.165892</td>\n",
       "      <td>0.134791</td>\n",
       "      <td>0.201108</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>54.414725</td>\n",
       "      <td>0.594844</td>\n",
       "      <td>7</td>\n",
       "      <td>1.473133</td>\n",
       "      <td>-1.470503</td>\n",
       "      <td>0.348816</td>\n",
       "      <td>-0.203604</td>\n",
       "      <td>-0.052023</td>\n",
       "      <td>1.839830</td>\n",
       "      <td>1.207616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450285</td>\n",
       "      <td>-6.704986</td>\n",
       "      <td>3.913702</td>\n",
       "      <td>0.307390</td>\n",
       "      <td>0.050393</td>\n",
       "      <td>0.466287</td>\n",
       "      <td>0.165981</td>\n",
       "      <td>0.134864</td>\n",
       "      <td>0.201454</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>52.590297</td>\n",
       "      <td>0.710299</td>\n",
       "      <td>14</td>\n",
       "      <td>1.339011</td>\n",
       "      <td>-1.423868</td>\n",
       "      <td>0.404094</td>\n",
       "      <td>-0.377848</td>\n",
       "      <td>0.040359</td>\n",
       "      <td>1.826301</td>\n",
       "      <td>1.588641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301795</td>\n",
       "      <td>10.012583</td>\n",
       "      <td>-9.362278</td>\n",
       "      <td>0.243099</td>\n",
       "      <td>0.162528</td>\n",
       "      <td>0.077476</td>\n",
       "      <td>0.166036</td>\n",
       "      <td>0.135049</td>\n",
       "      <td>0.201745</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>50.678805</td>\n",
       "      <td>0.704331</td>\n",
       "      <td>16</td>\n",
       "      <td>1.339011</td>\n",
       "      <td>-2.493569</td>\n",
       "      <td>0.356908</td>\n",
       "      <td>-0.412264</td>\n",
       "      <td>0.081168</td>\n",
       "      <td>1.870581</td>\n",
       "      <td>1.609865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644077</td>\n",
       "      <td>4.397136</td>\n",
       "      <td>-5.079122</td>\n",
       "      <td>0.116985</td>\n",
       "      <td>0.160568</td>\n",
       "      <td>0.211653</td>\n",
       "      <td>0.166214</td>\n",
       "      <td>0.135310</td>\n",
       "      <td>0.201981</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>45.073384</td>\n",
       "      <td>0.524385</td>\n",
       "      <td>12</td>\n",
       "      <td>1.216027</td>\n",
       "      <td>-3.271670</td>\n",
       "      <td>0.176167</td>\n",
       "      <td>-0.308095</td>\n",
       "      <td>-0.026821</td>\n",
       "      <td>1.635998</td>\n",
       "      <td>1.262500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499430</td>\n",
       "      <td>-6.568158</td>\n",
       "      <td>11.486942</td>\n",
       "      <td>0.284576</td>\n",
       "      <td>0.031673</td>\n",
       "      <td>0.451751</td>\n",
       "      <td>0.166357</td>\n",
       "      <td>0.135420</td>\n",
       "      <td>0.202113</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>34.102632</td>\n",
       "      <td>0.422933</td>\n",
       "      <td>15</td>\n",
       "      <td>0.752957</td>\n",
       "      <td>-3.271670</td>\n",
       "      <td>0.025503</td>\n",
       "      <td>-0.295098</td>\n",
       "      <td>-0.070304</td>\n",
       "      <td>1.554125</td>\n",
       "      <td>1.282143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150115</td>\n",
       "      <td>-0.362755</td>\n",
       "      <td>4.197469</td>\n",
       "      <td>0.251021</td>\n",
       "      <td>0.146157</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.166318</td>\n",
       "      <td>0.135431</td>\n",
       "      <td>0.202046</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>36.430979</td>\n",
       "      <td>0.500760</td>\n",
       "      <td>14</td>\n",
       "      <td>0.848964</td>\n",
       "      <td>-1.718198</td>\n",
       "      <td>-0.030588</td>\n",
       "      <td>-0.368090</td>\n",
       "      <td>-0.027619</td>\n",
       "      <td>1.052146</td>\n",
       "      <td>1.380320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430366</td>\n",
       "      <td>1.107494</td>\n",
       "      <td>13.327208</td>\n",
       "      <td>0.030838</td>\n",
       "      <td>0.085499</td>\n",
       "      <td>0.089046</td>\n",
       "      <td>0.166282</td>\n",
       "      <td>0.135482</td>\n",
       "      <td>0.202024</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>45.300768</td>\n",
       "      <td>0.590482</td>\n",
       "      <td>21</td>\n",
       "      <td>0.884936</td>\n",
       "      <td>-1.419650</td>\n",
       "      <td>-0.095153</td>\n",
       "      <td>-0.405477</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>2.111563</td>\n",
       "      <td>1.295890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224275</td>\n",
       "      <td>-4.906332</td>\n",
       "      <td>-20.907421</td>\n",
       "      <td>0.289117</td>\n",
       "      <td>0.221287</td>\n",
       "      <td>0.026877</td>\n",
       "      <td>0.166467</td>\n",
       "      <td>0.135460</td>\n",
       "      <td>0.202077</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>43.531043</td>\n",
       "      <td>0.560623</td>\n",
       "      <td>18</td>\n",
       "      <td>0.884936</td>\n",
       "      <td>-1.493561</td>\n",
       "      <td>-0.110971</td>\n",
       "      <td>-0.396155</td>\n",
       "      <td>0.031788</td>\n",
       "      <td>1.531344</td>\n",
       "      <td>1.208663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245824</td>\n",
       "      <td>-3.490971</td>\n",
       "      <td>-12.462420</td>\n",
       "      <td>0.097655</td>\n",
       "      <td>0.168684</td>\n",
       "      <td>0.108418</td>\n",
       "      <td>0.166626</td>\n",
       "      <td>0.135440</td>\n",
       "      <td>0.202048</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70cd4192-89aa-47d6-8c55-03361f847d83</th>\n",
       "      <td>39.858729</td>\n",
       "      <td>0.525110</td>\n",
       "      <td>11</td>\n",
       "      <td>1.119014</td>\n",
       "      <td>-1.995940</td>\n",
       "      <td>-0.057295</td>\n",
       "      <td>-0.297079</td>\n",
       "      <td>-0.037047</td>\n",
       "      <td>1.216295</td>\n",
       "      <td>1.644964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663639</td>\n",
       "      <td>1.546544</td>\n",
       "      <td>8.018927</td>\n",
       "      <td>0.115168</td>\n",
       "      <td>0.109326</td>\n",
       "      <td>0.121584</td>\n",
       "      <td>0.166762</td>\n",
       "      <td>0.135581</td>\n",
       "      <td>0.202147</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109472 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fundamental_freq  average_accel  \\\n",
       "healthCode                                                              \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         80.317635       1.101210   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         38.083914       0.427346   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         36.266223       0.414729   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         36.063199       0.403054   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         39.833932       0.395897   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         40.572347       0.386141   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         40.544675       0.389475   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         39.815055       0.391514   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         38.169775       0.403056   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         36.650815       0.417344   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         31.799533       0.444670   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         30.729082       0.438242   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         28.231253       0.382181   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         30.228680       0.376604   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         30.787937       0.393000   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         29.112360       0.417368   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         30.431357       0.423485   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         34.216155       0.442942   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         37.543556       0.491090   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         35.295746       0.472282   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         37.277198       0.443325   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         36.920857       0.438088   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         40.939597       0.427087   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         42.277695       0.424758   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         45.072673       0.450694   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         40.406912       0.473828   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         33.173641       0.437087   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         28.800481       0.402817   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         29.481459       0.414416   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         34.483462       0.426526   \n",
       "...                                                ...            ...   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         52.828292       0.628040   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         43.350011       0.526060   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         42.592703       0.503652   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         38.893859       0.511078   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         40.138264       0.545278   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         45.851966       0.584270   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         49.215314       0.608076   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         52.140038       0.626000   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         44.058709       0.527484   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         36.469316       0.449385   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         40.573587       0.480788   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         44.435151       0.504567   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         37.267953       0.476695   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         40.727379       0.465846   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         39.500244       0.533963   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         50.379195       0.636201   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         55.911870       0.709035   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         68.189933       0.768507   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         51.304219       0.668618   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         38.022984       0.476659   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         39.297481       0.493623   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         54.414725       0.594844   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         52.590297       0.710299   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         50.678805       0.704331   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         45.073384       0.524385   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         34.102632       0.422933   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         36.430979       0.500760   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         45.300768       0.590482   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         43.531043       0.560623   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         39.858729       0.525110   \n",
       "\n",
       "                                      peakcount       max       min     mut_x  \\\n",
       "healthCode                                                                      \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         17  2.143267 -3.015490  0.399885   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5          7  1.006866 -3.045824 -0.057948   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         11  0.795667 -4.162361  0.010990   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         12  0.763178 -4.162361  0.028150   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         12  0.805862 -3.484050  0.015722   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         11  0.805862 -3.331733 -0.009309   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         10  0.883401 -3.331733 -0.013233   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5          9  0.883401 -2.900933 -0.007431   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         10  1.031602 -2.900933  0.004995   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         10  1.031602 -3.312742  0.023705   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         11  0.908468 -3.312742  0.030880   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         12  0.908468 -2.649798  0.000769   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         12  0.782783 -2.649798 -0.036705   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         12  0.799533 -2.548177 -0.025995   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         12  0.883408 -2.548177 -0.005658   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         11  0.883408 -2.276670 -0.012035   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         10  0.872848 -2.672177 -0.026599   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         10  0.991339 -2.672177 -0.053810   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         10  1.061596 -2.156044 -0.091652   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         11  1.061596 -2.349747 -0.084599   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         10  0.997225 -3.284379 -0.069377   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5          8  0.988750 -3.284379 -0.062944   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         10  0.906632 -3.552532 -0.036357   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         13  0.994060 -3.552532 -0.017354   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         10  0.994060 -3.038502 -0.013549   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5          7  1.033453 -2.315667 -0.063171   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         10  1.033453 -3.492994 -0.096032   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         12  0.913586 -3.492994 -0.062323   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         11  0.859915 -3.226516 -0.036485   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5         11  1.059767 -2.854564 -0.049624   \n",
       "...                                         ...       ...       ...       ...   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         11  1.417420 -1.396874 -0.304097   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         11  1.143269 -1.456742 -0.162039   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83          6  1.321165 -1.492547 -0.182785   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83          9  1.321165 -1.492547 -0.276793   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         11  1.335838 -1.520989 -0.372324   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83          8  1.466551 -1.520989 -0.407144   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         10  1.466551 -1.665415 -0.397005   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         17  1.164793 -2.192439 -0.015552   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         14  1.188728 -2.192439  0.169356   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83          8  1.188728 -1.945671  0.014326   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         13  1.053820 -2.012198  0.090739   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83          8  1.279680 -2.012198  0.176145   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83          8  1.279680 -2.189185  0.091312   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         13  1.021091 -2.189185  0.042009   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         16  0.992020 -1.879248  0.165353   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         13  1.421234 -1.879248  0.224477   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83          5  2.396162 -2.930654  0.213971   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83          9  2.396162 -2.930654  0.258798   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         15  1.363268 -1.571988  0.237104   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         17  0.951322 -2.710442  0.064138   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         11  1.473133 -2.710442  0.147934   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83          7  1.473133 -1.470503  0.348816   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         14  1.339011 -1.423868  0.404094   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         16  1.339011 -2.493569  0.356908   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         12  1.216027 -3.271670  0.176167   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         15  0.752957 -3.271670  0.025503   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         14  0.848964 -1.718198 -0.030588   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         21  0.884936 -1.419650 -0.095153   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         18  0.884936 -1.493561 -0.110971   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83         11  1.119014 -1.995940 -0.057295   \n",
       "\n",
       "                                         mut_y     mut_z     muf_x     muf_y  \\\n",
       "healthCode                                                                     \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.597875 -0.570088  2.706136  3.721300   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.067404 -0.078100  1.599965  1.706091   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.121640  0.016409  1.233173  1.099697   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.134769 -0.005430  1.244109  1.140910   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.123211 -0.007962  1.277820  1.117586   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.103373 -0.015332  1.168532  1.068780   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.073333 -0.019231  1.248801  1.131872   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.092426 -0.007466  1.241145  1.226106   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.163079 -0.011702  1.294036  1.179408   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.176902 -0.043664  1.464291  1.267359   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.238972 -0.081164  1.257929  1.376721   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.251979 -0.107831  1.101800  1.274881   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.179970 -0.096401  1.096851  0.986436   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.190101 -0.060055  1.050832  1.014062   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.199336 -0.049064  1.195186  1.091994   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.202480 -0.052199  1.396775  1.235078   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.196997 -0.051949  1.396252  1.421165   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.134394 -0.095326  1.398250  1.404973   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.092010 -0.134724  1.656743  1.467439   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.125710 -0.116248  1.456052  1.363617   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.143473 -0.088805  1.470408  1.319044   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.127512 -0.065953  1.360357  1.348092   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.123838 -0.023351  1.371916  1.264012   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.132121  0.027927  1.462963  1.267214   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.128303  0.046469  1.458418  1.424103   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.114065  0.016906  1.511230  1.717430   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.125813 -0.017080  1.393016  1.369123   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.116522 -0.038545  1.446940  1.200983   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.104814 -0.038988  1.469317  1.249876   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5 -0.122114 -0.003704  1.527989  1.224401   \n",
       "...                                        ...       ...       ...       ...   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.261937 -0.062545  2.323359  1.483233   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.353234 -0.021301  1.288965  1.192068   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.277464 -0.060957  1.068410  1.116731   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.205265 -0.091271  1.233148  1.012058   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.182913 -0.074234  1.632196  1.140853   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.206234 -0.078690  1.654085  1.077577   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.260055 -0.026702  1.553447  1.028611   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.176228  0.006706  2.806662  1.523453   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.183789 -0.053099  2.292314  1.680718   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.309467 -0.073990  1.305381  1.523373   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.321100 -0.104128  1.428303  1.592577   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.320931 -0.104129  1.600739  1.882789   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.308474 -0.049599  1.227465  1.673653   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.350287 -0.028044  1.286258  1.284071   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.399936 -0.017014  1.303148  1.325559   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.486268  0.115628  1.534682  1.466833   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.488960  0.268310  2.238686  1.977220   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.389887  0.232321  2.455459  2.098580   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.348492  0.007693  1.738378  1.694238   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.309849 -0.071563  1.165461  1.228878   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.197785 -0.046850  1.994128  1.132264   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.203604 -0.052023  1.839830  1.207616   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.377848  0.040359  1.826301  1.588641   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.412264  0.081168  1.870581  1.609865   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.308095 -0.026821  1.635998  1.262500   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.295098 -0.070304  1.554125  1.282143   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.368090 -0.027619  1.052146  1.380320   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.405477  0.019394  2.111563  1.295890   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.396155  0.031788  1.531344  1.208663   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83 -0.297079 -0.037047  1.216295  1.644964   \n",
       "\n",
       "                                       ...      medf_z   cross_xz   cross_yz  \\\n",
       "healthCode                             ...                                     \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    1.024757  -0.701445   1.048742   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.243954   0.741968   0.863040   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.103315   0.669768  -7.413123   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.072295  -5.184453  24.820875   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.111486  -1.974480  15.474189   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.120747   0.607182   6.742411   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.077935   0.688129   3.813308   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.106640   0.995236  12.378906   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.069943  -0.426892  13.936223   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.116674  -0.542889   4.051397   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.084430  -0.380467   2.944302   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.103083  -0.007135   2.336798   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.075311   0.380751   1.866880   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.090759   0.432849   3.165455   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.130118   0.115319   4.062745   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.112999   0.230566   3.879014   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.228217   0.512030   3.792127   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.188064   0.564488   1.409844   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.141130   0.680297   0.682951   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.136039   0.727749   1.081399   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.116797   0.781230   1.615596   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.143937   0.954372   1.933373   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.162345   1.557008   5.303390   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.102066  -0.621410  -4.730989   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.207526  -0.291575  -2.761052   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.167149  -3.736528  -6.746907   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.080842   5.622348   7.365930   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.120866   1.616910   3.023038   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.201264   0.935791   2.688360   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5   ...    0.186670  13.399140  32.972619   \n",
       "...                                    ...         ...        ...        ...   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.443512   4.862036   4.187972   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.686111   7.607218  16.583156   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.132104   2.998610   4.551815   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.385876   3.032660   2.248967   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.226559   5.015548   2.464012   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.501625   5.173995   2.620825   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.540165  14.868031   9.739186   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.651866  -2.319193 -26.280592   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.649354  -3.189464   3.461265   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.399765  -0.193619   4.182557   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.156635  -0.871421   3.083707   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.580765  -1.691603   3.082039   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.151179  -1.841028   6.219411   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.708002  -1.497952  12.490524   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.145750  -9.718391  23.505754   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.214852   1.941368  -4.205437   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.429207   0.797476  -1.822366   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.321095   1.113967  -1.678229   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.681751  30.821006 -45.300239   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.207464  -0.896242   4.329707   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.183505  -3.157618   4.221670   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.450285  -6.704986   3.913702   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.301795  10.012583  -9.362278   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.644077   4.397136  -5.079122   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.499430  -6.568158  11.486942   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.150115  -0.362755   4.197469   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.430366   1.107494  13.327208   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.224275  -4.906332 -20.907421   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.245824  -3.490971 -12.462420   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83   ...    0.663639   1.546544   8.018927   \n",
       "\n",
       "                                      spect_cent_x  spect_cent_y  \\\n",
       "healthCode                                                         \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.972882      2.182844   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.053480      0.077227   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.240560      0.035527   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.220195      0.042900   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.322941      0.020514   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.332373      0.021014   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.301156      0.012263   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.243073      0.041197   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.190484      0.042568   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.127965      0.037677   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.112566      0.027365   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.096505      0.071444   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.163117      0.045508   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.088134      0.028003   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.014328      0.012077   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.081094      0.023745   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.042021      0.018297   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.043166      0.113782   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.065793      0.126554   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.045913      0.033708   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.095510      0.056972   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.105109      0.070946   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.264331      0.219571   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.468264      0.278955   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.316256      0.170338   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.226604      0.229269   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.150547      0.082777   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.137144      0.017857   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.103389      0.056073   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.032652      0.055063   \n",
       "...                                            ...           ...   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.855566      0.150704   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.026025      0.179796   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.022198      0.024215   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.056469      0.088342   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.058043      0.106533   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.121632      0.006749   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.203576      0.015886   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.881595      0.084545   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.249650      0.062369   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.011723      0.358533   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.178125      0.237442   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.193664      0.119480   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.005735      0.155533   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.114106      0.253891   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.004343      0.215670   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.071769      0.158857   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.005087      0.012955   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.077514      0.116841   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.046864      0.076012   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.081460      0.137504   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.242298      0.049221   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.307390      0.050393   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.243099      0.162528   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.116985      0.160568   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.284576      0.031673   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.251021      0.146157   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.030838      0.085499   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.289117      0.221287   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.097655      0.168684   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.115168      0.109326   \n",
       "\n",
       "                                      spect_cent_z  average_dist_meanx  \\\n",
       "healthCode                                                               \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      1.582017            0.517323   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.079480            0.393835   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.016021            0.366362   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.013047            0.347282   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.007707            0.335096   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.013244            0.325556   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.008668            0.318741   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.008781            0.312888   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.030016            0.306509   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.042539            0.301758   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.011348            0.296665   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.024926            0.292416   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.008703            0.289043   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.012784            0.286296   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.037672            0.284161   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.046920            0.282626   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.027537            0.281763   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.031045            0.281365   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.028939            0.281751   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.021398            0.281919   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.031373            0.281940   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.026972            0.282092   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.027200            0.282484   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.009530            0.283072   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.016125            0.282992   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.024033            0.283099   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.025186            0.284040   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.045020            0.284194   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.010954            0.283689   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5      0.001379            0.283866   \n",
       "...                                            ...                 ...   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.099218            0.163946   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.188299            0.164028   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.026499            0.163881   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.305038            0.163772   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.079211            0.163766   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.175779            0.163765   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.181027            0.163704   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.096796            0.164536   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.027808            0.164979   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.298978            0.164886   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.055550            0.164844   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.129398            0.164844   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.019384            0.164977   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.011435            0.164965   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.056767            0.164872   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.055726            0.164900   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.107922            0.165260   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.034567            0.165701   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.134084            0.165741   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.038262            0.165742   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.084290            0.165892   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.466287            0.165981   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.077476            0.166036   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.211653            0.166214   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.451751            0.166357   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.012122            0.166318   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.089046            0.166282   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.026877            0.166467   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.108418            0.166626   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83      0.121584            0.166762   \n",
       "\n",
       "                                      average_dist_meany  average_dist_meanz  \\\n",
       "healthCode                                                                     \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.568784            0.386417   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.392307            0.277441   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.327574            0.209817   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.293034            0.177266   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.271001            0.159870   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.256530            0.148543   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.248437            0.140951   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.242275            0.135897   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.236810            0.131662   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.233226            0.128470   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.229085            0.128299   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.225061            0.126876   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.220353            0.123195   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.215466            0.120215   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.211626            0.118387   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.209953            0.118099   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.209097            0.117977   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.209760            0.118903   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.211969            0.120123   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.212941            0.121180   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.213269            0.121459   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.214146            0.120520   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.214580            0.119236   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.214782            0.117503   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.216800            0.116387   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.219502            0.115700   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.219318            0.114741   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.218083            0.113999   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.218032            0.113167   \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5            0.218091            0.112030   \n",
       "...                                                  ...                 ...   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.133173            0.197661   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.133131            0.197716   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.132998            0.198023   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.132870            0.198303   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.132801            0.198487   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.132736            0.198751   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.132672            0.199057   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.132795            0.199286   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.132901            0.199343   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.132910            0.199485   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.133037            0.199547   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.133360            0.199543   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.133590            0.199523   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.133606            0.199483   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.133599            0.199528   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.133659            0.199578   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.134016            0.199650   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.134387            0.200221   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.134629            0.200810   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.134725            0.200893   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.134791            0.201108   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.134864            0.201454   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.135049            0.201745   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.135310            0.201981   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.135420            0.202113   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.135431            0.202046   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.135482            0.202024   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.135460            0.202077   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.135440            0.202048   \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83            0.135581            0.202147   \n",
       "\n",
       "                                         sex  \n",
       "healthCode                                    \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "cb2f2d4b-dd77-4084-baea-74ecbd8774b5  Female  \n",
       "...                                      ...  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "70cd4192-89aa-47d6-8c55-03361f847d83    Male  \n",
       "\n",
       "[109472 rows x 26 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tengaps_total = tengaps_total[tengaps_total.weight < 400]\n",
    "tengaps_total = tengaps_total[tengaps_total.weight > 80]\n",
    "\n",
    "# this dataframe doesn't have demographic data\n",
    "tengaps_no_demog = tengaps_total.drop(columns=['sex', 'currentAge', 'weight', 'height'])\n",
    "\n",
    "# Inserts sex into \n",
    "\n",
    "#tengaps_no_demog.insert(25, 'currentAge', tengaps_total.currentAge.values)\n",
    "#tengaps_no_demog.insert(26, 'weight', tengaps_total.weight.values)\n",
    "#tengaps_no_demog.insert(27, 'height', tengaps_total.height.values)\n",
    "tengaps_no_demog.insert(25, 'sex', tengaps_total.sex.values)\n",
    "tengaps_no_demog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell is dedicated to creating a balanced class training set\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numOfTotalHC = 311\n",
    "numOfTrainHC = 217\n",
    "numOfTestHC = 94\n",
    "\n",
    "training = tengaps_no_demog.iloc[0:(numOfTrainHC * find_lowest_num_samples(tengaps_no_demog))]\n",
    "testing = tengaps_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(tengaps_no_demog)):]\n",
    "\n",
    "female_train = training.loc[training['sex'] == 'Female']\n",
    "male_train = training.loc[training['sex'] == 'Male']\n",
    "choppedmale_train = male_train.iloc[0:17000]\n",
    "\n",
    "Xmale = np.array(choppedmale_train.iloc[:, 0:25])\n",
    "Xfemale = np.array(female_train.iloc[:, 0:25])\n",
    "X_scaledmale = preprocessing.scale(Xmale)\n",
    "X_scaledfemale = preprocessing.scale(Xfemale)\n",
    "\n",
    "X_scaledtotal = np.array(list(X_scaledmale)+list(X_scaledfemale))\n",
    "y_total = np.array(list(choppedmale_train.iloc[:, 25]) + list(female_train.iloc[:, 25]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaledtotal, y_total, test_size=0.33, random_state=42)\n",
    "\n",
    "X_mixedequal = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixedequal = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "# Binary encoding\n",
    "male_zero = [1 if x=='Female' else 0 for x in y_mixedequal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  25.1s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  25.4s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  25.9s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  25.9s\n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  25.9s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  3.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.4min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.5min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.5min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.5min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.5min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.5min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 2.0min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 2.0min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 2.0min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 2.0min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 2.0min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.6min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  16.3s\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  16.1s\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.5min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.5min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.5min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.6min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  17.0s\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  17.3s\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  17.3s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 6.2min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.9min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 6.0min\n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 6.0min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 6.0min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.3min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV] n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False, total= 1.8min\n",
      "[CV] n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False, total= 1.7min\n",
      "[CV] n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False, total= 1.7min\n",
      "[CV] n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False, total= 1.7min\n",
      "[CV] n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False, total= 1.7min\n",
      "[CV] n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 7.2min\n",
      "[CV] n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 7.1min\n",
      "[CV] n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False, total= 4.0min\n",
      "[CV] n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False, total= 3.9min\n",
      "[CV] n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=11.8min\n",
      "[CV] n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True, total= 3.3min\n",
      "[CV] n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False, total= 4.1min\n",
      "[CV] n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False, total= 4.1min\n",
      "[CV] n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False, total= 4.0min\n",
      "[CV] n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 6.9min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 6.9min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 6.9min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True, total= 3.3min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=11.6min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=11.7min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=11.7min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=11.7min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True, total= 3.5min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False, total= 6.7min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 3.3min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False, total= 6.7min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total= 5.5min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total= 5.4min\n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total= 5.5min\n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False, total= 6.6min\n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False, total= 6.6min\n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False, total= 6.7min\n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total= 5.5min\n",
      "[CV] n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total= 5.4min\n",
      "[CV] n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True, total= 1.7min\n",
      "[CV] n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True, total= 1.7min\n",
      "[CV] n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True, total= 1.7min\n",
      "[CV] n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True, total= 1.7min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True, total= 1.7min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False, total= 8.6min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False, total= 8.7min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False, total= 8.8min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 3.1min\n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 3.1min\n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 3.2min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False, total= 8.6min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False, total= 8.6min\n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 3.0min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True, total= 3.5min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True, total= 3.5min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True, total= 3.3min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True, total= 3.3min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True, total= 3.2min\n",
      "[CV]  n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False, total= 6.2min\n",
      "[CV]  n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False, total= 5.8min\n",
      "[CV]  n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False, total= 4.9min\n",
      "[CV]  n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False, total= 4.9min\n",
      "[CV]  n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False, total= 4.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 29.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [10, 31, 52, 73, 94, 115, 136, 157, 178, 200], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "dsrf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = dsrf, param_distributions = random_grid, n_iter = 20, scoring='roc_auc', cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_mixedequal, male_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 30,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 178}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=178, n_jobs=1,\n",
       "            oob_score=False, random_state=22, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "dsrf = RandomForestClassifier(n_estimators=178, max_depth=30, min_samples_split=2, min_samples_leaf=2, bootstrap=False, random_state=22)\n",
    "dsrf.fit(X_mixedequal, male_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_labels = [1 if x=='Female' else 0 for x in testing.iloc[:, 25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_female = []\n",
    "for y in total_labels:\n",
    "    if y == 1:\n",
    "        more_female.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_male = []\n",
    "for y in total_labels:\n",
    "    if y == 0:\n",
    "        more_male.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_test = testing.loc[testing['sex'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_test = testing.loc[testing['sex'] == 'Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33088"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33088"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6808510638297872"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22528/33088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6503264023210832"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrf.score(testing.iloc[:, 0:25], total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2046"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dsrf.predict(female_test.iloc[:, 0:25])).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.7340824, 0.2659176]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.65917603, 0.34082397]),\n",
       " array([0.38576779, 0.61423221]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.67790262, 0.32209738]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.6835206, 0.3164794]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.68913858, 0.31086142]),\n",
       " array([0.67509363, 0.32490637]),\n",
       " array([0.667603, 0.332397]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.74812734, 0.25187266]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.68820225, 0.31179775]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.6835206, 0.3164794]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.69756554, 0.30243446]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.67228464, 0.32771536]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.67977528, 0.32022472]),\n",
       " array([0.68820225, 0.31179775]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.66385768, 0.33614232]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.71910112, 0.28089888]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.71910112, 0.28089888]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.74625468, 0.25374532]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.65168539, 0.34831461]),\n",
       " array([0.64700375, 0.35299625]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.53370787, 0.46629213]),\n",
       " array([0.66104869, 0.33895131]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.417603, 0.582397]),\n",
       " array([0.37172285, 0.62827715]),\n",
       " array([0.38389513, 0.61610487]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.75561798, 0.24438202]),\n",
       " array([0.76966292, 0.23033708]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.74438202, 0.25561798]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.77434457, 0.22565543]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.68632959, 0.31367041]),\n",
       " array([0.74344569, 0.25655431]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.73970037, 0.26029963]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.69756554, 0.30243446]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.71254682, 0.28745318]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.75187266, 0.24812734]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.7659176, 0.2340824]),\n",
       " array([0.75, 0.25]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.74812734, 0.25187266]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.74250936, 0.25749064]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.68258427, 0.31741573]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.73970037, 0.26029963]),\n",
       " array([0.74250936, 0.25749064]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.69756554, 0.30243446]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.77902622, 0.22097378]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.75, 0.25]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.6741573, 0.3258427]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.73689139, 0.26310861]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.74906367, 0.25093633]),\n",
       " array([0.75093633, 0.24906367]),\n",
       " array([0.75374532, 0.24625468]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.74906367, 0.25093633]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.74906367, 0.25093633]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.74812734, 0.25187266]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.75749064, 0.24250936]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.73689139, 0.26310861]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.4082397, 0.5917603]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.67696629, 0.32303371]),\n",
       " array([0.68820225, 0.31179775]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.52996255, 0.47003745]),\n",
       " array([0.56273408, 0.43726592]),\n",
       " array([0.59644195, 0.40355805]),\n",
       " array([0.58988764, 0.41011236]),\n",
       " array([0.58988764, 0.41011236]),\n",
       " array([0.57677903, 0.42322097]),\n",
       " array([0.58707865, 0.41292135]),\n",
       " array([0.61423221, 0.38576779]),\n",
       " array([0.5917603, 0.4082397]),\n",
       " array([0.57397004, 0.42602996]),\n",
       " array([0.44194757, 0.55805243]),\n",
       " array([0.53838951, 0.46161049]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.74344569, 0.25655431]),\n",
       " array([0.49812734, 0.50187266]),\n",
       " array([0.51685393, 0.48314607]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.49812734, 0.50187266]),\n",
       " array([0.50749064, 0.49250936]),\n",
       " array([0.5411985, 0.4588015]),\n",
       " array([0.62921348, 0.37078652]),\n",
       " array([0.65543071, 0.34456929]),\n",
       " array([0.6329588, 0.3670412]),\n",
       " array([0.56367041, 0.43632959]),\n",
       " array([0.56086142, 0.43913858]),\n",
       " array([0.57490637, 0.42509363]),\n",
       " array([0.44101124, 0.55898876]),\n",
       " array([0.3988764, 0.6011236]),\n",
       " array([0.39419476, 0.60580524]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.62921348, 0.37078652]),\n",
       " array([0.68913858, 0.31086142]),\n",
       " array([0.65355805, 0.34644195]),\n",
       " array([0.64606742, 0.35393258]),\n",
       " array([0.63014981, 0.36985019]),\n",
       " array([0.66011236, 0.33988764]),\n",
       " array([0.67134831, 0.32865169]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.66385768, 0.33614232]),\n",
       " array([0.66011236, 0.33988764]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.66947566, 0.33052434]),\n",
       " array([0.64419476, 0.35580524]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.67977528, 0.32022472]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.667603, 0.332397]),\n",
       " array([0.68913858, 0.31086142]),\n",
       " array([0.65543071, 0.34456929]),\n",
       " array([0.62546816, 0.37453184]),\n",
       " array([0.67696629, 0.32303371]),\n",
       " array([0.66947566, 0.33052434]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.66573034, 0.33426966]),\n",
       " array([0.66479401, 0.33520599]),\n",
       " array([0.66198502, 0.33801498]),\n",
       " array([0.667603, 0.332397]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.667603, 0.332397]),\n",
       " array([0.66479401, 0.33520599]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.67696629, 0.32303371]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.68632959, 0.31367041]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.6488764, 0.3511236]),\n",
       " array([0.65730337, 0.34269663]),\n",
       " array([0.6582397, 0.3417603]),\n",
       " array([0.66104869, 0.33895131]),\n",
       " array([0.66011236, 0.33988764]),\n",
       " array([0.6835206, 0.3164794]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.71254682, 0.28745318]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.75749064, 0.24250936]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.68632959, 0.31367041]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.68820225, 0.31179775]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.71910112, 0.28089888]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.75, 0.25]),\n",
       " array([0.81928839, 0.18071161]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.68632959, 0.31367041]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.76404494, 0.23595506]),\n",
       " array([0.75749064, 0.24250936]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.76872659, 0.23127341]),\n",
       " array([0.82303371, 0.17696629]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.76310861, 0.23689139]),\n",
       " array([0.76310861, 0.23689139]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.65730337, 0.34269663]),\n",
       " array([0.65168539, 0.34831461]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.69756554, 0.30243446]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.74344569, 0.25655431]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.75749064, 0.24250936]),\n",
       " array([0.78277154, 0.21722846]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.74625468, 0.25374532]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.74438202, 0.25561798]),\n",
       " array([0.76966292, 0.23033708]),\n",
       " array([0.66573034, 0.33426966]),\n",
       " array([0.76217228, 0.23782772]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.73970037, 0.26029963]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.75280899, 0.24719101]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.80524345, 0.19475655]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.74812734, 0.25187266]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.80898876, 0.19101124]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.75093633, 0.24906367]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.77902622, 0.22097378]),\n",
       " array([0.67134831, 0.32865169]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.76310861, 0.23689139]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.75187266, 0.24812734]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.75374532, 0.24625468]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.8164794, 0.1835206]),\n",
       " array([0.75374532, 0.24625468]),\n",
       " array([0.64794007, 0.35205993]),\n",
       " array([0.65730337, 0.34269663]),\n",
       " array([0.82022472, 0.17977528]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.78838951, 0.21161049]),\n",
       " array([0.76217228, 0.23782772]),\n",
       " array([0.76404494, 0.23595506]),\n",
       " array([0.68258427, 0.31741573]),\n",
       " array([0.77996255, 0.22003745]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.75093633, 0.24906367]),\n",
       " array([0.79307116, 0.20692884]),\n",
       " array([0.67977528, 0.32022472]),\n",
       " array([0.78651685, 0.21348315]),\n",
       " array([0.79494382, 0.20505618]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.71910112, 0.28089888]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.74812734, 0.25187266]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.75280899, 0.24719101]),\n",
       " array([0.76404494, 0.23595506]),\n",
       " array([0.74906367, 0.25093633]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.75, 0.25]),\n",
       " array([0.76966292, 0.23033708]),\n",
       " array([0.80524345, 0.19475655]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.38576779, 0.61423221]),\n",
       " array([0.53558052, 0.46441948]),\n",
       " array([0.55805243, 0.44194757]),\n",
       " array([0.50842697, 0.49157303]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.51779026, 0.48220974]),\n",
       " array([0.50187266, 0.49812734]),\n",
       " array([0.52153558, 0.47846442]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.52434457, 0.47565543]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.51498127, 0.48501873]),\n",
       " array([0.51310861, 0.48689139]),\n",
       " array([0.51310861, 0.48689139]),\n",
       " array([0.50468165, 0.49531835]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.52996255, 0.47003745]),\n",
       " array([0.52715356, 0.47284644]),\n",
       " array([0.52059925, 0.47940075]),\n",
       " array([0.49719101, 0.50280899]),\n",
       " array([0.50374532, 0.49625468]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.52996255, 0.47003745]),\n",
       " array([0.52621723, 0.47378277]),\n",
       " array([0.40636704, 0.59363296]),\n",
       " array([0.40168539, 0.59831461]),\n",
       " array([0.38576779, 0.61423221]),\n",
       " array([0.49438202, 0.50561798]),\n",
       " array([0.51872659, 0.48127341]),\n",
       " array([0.51029963, 0.48970037]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.49625468, 0.50374532]),\n",
       " array([0.50749064, 0.49250936]),\n",
       " array([0.52434457, 0.47565543]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.50374532, 0.49625468]),\n",
       " array([0.47191011, 0.52808989]),\n",
       " array([0.4494382, 0.5505618]),\n",
       " array([0.43726592, 0.56273408]),\n",
       " array([0.41292135, 0.58707865]),\n",
       " array([0.44850187, 0.55149813]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.50093633, 0.49906367]),\n",
       " array([0.47846442, 0.52153558]),\n",
       " array([0.49250936, 0.50749064]),\n",
       " array([0.49157303, 0.50842697]),\n",
       " array([0.45318352, 0.54681648]),\n",
       " array([0.42322097, 0.57677903]),\n",
       " array([0.43164794, 0.56835206]),\n",
       " array([0.46067416, 0.53932584]),\n",
       " array([0.42228464, 0.57771536]),\n",
       " array([0.42041199, 0.57958801]),\n",
       " array([0.46441948, 0.53558052]),\n",
       " array([0.48127341, 0.51872659]),\n",
       " array([0.52621723, 0.47378277]),\n",
       " array([0.55243446, 0.44756554]),\n",
       " array([0.52621723, 0.47378277]),\n",
       " array([0.51685393, 0.48314607]),\n",
       " array([0.50187266, 0.49812734]),\n",
       " array([0.52247191, 0.47752809]),\n",
       " array([0.52153558, 0.47846442]),\n",
       " array([0.50468165, 0.49531835]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.52434457, 0.47565543]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.6170412, 0.3829588]),\n",
       " array([0.63670412, 0.36329588]),\n",
       " array([0.67041199, 0.32958801]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.66479401, 0.33520599]),\n",
       " array([0.667603, 0.332397]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.66479401, 0.33520599]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.6741573, 0.3258427]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.76966292, 0.23033708]),\n",
       " array([0.76872659, 0.23127341]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.75280899, 0.24719101]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.78370787, 0.21629213]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.79962547, 0.20037453]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.76404494, 0.23595506]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.71254682, 0.28745318]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.71254682, 0.28745318]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.74438202, 0.25561798]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.80524345, 0.19475655]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.76498127, 0.23501873]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.76779026, 0.23220974]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.76310861, 0.23689139]),\n",
       " array([0.75374532, 0.24625468]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.77247191, 0.22752809]),\n",
       " array([0.76498127, 0.23501873]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.67790262, 0.32209738]),\n",
       " array([0.53838951, 0.46161049]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.51779026, 0.48220974]),\n",
       " array([0.53277154, 0.46722846]),\n",
       " array([0.50655431, 0.49344569]),\n",
       " array([0.52059925, 0.47940075]),\n",
       " array([0.51872659, 0.48127341]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.5411985, 0.4588015]),\n",
       " array([0.52715356, 0.47284644]),\n",
       " array([0.54213483, 0.45786517]),\n",
       " array([0.63951311, 0.36048689]),\n",
       " array([0.65074906, 0.34925094]),\n",
       " array([0.65355805, 0.34644195]),\n",
       " array([0.52715356, 0.47284644]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.59737828, 0.40262172]),\n",
       " array([0.64606742, 0.35393258]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.67134831, 0.32865169]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.66666667, 0.33333333]),\n",
       " array([0.66947566, 0.33052434]),\n",
       " array([0.66104869, 0.33895131]),\n",
       " array([0.66947566, 0.33052434]),\n",
       " array([0.66385768, 0.33614232]),\n",
       " array([0.67696629, 0.32303371]),\n",
       " array([0.65543071, 0.34456929]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.67790262, 0.32209738]),\n",
       " array([0.67790262, 0.32209738]),\n",
       " array([0.6835206, 0.3164794]),\n",
       " array([0.6835206, 0.3164794]),\n",
       " array([0.68071161, 0.31928839]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.82865169, 0.17134831]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.73689139, 0.26310861]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.74438202, 0.25561798]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.8005618, 0.1994382]),\n",
       " array([0.80243446, 0.19756554]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.68258427, 0.31741573]),\n",
       " array([0.68913858, 0.31086142]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.68913858, 0.31086142]),\n",
       " array([0.69756554, 0.30243446]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.71910112, 0.28089888]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dsrf.predict_proba(testing.iloc[:, 0:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.5846228239845261\n",
      "Male accuracy: 0.7627608047690015\n",
      "Female accuracy: 0.2553374655647383\n",
      "ROC_AUC score: 0.5090491351668699\n",
      "Average Precision score: 0.3553857341988309\n"
     ]
    }
   ],
   "source": [
    "# These are the metrics from the classifier that was scored using roc_auc\n",
    "# 22\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Total accuracy: \" + str(accuracy_score(total_labels, dsrf.predict(testing.iloc[:, 0:25]), normalize=True)))\n",
    "print(\"Male accuracy: \" + str(accuracy_score(more_male, dsrf.predict(male_test.iloc[:, 0:25]), normalize=True)))\n",
    "print(\"Female accuracy: \" + str(accuracy_score(more_female, dsrf.predict(female_test.iloc[:, 0:25]), normalize=True)))\n",
    "\n",
    "print(\"ROC_AUC score: \" + str(roc_auc_score(total_labels, dsrf.predict(testing.iloc[:, 0:25]))))\n",
    "print(\"Average Precision score: \" + str(average_precision_score(total_labels, dsrf.predict(testing.iloc[:, 0:25]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76384"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34144"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_mixedequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33088"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "y_pred_rf = dsrf.predict_proba(testing.iloc[:, 0:25])[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(total_labels, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxLOkYIwxJt7/A3bfW1Qw3kANAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.plot()\n",
    "#plt.savefig('bmiroc.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 700, num = 10)]\n",
    "weights=['uniform', 'distance']\n",
    "algorithm=['ball_tree', 'kd_tree', 'brute', 'auto']\n",
    "leaf_size=[20, 30, 50, 70, 80, 100, 200]\n",
    "# Create the random grid\n",
    "random_grid = {'n_neighbors': n_estimators,\n",
    "               'weights': weights,\n",
    "               'algorithm': algorithm,\n",
    "               'leaf_size': leaf_size}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "knn = KNeighborsClassifier(n_neighbors=12)\n",
    "knn.fit(X_mixedequal, male_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6557486631016043"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(female_test.iloc[:, 0:25], more_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35956439393939393"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(male_test.iloc[:, 0:25], more_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666948742746615"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(testing.iloc[:, 0:25], total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16544"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(male_zero).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KNeighborsClassifier' object has no attribute 'decision_function'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-91af1d20a65f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_mixedequal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmale_zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[1;32m    384\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             )\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myList = list(range(10, 300))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = filter(lambda x: x % 50 != 0, myList)\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_mixedequal, male_zero, cv=5, scoring='roc_auc')\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbors = list(filter(lambda x: x % 100 != 0, myList))\n",
    "\n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "y_pred_rf = knn.predict_proba(testing.iloc[:, 0:25])[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(total_labels, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC score: 0.5076565285204991\n",
      "Average Precision score: 0.36529100393372405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "print(\"ROC_AUC score: \" + str(roc_auc_score(total_labels, knn.predict(testing.iloc[:, 0:25]))))\n",
    "print(\"Average Precision score: \" + str(average_precision_score(total_labels, knn.predict(testing.iloc[:, 0:25]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XdcleX7wPHPJUNcuDUVwT3QzIGa\n5myaDbO+llm5MLMsM7VpmY2fXy3NtNy5c2bL1LSd30xLnLlSMhC3uMABMq7fH+dIaKBH5XDgcL1f\nL14+4z7Pcz2KXNzjuW9RVYwxxhiAfJ4OwBhjTM5hScEYY0waSwrGGGPSWFIwxhiTxpKCMcaYNJYU\njDHGpLGkYIwxJo0lBeN1RCRKRM6KyCkROSgiM0Sk8EVlmovIDyISLyInReQrEQm9qEygiLwvInuc\n1/rLuV8qe5/ImOxjScF4q3tUtTBQH2gAvHz+hIg0A74BvgTKA5WBTcAqEaniLOMPfA/UAdoBgUAz\n4CjQxF1Bi4ivu65tjCssKRivpqoHgRU4ksN57wCzVHWMqsar6jFVfRVYAwx1lukKBAMdVXWbqqaq\n6mFVfUtVl2V0LxGpIyLfisgxETkkIq84j88QkbfTlWsjInvT7UeJyIsishk47dxedNG1x4jIWOd2\nURGZKiIHRGSfiLwtIj7X+FdlDGBJwXg5EQkC7gQinfsFgebAJxkUXwjc5ty+FViuqqdcvE8R4Dtg\nOY7aRzUcNQ1XPQzcBRQD5gPtndfE+QP/QWCus+wMINl5jwbA7UCvK7iXMZmypGC81RciEg/EAIeB\n153HS+D4vj+QwWcOAOf7C0pmUiYzdwMHVXWUqiY4ayC/XcHnx6pqjKqeVdVoYD3Q0XnuZuCMqq4R\nkbJAe6C/qp5W1cPAaKDzFdzLmExZUjDe6j5VLQK0AWrxzw/740AqUC6Dz5QDYp3bRzMpk5mKwF9X\nFalDzEX7c3HUHgC68E8tIQTwAw6IyAkROQFMAspcw72NSWNJwXg1Vf0ZR3PLSOf+aWA10CmD4g/y\nT5PPd8AdIlLIxVvFAFUyOXcaKJhu/7qMQr1o/xOgjbP5qyP/JIUYIBEoparFnF+BqlrHxTiNuSRL\nCiYveB+4TURucO6/BHQTkX4iUkREijs7gpsBbzjLzMbxA/hTEaklIvlEpKSIvCIi7TO4xxKgnIj0\nF5H8zus2dZ7biKOPoISIXAf0v1zAqnoE+AmYDvytqtudxw/gGDk1yjlkNp+IVBWR1lfx92LMv1hS\nMF7P+QN2FjDEuf8LcAdwP45+g2gcHbYtVHWXs0wijs7mHcC3QBzwO45mqH/1FahqPI5O6nuAg8Au\noK3z9GwcQ16jcPxAX+Bi6HOdMcy96HhXwB/YhqM5bBFX1tRlTKbEFtkxxhhzntUUjDHGpLGkYIwx\nJo0lBWOMMWksKRhjjEmT6ybfKlWqlFaqVMnTYRhjTK6ybt26WFUtfblyuS4pVKpUiYiICE+HYYwx\nuYqIRLtSzpqPjDHGpLGkYIwxJo0lBWOMMWlyXZ9CRpKSkti7dy8JCQmeDsVtAgICCAoKws/Pz9Oh\nGGO8mFckhb1791KkSBEqVaqEiHg6nCynqhw9epS9e/dSuXJlT4djjPFibms+EpFpInJYRLZkcl5E\nZKyIRIrIZhFpeLX3SkhIoGTJkl6ZEABEhJIlS3p1TcgYkzO4s09hBo4FzzNzJ1Dd+dUbmHAtN/PW\nhHCetz+fMSZncFtSUNWVwLFLFOmAY/F0VdU1QDERsel/jTHmIsdOxvHSvDXsO3HW7ffy5OijCly4\nBOFe57F/EZHeIhIhIhFHjhzJluCuVOHChdO2ly1bRo0aNYiOjmbo0KEULFiQw4cPZ1hWRBg4cGDa\n/siRIxk6dGi2xGyMyflmL/6Ohi/OZ/6mo/yw/ZDb75crhqSq6mRVDVPVsNKlL/uWtkd9//339OvX\nj6+//pqQkBAASpUqxahRozIsnz9/fj777DNiY2MzPG+MyZuOHz9Ou6f/j8E/x0FAIAMaBfBYs0pu\nv68nk8I+HIudnxfkPJZrrVy5kscff5wlS5ZQtWrVtOM9e/ZkwYIFHDv279Y0X19fevfuzejRo7Mz\nVGNMDhYbf5aw/pPZUbg+5X1Ps3JwO/p1uiVb7u3JIamLgadFZD7QFDjpXH/2mrzx1Va27Y+75uDS\nCy0fyOv3XHpd9MTERO677z5++uknatWqdcG5woUL07NnT8aMGcMbb7zxr8/27duXevXq8cILL2Rp\n3MaY3OXo0aP8eVx5buFGKF+HbtcX5vXO7cmXL/sGmrhzSOo8YDVQU0T2iki4iPQRkT7OIsuA3UAk\nMAV4yl2xZAc/Pz+aN2/O1KlTMzzfr18/Zs6cSXx8/L/OBQYG0rVrV8aOHevuMI0xOZCqMnP2x9Tt\n8gpdPlpDofy+fPl0S97o0jpbEwK4saagqg9f5rwCfbP6vpf7jd5d8uXLx8KFC7nlllsYNmwYr7zy\nygXnixUrRpcuXRg3blyGn+/fvz8NGzakR48e2RGuMSaHiImJoWe/F9hSpDH5G9zL7dUK837Xmyjo\n75mGnFzR0ZxbFCxYkKVLlzJnzpwMawwDBgxg0qRJJCcn/+tciRIlePDBBzOtaRhjvM+8efNo0PEJ\n/qx8P4EVqvFB5/pM7tXaYwkBLClkuRIlSrB8+XLefvttFi9efMG5UqVK0bFjRxITEzP87MCBA20U\nkjF5RHxCEp8fKErhW/tyQ3BJfnjxNu6pn+Go/Gwljlac3CMsLEwvXmRn+/bt1K5d20MRZZ+88pzG\neKvk5GRGjx5NzFlfNgTcwL7jZ3n2lur0bVsNXx/3/o4uIutUNexy5bxiQjxjjMnpNm3aRM/wXkT6\nVaZ4q8eo4A8Ln2hGWKUSng7tAtZ8ZIwxbpSYmMhrr71GkzZ3cLjOQxRv3Y27b6jAsmdb5riEAF5U\nU1BVr540Lrc18xljHHbt2sWYRT9S8fHx+OUvwJsd6vKfRkE59ueVV9QUAgICOHr0qNf+4Dy/nkJA\nQICnQzHGuODUqVPMmTOHs+dSmLtLKdHhZWpXLMPSfi3pFFYxxyYE8JKaQlBQEHv37iWnTpaXFc6v\nvGaMydm+/fZbevfuzf4zwqQ9pdlzMoknWlVh4O018ffN+b+He0VS8PPzsxXJjDEedfz4cQYNGsS0\nadOo0i6c4AYdOZuaj9nhTWhZPWdP5JmeVyQFY4zxpJSUFG666SYiYw7S7MVZ7KcErWuU4d3/1KNk\n4fyeDu+KWFIwxpirFBsbS4kSJfDx8aHrC/9lfpQ/sckw9M5adGueO9eMz/kNXMYYk8OoKrNmzaJG\njRpMmvIRw5ZtZ+IOX0oHFuTLvjfR/abKuTIhgNUUjDHmikRHR/PEE0+wYsUKGt9yN5/GVSZy5W4e\naRrMq3eFUsDfx9MhXhNLCsYY46KPP/6YJ598ElWl9/Dp/O/0dZw7q0x6rBF31LnO0+FlCUsKxhjj\notKlS3Njq7ZU7PgCKyJPcmOVoox+qD7lihbwdGhZxpKCMcZkIikpiVGjRpGUlMRrr71GyZqNOdOy\nPz/vjuP5O2rSp3VVfLJ5ERx3s6RgjDEZ2LBhA+Hh4WzYsIGHOj/MmO92Mub7XQQVL8iiPs1oEFzc\n0yG6hY0+MsaYdBISEnjllVdo3Lgx+/fv56O5n5LS+mlGf7eLDvUrsLRfC69NCGA1BWOMuUBkZCQj\nR46ka9eutHv8Zd5esZtUjWf0QzfQsYH3TzVjNQVjTJ536tQpZs+eDUDdunXZuGU7pdv354Uvd1K5\ndGGW9muRJxICWE3BGJPHrVixgt69exMTE0NYWBgpgeXptziGv4+epm/bqvS/tQZ+bl4VLSfJO09q\njDHpHD16lG7dutGuXTsKFizIzytXsio2Px3Hr+LMuRTm9GrK83fUylMJAaymYIzJg9ImsIuMZPDg\nwTzx7PMM/upPVu7czu2hZRnxQD2KF/L3dJgeYUnBGJNnHDlyhJIlS+Lj48OIESMICQnheIHydJz0\nO/EJybx9X10eaRqca+ctygp5q15kjMmTVJXp06dTo0YNpkyZAkDTNncwY4fSY/paShXOz5JnWvDo\njSF5OiGA1RSMMV4uKiqK3r178+2339KyZUtuatWa8T9F8uEPkSSnKk+3rcbTN1cjwC93T2SXVSwp\nGGO81uzZs3nyyScREcaPH0/11h15esl2oo6e4bbQsrx2VyjBJQt6OswcxZqPjDFeq2zZsrRq1Yrl\nq9aztkAYvWatI18+YUaPxkzpGmYJIQNWUzDGeI2kpCTeeecdUlJSGDJkCDe1vpn1KcF0X7CL/L4+\nDG5fm27NK+Hva78PZ8aSgjHGK6xfv56ePXuyadMmHu7ShS827OW/X+/gUFwiDzQM4sV2NSkTGODp\nMHM8SwrGmFzt7NmzvPHGG4wcOZLSpUvzwcef81NcGfov2MT1FYoy/pFGNArx3gnssppbk4KItAPG\nAD7AR6o6/KLzwcBMoJizzEuqusydMRljvMvu3bt577336NKjN6Vv6cmoTYcoUfA0Ix64nk6NKpLP\ny9Y7cDe3NayJiA8wDrgTCAUeFpHQi4q9CixU1QZAZ2C8u+IxxniPuLg4ZsyYAUDNWrV55/M1bAq6\njy82H6Z780r8MKgNDzUOtoRwFdxZU2gCRKrqbgARmQ90ALalK6NAoHO7KLDfjfEYY7zAsmXL6NOn\nD/v27aNASD2mbzrFjoPxNK9akqH31qFG2SKeDjFXc2cXfAUgJt3+Xuex9IYCj4rIXmAZ8ExGFxKR\n3iISISIRR44ccUesxpgcLjY2lscee4y77rqLQqWDeOj95by44gDxCclMeKQhc3o1tYSQBTzd0fww\nMENVR4lIM2C2iNRV1dT0hVR1MjAZICwsTD0QpzHGg85PYLc7Oob7XpnAjnwhrDuUzLO3VKdP66oU\n8Le3kbOKO5PCPqBiuv0g57H0woF2AKq6WkQCgFLAYTfGZYzJJQ4dOkTp0qXJly8f3V4eyeK9fmw4\nlUK7WmUYfFdtKpawl8+ymjubj9YC1UWksoj44+hIXnxRmT3ALQAiUhsIAKx9yJg8TlWZOnUqNWvW\n5L/jptF9+lom78hH4YIF+Di8KRMfa2QJwU3cVlNQ1WQReRpYgWO46TRV3SoibwIRqroYGAhMEZHn\ncHQ6d1dVax4yJg/bvXs3jz/+OD/+spq6Dz3PtP3lKOh/nNfuDqVrs5A8t+hNdpPc9jM4LCxMIyIi\nPB2GMcYNZs6cyVNP9aVAaGvK3v4Ep1N8eDAsiOfvqEXpIvk9HV6uJiLrVDXscuU83dFsjDFp4gKu\nIzh8LGcLlqVa+WK8cW8d6lcs5umw8hRLCsYYjzl37hzDhw/nSHIAJyu1YeXOZMqXC+HN22rwQMMg\ne/nMAywpGGM8Yu3atXR/ehCHyzalUGgjisWcYHD72jzWLMQWvPEgSwrGmGx15swZXhjyNvP+OEHh\n1gMp5puP3q2r0rtVVYoW8PN0eHmeJQVjTLaJT0ji/z5fz+LUhgTWz89/Gpbn+Tvr2JTWOYglBWOM\n2x05epzBM1aw9nQJjp9J4tbQ63jtvgZULlXI06GZi1hSMMa4TUqqMnTGMmatP4oULkmDcr7M7NmE\nekE2oiinsqRgjHGLL37fxSvzf+eMfzF8ks/ySoui9Lq7hafDMpdhScEYk6UiD5/irSVb+XlnLMmn\nz3Br4WNMfL83AQH28lluYEnBGJMlTp5JYtjijXy6+QgF/HzoWEnp+vCNNLjhek+HZq6AJQVjzDVJ\nTkll7m/R/HfJH5xJEeoXOc3U/h0pVdhqBrnRZZOCiBQA+gMhqtpHRKoB1VX1a7dHZ4zJ0VZFxjL4\n0w1EHT9Hwp5tVIvbyOixwywh5GKu1BSmAX8A53uI9gOfAJYUjMmjomJPM2zZdr7ZdoiUk4c4u2Yu\n/32qM716zUPEpqbIzVxJCtVV9WER6QSgqmfE/tWNyZPiE5L48MdIpv8Sha+PcH81XyKXLmXCkplU\nqHDxarsmN3IlKZxzroimACJSGTjn1qiMMTlKSqqyaF0M7674k9hT56ia7whzB3WmbGAA9LrD0+GZ\nLORKUngLWA4EichMoDXQy61RGWNyjN//PsabS7ayZV8c+Y5Fc2DJGNrc3owyRbp5OjTjBpdNCqr6\ntYhEAM0BAZ5XVVtD2RgvF3k4nhHL/+TbbYcooAnELvmQ4nGRfDZlInfddZenwzNu4sroo29U9Xbg\nywyOGWO8zMGTCbz/3U4WRsRQ0N+XrvWL826vO+nR9RGGD/+SwMBAT4do3CjTpCAi/kAAUFZEiuCo\nJQAEAsHZEJsxJhudPJvEpJ//Ytqqv0lOUcICTzPhmQ6ULJyf3i22EhQU5OkQTTa4VE2hLzAAKANs\n5Z+kEAdMdHNcxphskpicwuzV0Xz4YyQnziTRqFQqqycP5rPd23iz4xZK1qplCSEPyTQpqOpoYLSI\n9FfV97MxJmNMNlBVlm85yNtLt7PvxFmahgRyZvXnfDZiIvXq1WPxmjXUqlXL02GabOZKR/P7IlIL\nCMXRnHT++Fx3BmaMcZ/9J84y5MutfLf9ELWuK8LMHmH0ursFe/bs4e233+aFF17Az89WQcuLXOlo\nfhW4HagFrADuAH4BLCkYk8ukpCqzV0fx7oo/SVGl703l6dfuevL7+TJmzBgqVapEaGiop8M0HpTP\nhTIPAW2BA6r6GHADYMslGZPLbD8Qx/0TfmXoV9toFFKcbqVjeOuR1kydMhmA9u3bW0IwLr28dlZV\nU0Qk2TkK6SAQ4ua4jDFZJCEphTHf72LKyt0ULeDHS63LMnf4QGavXMmtt97KnXfe6ekQTQ7iSlLY\nICLFcEyMF4Fj9NHvbo3KGJMltuw7Sd+564k+eoYHw4KoeGwdz91/LwEBAUybNo3u3bvbBHbmApdM\nCs6J74aq6glgnIisAAJVdX22RGeMuWrL/jjAgIUbKVkoP3Mfb0rzqqX4/vtY7rzzTsaNG0e5cuU8\nHaLJgURVL11AZIuq1s2meC4rLCxMIyIiPB2GMTmWqvLBD5G89+1OGlQsSpX931NAknj77bc9HZrx\nIBFZp6phlyvnSkfzRhFpkAUxGWPcLCEphX7zN/LetztpEeTP9vFP8t6woRw4cIDL/QJoDLjWp9AA\nWCsifwGncbzZrKra0K2RGWOuyOG4BB6fvY7NMSeonbSTuf0GUrFiRZYvX84dd9j01sY1riSFe6/2\n4iLSDhgD+AAfqerwDMo8CAzFsV7DJlXtcrX3Myav2rLvJI/PiuDk2SQGtynD0/c9QN++fRk2bBhF\nihTxdHgmF3Hljea/rubCIuIDjANuA/biqG0sVtVt6cpUB14GblLV4yJS5mruZUxetnzLAfov2Ih/\n6jkW9W1LaPlA2u/eTfny5T0dmsmFXOlTuFpNgEhV3a2q54D5QIeLyjwOjFPV4wC2ToMxrlNVPvxh\nF30+Xs+ZfbvY8UE4PvEHACwhmKvmSvPR1aoAxKTb3ws0vahMDQARWYWjiWmoqi6/+EIi0hvoDRAc\nbLN2G5OQlMKzc35nxY5jnNr6I0H7f+aLn76hZs2ang7N5HIu1RREJEhE2jq384tIVk1z4QtUB9oA\nDwNTnC/KXUBVJ6tqmKqGlS5dOotubUzudDg+gc6TV7NixzHiV81hQLOSrF3zKw0b2tgPc+1cmRCv\nJ/A0UBSoimOKi/HArZf56D6gYrr9IOex9PYCv6lqEvC3iOzEkSTWuhS9MXnMjxt28cryPZw4k8QT\ndYSO3YfY9NYmS7nSfNQPR//AbwCqutPFDuG1QHURqYwjGXQGLh5Z9AWOGsJ0ESmFozlpt4uxG5Nn\npKam0n/kdL48VIzAAF8+eaoNdSsU9XRYxgu50nyU4OwoBtJGFV12shRVTcZRw1gBbAcWqupWEXlT\nRM4Pc10BHBWRbcCPwPOqevRKH8IYb7Z9+3bqd3mRxceuo8C5E8x8pI4lBOM2rtQUVonIC0CAs1+h\nL7DElYur6jJg2UXHhqTbVhxLfg5wOWJj8pCJkz/i9aU7KVC7DdcHJrLwzW4U8Hfn+BCT17ny3fUC\njpE/O4Bncfx2P8mdQRlj4Eh8Ip8crUCB2uXo07w8L95T32Y0NW7nSlK4C8fbyBPcHYwxeV1CQgJv\nvvkmx7UgmwKbcewMTHikIXdebzOamuzhSp9CJyBSRKaLSDtnn4IxJoutWrWK+vXr8/4nP/BN6vWk\nKizq09wSgslWl00KziU4awBfAT2A3SIy0d2BGZNXxMfH88wzz9CyZUsSKrWg7AOvUbdiSRY/fZN1\nKJts51KPlaomisiXwFkcbx4/CPRxZ2DG5BV79+7lo2nTaTlgPNG+FWl/fTlGPXgDAX5WKTfZ77I1\nBRG5TUQ+Av4CHgFmAde5OzBjvNnRo0eZMMHRTVehcjXufXcZ0b4VeapNVT54uIElBOMxrtQUegML\ngGdU9ayb4zHGq6kqn376KX379uXYsWPUadKS/1t5jL+OnOKdB+rxYOOKl7+IMW7kytTZnbIjEGO8\n3YEDB+jbty+ff/45jRo1Yty8JQz4+iCJySnM7NmEm6qV8nSIxmSeFETkZ1VtLSLHcSyAk3YKx3tn\nJdwenTFeIiUlhZYtW7Jv3z7eeecd6tzRhQGfbKZU4fzMe7wp1cvaQjgmZ7hUTaGt80/79cWYqxQT\nE0OFChXw8fFh3LhxVKpUiZWH/Og7byM3BBVjStcwShfJ7+kwjUmTaUezqqY6N6eqakr6L2Bq9oRn\nTO6UkpLC2LFjqVWrVlqH8i233sasbef4v2XbubPudczvfaMlBJPjuNLRXC/9jvPltcbuCceY3G/7\n9u2Eh4ezevVq7rzzTu655x7iE5J4eu4Gft55hCfbVOX522uSL59NWWFynkxrCiLyorM/oZ6IHHN+\nHQeOcNEkd8YYh8mTJ1O/fn127tzJ7NmzWbp0KT6Bpek0cTW/RMYy/P7rebFdLUsIJse6VE3hHWAU\n8F/gpfMHnc1HxpgMVK9enY4dOzJ27FjKlCnDH3tP0nPmWhLOpTCzRxNaVLcuOpOziWP26gxOiFRX\n1V0iUi+j86q62a2RZSIsLEwjIiI8cWtj/uXs2bMMHToUEWH48OEXnPtm60Genb+REoX8md6jMTVs\nhJHxIBFZp6phlyt3qZrCS0A4MC6Dcwq0usrYjPEKK1eupFevXuzatYs+ffqgqogIqsrUX/7m/5Zt\np15QMT6yEUYmF8k0KahquPPPltkXjjE5X1xcHC+99BITJkygSpUqfP/999x8880AJKek8sZX25i9\nJpo7617Hew/Wp4C/TVlhcg9X5j66X0SKOLdfEpGFInKD+0MzJmfav38/M2bMYMCAAWzevDktIZxK\nTKbXrAhmr4nmidZVGNeloSUEk+u4MiR1qKp+JiLNgfY4Op8nATe6NTJjcpDY2FgWLlzIU089Ra1a\ntfj7778pW7Zs2vn9J87Sc8Zadh0+xbCO19OlabAHozXm6rmyyM750UZ3A5NU9UvAGkhNnqCqLFiw\ngNDQUPr378/OnTsBLkgIW/ad5L5xq9h3/CzTuze2hGByNVeSwgERGQd0BpaJiL+LnzMmV9u/fz/3\n3XcfnTt3JiQkhHXr1lGjRo0Lyny37RCdJq7Gzycfi55sTqsapT0UrTFZw5XmowdxNBt9oKrHRaQ8\n6d5bMMYbpaSk0KpVK/bt28fIkSN59tln8fX957+LqjJ9VRRvLd3G9RWK8lG3MMoUCfBgxMZkDVem\nzj4lIluBNiLSBvifqn7t9siM8YDo6GiCgoLw8fFh/PjxVKlShWrVql1QJjkllbeWbGPm6mjuqFOW\n9x9qYB3Kxmu4MvroaeATINj5tVBEnnJ3YMZkp5SUFN577z1q166dNoHd7bff/q+EcCoxmcdnRTBz\ndTS9W1VhwiONLCEYr+LqymtNVPUUgIgMA34FxrszMGOyy5YtWwgPD+f333/n7rvv5r777suw3IGT\nZ+k5I4Kdh+J5+766PHpjSDZHaoz7uZIUBDiXbj/JecyYXG/ixIn069ePokWLMnfuXDp37ozIv7+9\nt+w7SfjMtZxOTGFa98a0tg5l46VcSQqzgd9E5FMcyeA+YKZbozLGzc5PSVG7dm06derE+++/T+nS\nGf+g/377IZ6Zt4FiBfxY9GQzal0XmM3RGpN9Mp0Q74JCIk2AFjjmPPpFVde6O7DM2IR45lqcOXOG\nIUOG4OPjw4gRIy5bfvqqv3lryTbqlC/K1G5hlAm0EUYmd3J1QjxX3zdIABLT/WlMrvPTTz9Rr149\nRo0axalTp7jUL0QpqcrQxVt546tt3Fq7LAueuNESgskTXBl9NBiYB5QDgoC5IvKyuwMzJqucPHmS\nJ554grZtHcuO//DDD4wbNy7DvgOA04nJ9J4VwYxfo3i8ZWUmPNqIgv6utLQak/u58p3eFWigqmcA\nROT/gA04Ft8xJsc7cOAAH3/8MYMGDeKNN96gYMGCmZY9eDKB8Jlr2X4gjrfuq8tjNsLI5DEuTXPB\nhcnD13nsskSknYj8KSKRIpLpW9Ai8oCIqIhctr3LGFccOXKEDz74AIBatWoRFRXFu+++e8mEsHW/\nYw6jqNjTTO3e2BKCyZNcSQrHgK0i8pGITAH+AGJF5D0ReS+zD4mID44Feu4EQoGHRSQ0g3JFgGeB\n367mAYxJT1WZO3cutWvXZuDAgWkT2GU2sui8H3Y45jASgUVPNqdtzTLZEa4xOY4rzUdLnV/nrXHx\n2k2ASFXdDSAi84EOwLaLyr0FjACed/G6xmQoJiaGJ598kqVLl9K0aVOmTp36rwnsMjLz1yje+Gor\noeUDmdqtMWWtQ9nkYa7MfTT1Kq9dAYhJt78XaJq+gIg0BCqq6lIRyTQpiEhvHG9WExxs0xKbf0tO\nTqZNmzYcPHiQ0aNH88wzz+Djc+npJ1JSlbeXbmP6qihurV2WsQ/Xtw5lk+d57H+AiOQD3gO6X66s\nqk4GJoPjPQX3RmZyk6ioKCpWrIivry+TJk2iSpUqVKlS5bKfO52YzLPzN/Dd9sOEt6jMK+1r45PP\nXtQ3xp3rIuwDKqbbD3IeO68IUBf4SUSicKzkttg6m40rkpOTGTlyJLVr12b8eMc0XLfeeqtLCeFQ\nXAIPTlrNDzsO82aHOrx2d6ixp8UAAAAX00lEQVQlBGOcXK4piEh+Vb2SF9fWAtVFpDKOZNAZ6HL+\npKqeBEqlu/5PwCBVtdeVzSVt3ryZ8PBwIiIi6NChAw888IDLn922P47wmWuJO5vE1G6NaVvLOpSN\nSc+Vl9eaiMgfwC7n/g0i8sHlPqeqycDTwApgO7BQVbeKyJsicu81xm3yqPHjx9OoUSOio6NZsGAB\nn3/+OeXLl3fpsz/+eZhOE39FFT7p09wSgjEZcKWmMBbH+sxfAKjqJhFp68rFVXUZsOyiY0MyKdvG\nlWuavOn8BHZ169alc+fOjB49mlKlSl3+g06zV0fx+uKt1C7nGGF0XVEbYWRMRlxJCvlUNfqiKQFS\n3BSPMRc4ffo0r776Kr6+vrz77ru0atWKVq1aufz5lFRl2LLtTP3lb26tXYYxnRtQKL+NMDImM650\nNMc4Z0lVEfERkf7ATjfHZQzff/89119/Pe+//z6JiYmXnMAuI2fOJdPn43VM/eVvetxUiUmPhVlC\nMOYyXPkf8iSOJqRg4BDwnfOYMW5x4sQJBg0axNSpU6levTorV66kZcuWV3SNQ3EJ9JoZwdb9Jxl6\nTyjdb6rspmiN8S6uvLx2GMfIIWOyxaFDh5g/fz4vvvgir7/+OgUKFLiiz28/EEf4jLWcOJvER93C\nuLlWWTdFaoz3uWxScM539K96u6r2dktEJk86nwieffZZatasSVRU1BV1JJ/305+HeXruBgrl9+GT\nPs2oU76oG6I1xnu50nz0XbrtAKAjF05fYcxVU1XmzJnDs88+y6lTp2jfvj3Vq1e/qoQwe000Qxdv\npWbZIkztHka5oldWwzDGuNZ8tCD9vojMBn5xW0Qmz9izZw99+vTh66+/plmzZml9CFcqJVX577Lt\nfPTL39xcqwwfPGwjjIy5WlfzP6cyYI205pqcn8Du8OHDjB07lqeeeuqyE9hl5My5ZPrP38g32w7R\nvXklm7LCmGvkSp/Ccf7pU8iHY32FTBfMMeZSdu/eTUhICL6+vkyZMoWqVatSqVKlq7rW4bgEes2K\nYMu+k7x+Tyg9bISRMdfsku8piOONtRuA0s6v4qpaRVUXZkdwxnskJyczYsQIQkNDGTduHAC33HLL\nVSeEHQfjuG/cKiIPn2LyY2GWEIzJIpesKaiqisgyVa2bXQEZ77Nx40bCw8NZv349HTt2pFOnTtd0\nvZ93HqHvnPUUyu/DwieaUbeCjTAyJqu48kbzRhFp4PZIjFf68MMPady4Mfv27WPRokV89tlnlCtX\n7qqvN+e3aHrOWEvFEgX5ou9NlhCMyWKZ1hRExNc502kDYK2I/AWcBgRHJaJhNsVocqHzE9jVq1eP\nRx55hPfee48SJUpc9fVSU5Xhy3cweeVu2tYszQddGlLYRhgZk+Uu9b/qd6AhYNNcG5edOnWKwYMH\n4+fnx8iRI694AruMnD2XwnMLNrJ860G6NgthyN2h+Pq4c30oY/KuSyUFAVDVv7IpFpPLffPNN/Tu\n3Zs9e/bwzDPPpNUWrsXh+AQenxnB5n0nGXJ3KD1uqnTN1zTGZO5SSaG0iAzI7KSqvueGeEwudPz4\ncQYMGMCMGTOoWbMmK1eupEWLFtd83T8PxtNzxlqOnT7H5MfCuC3UXo8xxt0ulRR8gMI4awzGZObw\n4cMsWrSIl19+mSFDhhAQcO0L2Pxv1xGe+ng9BfwdI4yuD7IOZWOyw6WSwgFVfTPbIjG5ysGDB5k3\nbx7PPfdc2gR2JUuWzJJrz/t9D69+sYXqZQozrXtjyhezOYyMyS6X6q2zGoL5F1Vl5syZhIaG8vLL\nL7Nr1y6ALEkIqanKf7/ezsuf/UGLaqX4pE8zSwjGZLNLJYVbsi0KkytERUXRrl07unfvTmhoKBs3\nbryqCewykpCUQt+565n0824evTGYqd3CKBLglyXXNsa4LtPmI1U9lp2BmJwtOTmZtm3bEhsby7hx\n4+jTpw/58mXNsNAj8Yn0mhXB5r0nePWu2oS3qGwjjIzxEHv7x1xSZGQklStXxtfXl2nTplGlShVC\nQkKy7Pq7DsXTfbpjhNHERxtxR53rsuzaxpgrZ28AmQwlJSUxbNgw6tSpkzaBXdu2bbM0IfyyK5b7\nJ/zKuZRUFjxxoyUEY3IAqymYf1m/fj3h4eFs3LiRTp068dBDD2X5PeY7RxhVLV2YaT0aU8E6lI3J\nEaymYC4wduxYmjRpwsGDB/nss89YuHAhZctm3UtjqanKiOU7eOmzP2herRSLnmxmCcGYHMRqCgb4\nZwK7Bg0a0LVrV0aNGkXx4sWz9B4JSSkMXLiJpX8coEvTYN68t47NYWRMDmNJIY+Lj4/n5ZdfJn/+\n/IwaNYqWLVvSsmXLLL1H7KlENuw5wfifItkYc4LB7WvTq6WNMDImJ7KkkIctX76cJ554gpiYGPr3\n758lE9glpaSy40A8G2KOsz76OOv3nGDPsTMAFPL3YcIjjWhX1zqUjcmpLCnkQUePHmXAgAHMmjWL\n2rVrs2rVKpo1a3ZV1zoSn8j6PcdZv+c4G/acYPPeEyQkpQJQpkh+GgYX59Ebg2kYXJy6FYoS4OeT\nlY9ijMlilhTyoKNHj/L555/z2muvMXjwYPLnz+/S55JSUtl+IC6tBrAh5jgxx84C4Ocj1ClflIeb\nOBJAw5DilC8aYE1ExuQybk0KItIOGINjxtWPVHX4RecHAL2AZOAI0FNVo90ZU1514MAB5syZw8CB\nA6lRowbR0dGX7Ug+HJ/A+ugTbHDWBDbvPUlisqMWcF1gAA1DitH1xko0DClGnfJWCzDGG7gtKYiI\nDzAOuA3Yi2NJz8Wqui1dsQ1AmKqeEZEngXeArB8Un4epKtOnT2fAgAEkJibSoUMHqlev/q+EcC7Z\nWQvY46gFrI8+zr4TjlqAv08+6lQI5NEbQ2gQXIyGwcVtojpjvJQ7awpNgEhV3Q0gIvOBDkBaUlDV\nH9OVXwM86sZ48py///6b3r17891339GqVSumTJmSNoHdobgEZw3AkQD+2PdPLaBc0QAaBhenx02V\naBBcnLoVAsnva7UAY/ICdyaFCkBMuv29QNNLlA8Hvs7ohIj0BnoDBAcHZ1V8Xi05OZmbb76Zo0eP\n8uH4CTRr/yC/xJxkbMR6Nuw5cUEtoG6FQB67MYSGIcVpEFyMckWtFmBMXpUjOppF5FEgDGid0XlV\nnQxMBggLC9NsDC3X2bVrFwVLlmfTvjjueHEiexP8GbMvgXcnrAagfNEAGoQUp2eLyjQILkad8lYL\nMMb8w51JYR9QMd1+kPPYBUTkVmAw0FpVE90Yj9fatj+OX3YdZt63a4g8loxPYGkA/H3zcX2F/HRr\nVpaGwcVpEFyc64pe+1KZxhjv5c6ksBaoLiKVcSSDzkCX9AVEpAEwCWinqofdGItXik9IYtiy7cz7\n3dFKl3wyibK+Z+jWpiGt6gQTWi4Qf1+bRsIY4zq3JQVVTRaRp4EVOIakTlPVrSLyJhChqouBd4HC\nwCfO8ex7VPVed8XkTX7ZFcuLn25m/4kzxP32GQVi1jDhveHce28PT4dmjMnF3NqnoKrLgGUXHRuS\nbvtWd97fG51KTGbYsu3M/W0PVUoX4vUWRfj1mC/vfP4rxYoV83R4xphcLkd0NBvXrIqM5flPNrL/\nRALVUqJZ0q8PAX4+dL87w/55Y4y5YtbgnAucTkzm1S/+4JGPfmNfTDSH5r5IA4kiv/UXGGOymNUU\ncrhf/4pl0IKN7D+ZQNzaLygXG8HCRdNo2vRSr3wYY8zVsV81c6jTickM+XILXab8BqQS98Ub9GsV\nxIaI3y0hGGPcxmoKOdCa3UcZMH89++MS6XlTZZ6/oxaJTzWxjmRjjNtZUshBzpxLZsTXO5i5OpqU\nkweJ+3YcXXotpIC/DwX8LSEYY9zPkkIO8fvfx+g/L4L9cUnERSzmev2bqcsXUq1aNU+HZozJQywp\neNjZcym8s2IHM36NQuOPEPfdBIYPCKdXrwnky2ddPsaY7GVJwYPWRh3j2TkR7I9PoluzEG4qXIjQ\nlz4lKCjI06EZY/IoSwoecPZcCiO+3saM1dEknzxM58rJvNHhLk+HZYwxlhSy27roYzw9+3cOnEoh\nfv1Sbitzhpd6jvJ0WMYYA1hSyDYJSSmM+uZPpvxvN8knDyO/z2HmG89x9913ezo0Y4xJY0khG6zf\nc5xBn2xi95HT3BKSH9m0jlE/fEbRokU9HZoxxlzAkoIbJSSlMHzpH8xYvZcCJPBxrza0qF4KuM3T\noRljTIYsKbjJxpgT9Jn2CwfPCqc2r+D+ekW4qdoDng7LGGMuyZJCFktMTmHY4k3M/G0fyfGxBO5Y\nwicjXqJx48aeDs0YYy7LkkIW2hRzgkGfbGLX4VMk7viZ8IbFGPL+PPz9/T0dmjHGuMSSQhZITE7h\n7c/X8/G6Q1xXtAAzejSmwXUtrCPZGJPrWFK4RptijtNr8k8cSfLn7NYfmTCiN/VrlvF0WMYYc1Us\nKVylc8mpvLHoN+ZsiCX5VDwVD65kzphXqFKliqdDM8aYq2ZJ4Sps2XeSgQs38uehUyT++T9eu6s2\nT/aagoh4OjRjjLkmlhSuwLnkVIZ+spoFf5ykZCF/BoYV4IF+/SlfvrynQzPGmCxhScFFG6Ni6THp\nB45rIWoHxDH/uf9QtKCfp8MyxpgsZUnhMpJSUnl59k8s2naK5DOJ3JC4nlnDn7eEYIzxSpYULmHb\n/ji6jv+W2OQANDqC9x+5kf/cO9zTYRljjNtYUshAUkoq43+M5IMfIinkV4BGcWuZPmUQgYGBng7N\nGGPcypLCRdbu3EfPST8S71ecDvXLM/SeOhQv1N7TYRljTLawpOCUnJJKv4lLWBqlpJ4T2vhv5/2H\n2tswU2NMnmJJAVi9LYrwKT9zJn8p/A9vZkqf22jT7BFPh2WMMdkuTyeF5JRUJq3czfvf7iQx1Y/b\nC0Qx4aNB+PnZyCJjTN6UZ5PCyo07GbhwI0dSC3FXvXK8cHNTQq4r6emwjDHGo9yaFESkHTAG8AE+\nUtXhF53PD8wCGgFHgYdUNcqdMZ1LSubxUfP56Whh9FwKr99VnvDbG7jzlsYYk2vkc9eFRcQHGAfc\nCYQCD4tI6EXFwoHjqloNGA2McFc8AN/+9gd1+0/n5xPFKRIXxZd9GltCMMaYdNyWFIAmQKSq7lbV\nc8B8oMNFZToAM53bi4BbxE3Dfeb/Fs3ji/4iwbcI/ykfx+YJ/WhQu5o7bmWMMbmWO5uPKgAx6fb3\nAk0zK6OqySJyEigJxKYvJCK9gd4AwcHBVxVMtbJFaFyhAEPvbkidald3DWOM8Xa5oqNZVScDkwHC\nwsL0aq4RVqkEn/S/I0vjMsYYb+PO5qN9QMV0+0HOYxmWERFfoCiODmdjjDEe4M6ksBaoLiKVRcQf\n6AwsvqjMYqCbc/s/wA+qelU1AWOMMdfObc1Hzj6Cp4EVOIakTlPVrSLyJhChqouBqcBsEYkEjuFI\nHMYYYzzErX0KqroMWHbRsSHpthOATu6MwRhjjOvc2XxkjDEml7GkYIwxJo0lBWOMMWksKRhjjEkj\nuW0EqIgcAaKv8uOluOht6TzAnjlvsGfOG67lmUNUtfTlCuW6pHAtRCRCVcM8HUd2smfOG+yZ84bs\neGZrPjLGGJPGkoIxxpg0eS0pTPZ0AB5gz5w32DPnDW5/5jzVp2CMMebS8lpNwRhjzCVYUjDGGJPG\nK5OCiLQTkT9FJFJEXsrgfH4RWeA8/5uIVMr+KLOWC888QES2ichmEfleREI8EWdWutwzpyv3gIio\niOT64YuuPLOIPOj8t94qInOzO8as5sL3drCI/CgiG5zf3+09EWdWEZFpInJYRLZkcl5EZKzz72Oz\niDTM0gBU1au+cEzT/RdQBfAHNgGhF5V5Cpjo3O4MLPB03NnwzG2Bgs7tJ/PCMzvLFQFWAmuAME/H\nnQ3/ztWBDUBx534ZT8edDc88GXjSuR0KRHk67mt85lZAQ2BLJufbA18DAtwI/JaV9/fGmkITIFJV\nd6vqOWA+0OGiMh2Amc7tRcAtIiLZGGNWu+wzq+qPqnrGubsGx0p4uZkr/84AbwEjgITsDM5NXHnm\nx4FxqnocQFUPZ3OMWc2VZ1Yg0LldFNifjfFlOVVdiWN9mcx0AGapwxqgmIiUy6r7e2NSqADEpNvf\n6zyWYRlVTQZOAiWzJTr3cOWZ0wvH8ZtGbnbZZ3ZWqyuq6tLsDMyNXPl3rgHUEJFVIrJGRNplW3Tu\n4cozDwUeFZG9ONZveSZ7QvOYK/3/fkXcusiOyXlE5FEgDGjt6VjcSUTyAe8B3T0cSnbzxdGE1AZH\nbXCliFyvqic8GpV7PQzMUNVRItIMx2qOdVU11dOB5UbeWFPYB1RMtx/kPJZhGRHxxVHlPJot0bmH\nK8+MiNwKDAbuVdXEbIrNXS73zEWAusBPIhKFo+11cS7vbHbl33kvsFhVk1T1b2AnjiSRW7nyzOHA\nQgBVXQ0E4Jg4zlu59P/9anljUlgLVBeRyiLij6MjefFFZRYD3Zzb/wF+UGcPTi512WcWkQbAJBwJ\nIbe3M8NlnllVT6pqKVWtpKqVcPSj3KuqEZ4JN0u48r39BY5aAiJSCkdz0u7sDDKLufLMe4BbAESk\nNo6kcCRbo8xei4GuzlFINwInVfVAVl3c65qPVDVZRJ4GVuAYuTBNVbeKyJtAhKouBqbiqGJG4ujQ\n6ey5iK+di8/8LlAY+MTZp75HVe/1WNDXyMVn9iouPvMK4HYR2QakAM+raq6tBbv4zAOBKSLyHI5O\n5+65+Zc8EZmHI7GXcvaTvA74AajqRBz9Ju2BSOAM0CNL75+L/+6MMcZkMW9sPjLGGHOVLCkYY4xJ\nY0nBGGNMGksKxhhj0lhSMMYYk8aSgsmxRCRFRDam+6p0ibKVMptVMruJSJiIjHVutxGR5unO9RGR\nrtkYS/3cPmuoyV5e956C8SpnVbW+p4O4Us4X5M6/JNcGOAX86jw3MavvJyK+zjm8MlIfx7Qmy7L6\nvsY7WU3B5CrOGsH/RGS986t5BmXqiMjvztrFZhGp7jz+aLrjk0TEJ4PPRonIOyLyh7NstXT3/UH+\nWY8i2Hm8k4hsEZFNIrLSeayNiCxx1mz6AM8579lSRIaKyCARqSUiv1/0XH84txuJyM8isk5EVmQ0\nA6aIzBCRiSLyG/COiDQRkdXiWFPgVxGp6XwD+E3gIef9HxKRQuKYr/93Z9mMZpY1eZmn5w63L/vK\n7AvHG7kbnV+fO48VBAKc29VxvNUKUAnn/PPAB8Ajzm1/oABQG/gK8HMeHw90zeCeUcBg53ZXYIlz\n+yugm3O7J/CFc/sPoIJzu5jzzzbpPjcUGJTu+mn7zueq7Nx+EXgVx5urvwKlnccfwvEW78VxzgCW\nAD7O/UDA17l9K/Cpc7s78GG6zw0DHj0fL465kQp5+t/avnLOlzUfmZwso+YjP+BDEamPI2nUyOBz\nq4HBIhIEfKaqu0TkFqARsNY5zUcBILM5oOal+3O0c7sZcL9zezbwjnN7FTBDRBYCn13Jw+GYxO0h\nYLjzz4eAmjgm8vvWGacPkNm8Np+oaopzuygw01krUpzTImTgduBeERnk3A8AgoHtVxi78VKWFExu\n8xxwCLgBR/PnvxbPUdW5zmaVu4BlIvIEjlWqZqrqyy7cQzPZ/ndB1T4i0tR5r3Ui0si1xwBgAY65\nqD5zXEp3icj1wFZVbebC50+n234L+FFVOzqbrX7K5DMCPKCqf15BnCYPsT4Fk9sUBQ6oY678x3D8\nJn0BEakC7FbVscCXQD3ge+A/IlLGWaaEZL5O9UPp/lzt3P6VfyZOfAT4n/M6VVX1N1UdgmNmzvRT\nGgPE45jG+19U9S8ctZ3XcCQIgD+B0uJYFwAR8ROROpnEmV5R/pk+ufsl7r8CeEac1RBxzJ5rTBpL\nCia3GQ90E5FNQC0u/G35vAeBLSKyEUdTzCxV3Yajzf4bEdkMfAtktoRhcWeZZ3HUTMCxmlcP5/HH\nnOcA3nV2Sm/BkTg2XXStr4CO5zuaM7jXAuBR/lkP4ByO6dxHOJ9xI/CvzvQMvAP8V0Q2cGELwI9A\n6PmOZhw1Cj9gs4hsde4bk8ZmSTUmHXEsyBOmqrGejsUYT7CagjHGmDRWUzDGGJPGagrGGGPSWFIw\nxhiTxpKCMcaYNJYUjDHGpLGkYIwxJs3/AxQZaxezvWfpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='KNN')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.plot()\n",
    "#plt.savefig('bmiroc.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - BMI Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "tengaps_total  = pd.read_hdf('tengaps_total.h5', 'df')\n",
    "\n",
    "# Min number of samples is 352... total subjects after filtering is 311\n",
    "tengaps_total = min_df(find_lowest_num_samples(tengaps_total), tengaps_total)\n",
    "\n",
    "\n",
    "tengaps_bmi = tengaps_total[tengaps_total.weight < 400]\n",
    "tengaps_bmi = tengaps_total[tengaps_total.weight > 80]\n",
    "\n",
    "# this dataframe doesn't have demographic data\n",
    "tengaps_bmi = tengaps_total.drop(columns=['sex', 'currentAge', 'weight', 'height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BMI = []\n",
    "for q in list(set(tengaps_total.index.values)):\n",
    "    temp = []\n",
    "    temp.append(((tengaps_total.loc[q].weight.values) / (((tengaps_total.loc[q].height.values)**2))) * 703)\n",
    "    BMI.append(temp)\n",
    "    \n",
    "BMI = np.array(BMI)\n",
    "BMI = BMI.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bins(BMI):\n",
    "    '''\n",
    "    Returns a list of bins (labels) depending on the BMI category\n",
    "    0 - severely underweight\n",
    "    1 - underweight\n",
    "    2 - normal\n",
    "    3 - overweight\n",
    "    4 - severely overweight\n",
    "    '''\n",
    "    bins = []\n",
    "    for x in range(0, len(BMI)):\n",
    "        if BMI[x] < 18.5:\n",
    "            bins.append(0)\n",
    "        elif BMI[x] >= 18.5 and BMI[x] < 25:\n",
    "            bins.append(1)\n",
    "        elif BMI[x] >= 25 and BMI[x] < 30:\n",
    "            bins.append(2)\n",
    "        else:\n",
    "            bins.append(3)\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_bins = create_bins(BMI)\n",
    "tengaps_bmi.insert(25, 'BMIbins', final_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell is dedicated to creating a balanced class training set\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numOfTotalHC = 311\n",
    "numOfTrainHC = 186\n",
    "numOfTestHC = 125\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "training = tengaps_bmi.iloc[0:(numOfTrainHC * find_lowest_num_samples(tengaps_bmi))]\n",
    "\n",
    "X = np.array(training.iloc[:, 0:25])\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y = np.array(training.iloc[:, 25])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_mixed = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixed = np.concatenate((y_train, y_test), axis=0)\n",
    "# Splits the training and testing into 80/20 with no sample scrambling\n",
    "# Must scramble after so that training set has no test samples in it\n",
    "#training = everything.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = tengaps_bmi.iloc[(numOfTrainHC * find_lowest_num_samples(tengaps_bmi)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfbmi = RandomForestClassifier(n_estimators=30)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "#rf_bmi = RandomizedSearchCV(estimator = rfbmi, param_distributions = random_grid, n_iter = 20, scoring='accuracy', cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rfbmi.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "bestrf = RandomForestClassifier(n_estimators=45, min_samples_split=2, min_samples_leaf=2, max_depth=50, bootstrap=False, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=45, n_jobs=1,\n",
       "            oob_score=False, random_state=22, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestrf.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3642750176180409"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestrf.score(testing.iloc[:, 0:25], testing.iloc[:, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  132  191   29]\n",
      " [   0 9428 5156 3016]\n",
      " [   0 9315 5322 2259]\n",
      " [   0 6497 2272 1791]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(str(confusion_matrix(testing.iloc[:, 25], bestrf.predict(testing.iloc[:, 0:25]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor - BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "tengaps_total  = pd.read_hdf('tengaps_total.h5', 'df')\n",
    "\n",
    "# Min number of samples is 352... total subjects after filtering is 311\n",
    "tengaps_total = min_df(find_lowest_num_samples(tengaps_total), tengaps_total)\n",
    "\n",
    "\n",
    "tengaps_bmi = tengaps_total[tengaps_total.weight < 400]\n",
    "tengaps_bmi = tengaps_total[tengaps_total.weight > 80]\n",
    "\n",
    "# this dataframe doesn't have demographic data\n",
    "tengaps_bmiflat = tengaps_total.drop(columns=['sex', 'currentAge', 'weight', 'height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BMI = []\n",
    "for q in list(set(tengaps_total.index.values)):\n",
    "    temp = []\n",
    "    temp.append(((tengaps_total.loc[q].weight.values) / (((tengaps_total.loc[q].height.values)**2))) * 703)\n",
    "    BMI.append(temp)\n",
    "    \n",
    "BMI = np.array(BMI)\n",
    "BMI = BMI.flatten()\n",
    "tengaps_bmiflat.insert(25, 'BMI', BMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell is dedicated to creating a balanced class training set\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numOfTotalHC = 311\n",
    "numOfTrainHC = 186\n",
    "numOfTestHC = 125\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "training = tengaps_bmiflat.iloc[0:(numOfTrainHC * find_lowest_num_samples(tengaps_bmiflat))]\n",
    "\n",
    "X = np.array(training.iloc[:, 0:25])\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y = np.array(training.iloc[:, 25])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_mixed = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixed = np.concatenate((y_train, y_test), axis=0)\n",
    "# Splits the training and testing into 80/20 with no sample scrambling\n",
    "# Must scramble after so that training set has no test samples in it\n",
    "#training = everything.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = tengaps_bmiflat.iloc[(numOfTrainHC * find_lowest_num_samples(tengaps_bmiflat)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 1000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfreg = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_rand_reg = RandomizedSearchCV(estimator = rfreg, param_distributions = random_grid, n_iter = 5, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_rand_reg.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=90,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=4, min_samples_split=10,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=230, n_jobs=1,\n",
       "           oob_score=False, random_state=22, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfregfinal = RandomForestRegressor(n_estimators=230, min_samples_split=10, min_samples_leaf=4, max_depth=90, bootstrap=False, random_state=22)\n",
    "rfregfinal.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.007860755320008073"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WORSE THAN A HORIZONTAL LINE... BAD\n",
    "rfregfinal.score(testing.iloc[:, 0:25], testing.iloc[:, 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor - BMI Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kbmi = KNeighborsClassifier(n_neighbors=9)\n",
    "kbmi.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38909443269908384"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbmi.score(testing.iloc[:, 0:25],testing.iloc[:, 25])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
