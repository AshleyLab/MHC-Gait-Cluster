{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6MWT Total Sample Check\n",
    "\n",
    "### healthCodes of interest/associated synapse table:\n",
    "\n",
    "1. cab9f4ee-54e0-4b08-8eba-3b48085bd142 (v4-v1)\n",
    "2. 33f22bad-4570-43bb-bf68-263e6865ef76 (v4-v1)\n",
    "3. ff489c8a-f5ff-4f00-9682-33c44df02621 (v4-v2)\n",
    "4. 6fd3148e-f490-417a-9da8-a31d947e7aed (v4-v1)\n",
    "5. bb6613c1-5b48-4744-a5f5-2387149da94d (v4-v2)\n",
    "6. 43dcb6b4-24a9-4b71-bc9f-eef87e8adadb (v4-v2)\n",
    "7. fe1e5f81-ed68-4c45-b1a7-3a7443d5ae76 (v4-v2)\n",
    "8. 047b75f9-2778-4068-bc30-d47e8ea0780e (v4-v1)\n",
    "9. c6a9c011-defc-48a9-bd74-de6d3a72d2bd (v4-v2)\n",
    "10. e30dae44-8b7e-41a5-98e5-3f8abba35352 (v4-v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "# hc_filenum is the dictionary which stores the healthCode and num of files associated with that healthCode\n",
    "\n",
    "# num_of_files is just a list to count number of instances of certain number of files (Are there 0 files, 1 file...?)\n",
    "\n",
    "directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwt/accel_walk_dir'\n",
    "directory = os.fsencode(directory_in_str)\n",
    "hc_filenum = dict()\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    i = 0\n",
    "    for file in files:\n",
    "        i += 1\n",
    "    hc_filenum.update({subdir.decode()[subdir.decode().rfind('/') + 1:]: i})\n",
    "\n",
    "\n",
    "num_of_files = []\n",
    "for k, v in hc_filenum.items():\n",
    "        num_of_files.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291\n",
      "8129\n"
     ]
    }
   ],
   "source": [
    "print(num_of_files.count(0))\n",
    "print(len(hc_filenum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>healthCode</th>\n",
       "      <th>weight</th>\n",
       "      <th>weight2</th>\n",
       "      <th>sex</th>\n",
       "      <th>sex2</th>\n",
       "      <th>height</th>\n",
       "      <th>height2</th>\n",
       "      <th>currentAge</th>\n",
       "      <th>currentAge2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77f77904-6969-4b69-b408-131d7e434938</td>\n",
       "      <td>9c0a77cd-159b-423b-8e73-b7f3666ba938</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de3b154b-fe81-4ef7-b392-e51c36137e12</td>\n",
       "      <td>c4ed1db6-9bc0-46e5-a296-fd452a773072</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fd22a4b-b573-4a14-9503-9f4027a1822c</td>\n",
       "      <td>e4c01bfb-9688-4b96-9e80-137b3b0a6a4c</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8712c75a-2a69-41d7-9baf-eb3569e011af</td>\n",
       "      <td>c4ed1db6-9bc0-46e5-a296-fd452a773072</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2ee84b1b-ce33-405f-a27e-ab9ca150fe3b</td>\n",
       "      <td>90ccc54e-7916-4042-871b-bc25cc58867e</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ba83c4a7-1bb8-46b6-829b-e6ef7ff9696c</td>\n",
       "      <td>7008bee7-5a68-46a9-80a0-0f280df94f6d</td>\n",
       "      <td>221.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>03793227-ab8f-41ff-bc17-039b6eaa56db</td>\n",
       "      <td>d670264b-3edc-4d1f-b42d-6430bf9efb70</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43828c79-e658-4eca-a9ac-9fa27329fe4b</td>\n",
       "      <td>620e7c23-16bf-4b7c-80a1-af3a15e900a2</td>\n",
       "      <td>217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6788bff0-b65c-406f-b4c0-7f4a0cfdae20</td>\n",
       "      <td>74982b88-b3b3-4aa4-a7f1-715df241ab44</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bd5a34bc-7617-4ed2-a888-b57a1830f419</td>\n",
       "      <td>280f17b1-8b9e-40b5-9dd5-9c6d1e1b10ee</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99482689-3851-4ed3-bfc5-7124e709f0f2</td>\n",
       "      <td>6c23d224-591e-4160-b1df-706bfa2268ef</td>\n",
       "      <td>187.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fca99900-be8a-444e-a01f-b21b7198a807</td>\n",
       "      <td>deaebe71-9a37-493a-ada9-d93c4a23d83f</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6e153812-8d9c-4c09-ad83-9836652fb61c</td>\n",
       "      <td>cb7f3011-b6d3-4ff9-baba-0689994b23e2</td>\n",
       "      <td>361.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bb9ae76d-cff1-42d5-9673-1c339601bed9</td>\n",
       "      <td>d156e6e9-4a02-409d-9c59-aa04d17101d9</td>\n",
       "      <td>176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>de5ee62d-1caa-4dbc-9b8b-b307dbdaf1dc</td>\n",
       "      <td>f771225b-1ec6-4797-a79d-26f7d056e86c</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6b95bc22-68e9-4549-ae99-60cf70b4a8d9</td>\n",
       "      <td>915c331a-7250-4ba7-9047-39f69046e3d0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7fb16985-52ca-47a6-b87e-d1867fbe2f29</td>\n",
       "      <td>6819a834-d7fc-418f-9227-4718b05757bd</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>83455874-4b3a-4257-8188-2ecc94344608</td>\n",
       "      <td>f575687b-3b93-47af-950b-77ae2ee558d6</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>e9a2c2c0-0128-41f1-9da0-47477d940090</td>\n",
       "      <td>734d92f4-0b17-497c-a792-8c8aacf0c0f3</td>\n",
       "      <td>205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>d0984f7a-a6cc-4936-a3fb-25d52a200488</td>\n",
       "      <td>38520603-e165-41fa-a1ff-31aae34e5310</td>\n",
       "      <td>177.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>61ab53b8-8f45-4bbb-b939-775a64f1f7a4</td>\n",
       "      <td>1420f20a-7e25-4df1-b79f-194125b5f512</td>\n",
       "      <td>122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8d10c67c-ad02-4ed1-b69e-77c7f63046dc</td>\n",
       "      <td>44b3792d-d404-4eb0-97ab-942ad969f488</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6df7e9b0-7ccd-4537-99b1-38c872a39704</td>\n",
       "      <td>46b8102e-513f-40e5-9479-ee0df3d5b13a</td>\n",
       "      <td>271.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4445521e-6a8b-4297-83be-f5c942cd4e35</td>\n",
       "      <td>c78007ad-4a43-4fff-b81a-95fa78a74c53</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08a63a89-fdbb-41ba-948d-4deec8b04d9d</td>\n",
       "      <td>e28f3152-feb4-4412-82fe-4f8edcfff841</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>e5c683c5-2043-4c2d-affd-50307d82f6ae</td>\n",
       "      <td>3c3d2250-f475-4573-89a6-843ea50d5768</td>\n",
       "      <td>362.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2654c1da-7d79-4d2c-843a-17e3f325475e</td>\n",
       "      <td>90ccc54e-7916-4042-871b-bc25cc58867e</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>be93a9fd-812c-42d7-a1c1-842a84c33c87</td>\n",
       "      <td>09913b6c-7d0e-4959-9921-6dff5c8b82d4</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5aa32fc1-be45-4606-9808-4aadc0ef6995</td>\n",
       "      <td>74982b88-b3b3-4aa4-a7f1-715df241ab44</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>86b476eb-cc23-415f-8f24-a0d503fb52f6</td>\n",
       "      <td>7723c588-8176-4c00-ab36-b5ba1697173b</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44774</th>\n",
       "      <td>30559c42-2c0a-4cf4-b268-c18f5a4a55cc</td>\n",
       "      <td>22518c30-9ac7-4272-94c0-a552a3508926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44775</th>\n",
       "      <td>ab90b966-6efe-42f0-ba58-40ef67fb2bdc</td>\n",
       "      <td>d1c561c6-eb1f-476d-b63a-dafa7546b63c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44776</th>\n",
       "      <td>0c1b572c-f5c0-4d27-8b29-93c29ca2e453</td>\n",
       "      <td>776c151a-1c60-4109-9e54-561906812ce0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44777</th>\n",
       "      <td>a83350d3-e1de-4f4f-828a-f2457eac02e7</td>\n",
       "      <td>25e56528-4939-44b6-b243-137b7263b0b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44778</th>\n",
       "      <td>1811bb6d-4e14-42cc-a95c-5aa8288f0a2e</td>\n",
       "      <td>bc584770-2253-4344-ad2f-ead911b6e3a2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44779</th>\n",
       "      <td>860f6d39-9315-4de8-a523-cd6110c74fec</td>\n",
       "      <td>f372ae44-7f66-4ac9-8f0b-db519563927a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44780</th>\n",
       "      <td>0aaddc76-2167-49b1-ad90-4a2c07941f90</td>\n",
       "      <td>f372ae44-7f66-4ac9-8f0b-db519563927a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44781</th>\n",
       "      <td>c3006bc3-3b6d-410f-bbdb-023822ea9ff2</td>\n",
       "      <td>fec21464-5eb7-4c65-bc7c-7cbff43d2850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44782</th>\n",
       "      <td>b33fa2f4-3cf4-4909-8b1d-400d396ca925</td>\n",
       "      <td>3405b755-a037-4b1d-9ebd-6c46d00d67ba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44783</th>\n",
       "      <td>d7502988-17b1-4f8e-9486-6176eaf9ed22</td>\n",
       "      <td>47fc2f2c-80e3-40fd-b7f6-e171eabbafb7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44784</th>\n",
       "      <td>a448f863-c190-4a79-bfd6-aa7f44a042d2</td>\n",
       "      <td>cbaf99cb-fd25-4434-a8bc-e483eb2d0c7e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44785</th>\n",
       "      <td>91e4eb36-f933-43de-82db-7f20278266e0</td>\n",
       "      <td>5784f49f-33cf-415e-bf5f-667086604500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44786</th>\n",
       "      <td>e98c0309-b81e-4f99-ae23-8877b0f2c254</td>\n",
       "      <td>d1c561c6-eb1f-476d-b63a-dafa7546b63c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44787</th>\n",
       "      <td>889cc3c5-9fb7-4a3e-a81e-e1e82d190475</td>\n",
       "      <td>49461e00-809a-4d3e-bffe-1d50b71b4469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44788</th>\n",
       "      <td>7e43f30e-6b04-4934-b1d0-12cbefb65bea</td>\n",
       "      <td>f39b2eb4-3211-403d-825b-e717a5cdb50d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44789</th>\n",
       "      <td>a44f6e75-2414-4edd-af81-a61b4d4978c5</td>\n",
       "      <td>80877de1-e1f6-4f50-b0ae-7ece39c4b219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44790</th>\n",
       "      <td>d3d1b9e9-a2bc-4eb1-adcd-0d51fc4ac53b</td>\n",
       "      <td>aef3957c-3834-4f87-9f7f-bcfab8ea0649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44791</th>\n",
       "      <td>8d63d8dc-7b8a-4291-8273-a52b69023b11</td>\n",
       "      <td>6ef1357c-4174-4420-8af4-83b633bd277a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44792</th>\n",
       "      <td>c862f72c-d802-4727-a85a-98b6cb6fd8b2</td>\n",
       "      <td>5f7c25ee-2e4f-45f7-9e81-84c91be28cc8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44793</th>\n",
       "      <td>6f961d0a-6605-46be-bb60-f1bbb51adb49</td>\n",
       "      <td>0ea311be-7830-4d2d-bb3e-0ec055698f1f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44794</th>\n",
       "      <td>7ae0e816-24fe-49a1-8b72-6c581979c2ba</td>\n",
       "      <td>1d062596-e8e7-4a75-a1c0-a39e053c47b9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44795</th>\n",
       "      <td>fc0d80f9-0032-418e-9110-858c68289cd6</td>\n",
       "      <td>58972dcc-54d4-4b9f-96c8-da6c24dad91e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44796</th>\n",
       "      <td>05b5fc44-605e-478c-8442-66b4cb52ebbb</td>\n",
       "      <td>f2ce3938-5a24-4dc0-9991-ebee218bf506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44797</th>\n",
       "      <td>3b3e9f2b-b079-4840-a342-c34a40c39f28</td>\n",
       "      <td>31948491-672b-4fe0-884e-fa7161aae953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44798</th>\n",
       "      <td>2011e0cc-f59e-477c-b4e8-e3f2b896fb13</td>\n",
       "      <td>bd554b83-81af-4cae-89ca-4aa7362c037f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44799</th>\n",
       "      <td>0d414b2d-6ac8-410d-a0ff-a3c029c00f97</td>\n",
       "      <td>bf181501-f803-43cf-bbce-5bb19f29b380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44800</th>\n",
       "      <td>3ee7f904-d3a0-44af-8c23-96a787f36e0c</td>\n",
       "      <td>5784f49f-33cf-415e-bf5f-667086604500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44801</th>\n",
       "      <td>d52cd6f7-c376-4397-843f-df60748ea597</td>\n",
       "      <td>0108dedd-2159-434b-831f-ca68b8b2bff5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44802</th>\n",
       "      <td>63b613d5-28fb-4615-bf9c-b39d8fe8f3e3</td>\n",
       "      <td>99141974-57ac-433c-91fc-19f451172b5f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44803</th>\n",
       "      <td>fd34042c-a28e-4218-aff4-6cd13b0fc242</td>\n",
       "      <td>76f64214-d201-4d2e-aa84-3c9eba629517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34685 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   recordId  \\\n",
       "0      77f77904-6969-4b69-b408-131d7e434938   \n",
       "1      de3b154b-fe81-4ef7-b392-e51c36137e12   \n",
       "2      5fd22a4b-b573-4a14-9503-9f4027a1822c   \n",
       "3      8712c75a-2a69-41d7-9baf-eb3569e011af   \n",
       "4      2ee84b1b-ce33-405f-a27e-ab9ca150fe3b   \n",
       "5      ba83c4a7-1bb8-46b6-829b-e6ef7ff9696c   \n",
       "6      03793227-ab8f-41ff-bc17-039b6eaa56db   \n",
       "7      43828c79-e658-4eca-a9ac-9fa27329fe4b   \n",
       "8      6788bff0-b65c-406f-b4c0-7f4a0cfdae20   \n",
       "9      bd5a34bc-7617-4ed2-a888-b57a1830f419   \n",
       "10     99482689-3851-4ed3-bfc5-7124e709f0f2   \n",
       "11     fca99900-be8a-444e-a01f-b21b7198a807   \n",
       "12     6e153812-8d9c-4c09-ad83-9836652fb61c   \n",
       "13     bb9ae76d-cff1-42d5-9673-1c339601bed9   \n",
       "14     de5ee62d-1caa-4dbc-9b8b-b307dbdaf1dc   \n",
       "15     6b95bc22-68e9-4549-ae99-60cf70b4a8d9   \n",
       "16     7fb16985-52ca-47a6-b87e-d1867fbe2f29   \n",
       "17     83455874-4b3a-4257-8188-2ecc94344608   \n",
       "19     e9a2c2c0-0128-41f1-9da0-47477d940090   \n",
       "20     d0984f7a-a6cc-4936-a3fb-25d52a200488   \n",
       "21     61ab53b8-8f45-4bbb-b939-775a64f1f7a4   \n",
       "22     8d10c67c-ad02-4ed1-b69e-77c7f63046dc   \n",
       "23     6df7e9b0-7ccd-4537-99b1-38c872a39704   \n",
       "24     4445521e-6a8b-4297-83be-f5c942cd4e35   \n",
       "25     08a63a89-fdbb-41ba-948d-4deec8b04d9d   \n",
       "26     e5c683c5-2043-4c2d-affd-50307d82f6ae   \n",
       "27     2654c1da-7d79-4d2c-843a-17e3f325475e   \n",
       "28     be93a9fd-812c-42d7-a1c1-842a84c33c87   \n",
       "29     5aa32fc1-be45-4606-9808-4aadc0ef6995   \n",
       "30     86b476eb-cc23-415f-8f24-a0d503fb52f6   \n",
       "...                                     ...   \n",
       "44774  30559c42-2c0a-4cf4-b268-c18f5a4a55cc   \n",
       "44775  ab90b966-6efe-42f0-ba58-40ef67fb2bdc   \n",
       "44776  0c1b572c-f5c0-4d27-8b29-93c29ca2e453   \n",
       "44777  a83350d3-e1de-4f4f-828a-f2457eac02e7   \n",
       "44778  1811bb6d-4e14-42cc-a95c-5aa8288f0a2e   \n",
       "44779  860f6d39-9315-4de8-a523-cd6110c74fec   \n",
       "44780  0aaddc76-2167-49b1-ad90-4a2c07941f90   \n",
       "44781  c3006bc3-3b6d-410f-bbdb-023822ea9ff2   \n",
       "44782  b33fa2f4-3cf4-4909-8b1d-400d396ca925   \n",
       "44783  d7502988-17b1-4f8e-9486-6176eaf9ed22   \n",
       "44784  a448f863-c190-4a79-bfd6-aa7f44a042d2   \n",
       "44785  91e4eb36-f933-43de-82db-7f20278266e0   \n",
       "44786  e98c0309-b81e-4f99-ae23-8877b0f2c254   \n",
       "44787  889cc3c5-9fb7-4a3e-a81e-e1e82d190475   \n",
       "44788  7e43f30e-6b04-4934-b1d0-12cbefb65bea   \n",
       "44789  a44f6e75-2414-4edd-af81-a61b4d4978c5   \n",
       "44790  d3d1b9e9-a2bc-4eb1-adcd-0d51fc4ac53b   \n",
       "44791  8d63d8dc-7b8a-4291-8273-a52b69023b11   \n",
       "44792  c862f72c-d802-4727-a85a-98b6cb6fd8b2   \n",
       "44793  6f961d0a-6605-46be-bb60-f1bbb51adb49   \n",
       "44794  7ae0e816-24fe-49a1-8b72-6c581979c2ba   \n",
       "44795  fc0d80f9-0032-418e-9110-858c68289cd6   \n",
       "44796  05b5fc44-605e-478c-8442-66b4cb52ebbb   \n",
       "44797  3b3e9f2b-b079-4840-a342-c34a40c39f28   \n",
       "44798  2011e0cc-f59e-477c-b4e8-e3f2b896fb13   \n",
       "44799  0d414b2d-6ac8-410d-a0ff-a3c029c00f97   \n",
       "44800  3ee7f904-d3a0-44af-8c23-96a787f36e0c   \n",
       "44801  d52cd6f7-c376-4397-843f-df60748ea597   \n",
       "44802  63b613d5-28fb-4615-bf9c-b39d8fe8f3e3   \n",
       "44803  fd34042c-a28e-4218-aff4-6cd13b0fc242   \n",
       "\n",
       "                                 healthCode  weight  weight2     sex    sex2  \\\n",
       "0      9c0a77cd-159b-423b-8e73-b7f3666ba938   180.0      NaN  Female     NaN   \n",
       "1      c4ed1db6-9bc0-46e5-a296-fd452a773072   142.0      NaN    Male     NaN   \n",
       "2      e4c01bfb-9688-4b96-9e80-137b3b0a6a4c   190.0      NaN    Male     NaN   \n",
       "3      c4ed1db6-9bc0-46e5-a296-fd452a773072   142.0      NaN    Male     NaN   \n",
       "4      90ccc54e-7916-4042-871b-bc25cc58867e   245.0      NaN    Male     NaN   \n",
       "5      7008bee7-5a68-46a9-80a0-0f280df94f6d   221.0      NaN    Male     NaN   \n",
       "6      d670264b-3edc-4d1f-b42d-6430bf9efb70   140.0      NaN    Male     NaN   \n",
       "7      620e7c23-16bf-4b7c-80a1-af3a15e900a2   217.0      NaN    Male     NaN   \n",
       "8      74982b88-b3b3-4aa4-a7f1-715df241ab44   207.0      NaN    Male     NaN   \n",
       "9      280f17b1-8b9e-40b5-9dd5-9c6d1e1b10ee   140.0      NaN    Male     NaN   \n",
       "10     6c23d224-591e-4160-b1df-706bfa2268ef   187.0      NaN    Male     NaN   \n",
       "11     deaebe71-9a37-493a-ada9-d93c4a23d83f   165.0      NaN    Male     NaN   \n",
       "12     cb7f3011-b6d3-4ff9-baba-0689994b23e2   361.0      NaN    Male     NaN   \n",
       "13     d156e6e9-4a02-409d-9c59-aa04d17101d9   176.0      NaN    Male     NaN   \n",
       "14     f771225b-1ec6-4797-a79d-26f7d056e86c   195.0      NaN    Male     NaN   \n",
       "15     915c331a-7250-4ba7-9047-39f69046e3d0   182.0      NaN    Male     NaN   \n",
       "16     6819a834-d7fc-418f-9227-4718b05757bd   121.0      NaN  Female     NaN   \n",
       "17     f575687b-3b93-47af-950b-77ae2ee558d6    77.0      NaN  Female     NaN   \n",
       "19     734d92f4-0b17-497c-a792-8c8aacf0c0f3   205.0      NaN    Male     NaN   \n",
       "20     38520603-e165-41fa-a1ff-31aae34e5310   177.0      NaN    Male     NaN   \n",
       "21     1420f20a-7e25-4df1-b79f-194125b5f512   122.0      NaN  Female     NaN   \n",
       "22     44b3792d-d404-4eb0-97ab-942ad969f488   130.0      NaN  Female     NaN   \n",
       "23     46b8102e-513f-40e5-9479-ee0df3d5b13a   271.0      NaN    Male     NaN   \n",
       "24     c78007ad-4a43-4fff-b81a-95fa78a74c53   180.0      NaN    Male     NaN   \n",
       "25     e28f3152-feb4-4412-82fe-4f8edcfff841   165.0      NaN    Male     NaN   \n",
       "26     3c3d2250-f475-4573-89a6-843ea50d5768   362.0      NaN    Male     NaN   \n",
       "27     90ccc54e-7916-4042-871b-bc25cc58867e   245.0      NaN    Male     NaN   \n",
       "28     09913b6c-7d0e-4959-9921-6dff5c8b82d4   180.0      NaN    Male     NaN   \n",
       "29     74982b88-b3b3-4aa4-a7f1-715df241ab44   207.0      NaN    Male     NaN   \n",
       "30     7723c588-8176-4c00-ab36-b5ba1697173b   155.0      NaN    Male     NaN   \n",
       "...                                     ...     ...      ...     ...     ...   \n",
       "44774  22518c30-9ac7-4272-94c0-a552a3508926     NaN    137.0     NaN    Male   \n",
       "44775  d1c561c6-eb1f-476d-b63a-dafa7546b63c     NaN    123.0     NaN  Female   \n",
       "44776  776c151a-1c60-4109-9e54-561906812ce0     NaN    153.0     NaN    Male   \n",
       "44777  25e56528-4939-44b6-b243-137b7263b0b3     NaN    255.0     NaN  Female   \n",
       "44778  bc584770-2253-4344-ad2f-ead911b6e3a2     NaN    199.0     NaN    Male   \n",
       "44779  f372ae44-7f66-4ac9-8f0b-db519563927a     NaN      0.0     NaN  Female   \n",
       "44780  f372ae44-7f66-4ac9-8f0b-db519563927a     NaN      0.0     NaN  Female   \n",
       "44781  fec21464-5eb7-4c65-bc7c-7cbff43d2850     NaN      0.0     NaN    Male   \n",
       "44782  3405b755-a037-4b1d-9ebd-6c46d00d67ba     NaN    161.0     NaN  Female   \n",
       "44783  47fc2f2c-80e3-40fd-b7f6-e171eabbafb7     NaN    137.0     NaN  Female   \n",
       "44784  cbaf99cb-fd25-4434-a8bc-e483eb2d0c7e     NaN    256.0     NaN    Male   \n",
       "44785  5784f49f-33cf-415e-bf5f-667086604500     NaN    195.0     NaN    Male   \n",
       "44786  d1c561c6-eb1f-476d-b63a-dafa7546b63c     NaN    123.0     NaN  Female   \n",
       "44787  49461e00-809a-4d3e-bffe-1d50b71b4469     NaN    145.0     NaN  Female   \n",
       "44788  f39b2eb4-3211-403d-825b-e717a5cdb50d     NaN    109.0     NaN  Female   \n",
       "44789  80877de1-e1f6-4f50-b0ae-7ece39c4b219     NaN    147.0     NaN  Female   \n",
       "44790  aef3957c-3834-4f87-9f7f-bcfab8ea0649     NaN    144.0     NaN    Male   \n",
       "44791  6ef1357c-4174-4420-8af4-83b633bd277a     NaN    230.0     NaN    Male   \n",
       "44792  5f7c25ee-2e4f-45f7-9e81-84c91be28cc8     NaN      0.0     NaN  Female   \n",
       "44793  0ea311be-7830-4d2d-bb3e-0ec055698f1f     NaN    167.0     NaN    Male   \n",
       "44794  1d062596-e8e7-4a75-a1c0-a39e053c47b9     NaN    223.0     NaN    Male   \n",
       "44795  58972dcc-54d4-4b9f-96c8-da6c24dad91e     NaN    215.0     NaN    Male   \n",
       "44796  f2ce3938-5a24-4dc0-9991-ebee218bf506     NaN    198.0     NaN    Male   \n",
       "44797  31948491-672b-4fe0-884e-fa7161aae953     NaN    210.0     NaN    Male   \n",
       "44798  bd554b83-81af-4cae-89ca-4aa7362c037f     NaN    195.0     NaN    Male   \n",
       "44799  bf181501-f803-43cf-bbce-5bb19f29b380     NaN    203.0     NaN    Male   \n",
       "44800  5784f49f-33cf-415e-bf5f-667086604500     NaN    195.0     NaN    Male   \n",
       "44801  0108dedd-2159-434b-831f-ca68b8b2bff5     NaN    225.0     NaN    Male   \n",
       "44802  99141974-57ac-433c-91fc-19f451172b5f     NaN    184.0     NaN  Female   \n",
       "44803  76f64214-d201-4d2e-aa84-3c9eba629517     NaN    170.0     NaN    Male   \n",
       "\n",
       "       height  height2  currentAge  currentAge2  \n",
       "0        66.0      NaN        51.0          NaN  \n",
       "1        67.0      NaN        18.0          NaN  \n",
       "2        68.0      NaN        44.0          NaN  \n",
       "3        67.0      NaN        18.0          NaN  \n",
       "4        68.0      NaN        42.0          NaN  \n",
       "5        68.0      NaN        39.0          NaN  \n",
       "6        66.0      NaN        28.0          NaN  \n",
       "7        70.0      NaN        32.0          NaN  \n",
       "8        72.0      NaN        41.0          NaN  \n",
       "9        69.0      NaN        36.0          NaN  \n",
       "10       68.0      NaN        30.0          NaN  \n",
       "11       68.0      NaN        20.0          NaN  \n",
       "12       72.0      NaN        23.0          NaN  \n",
       "13       72.0      NaN        31.0          NaN  \n",
       "14       71.0      NaN        48.0          NaN  \n",
       "15       71.0      NaN        24.0          NaN  \n",
       "16       61.0      NaN        18.0          NaN  \n",
       "17       57.0      NaN        31.0          NaN  \n",
       "19       68.0      NaN        19.0          NaN  \n",
       "20       68.0      NaN        32.0          NaN  \n",
       "21       66.0      NaN        20.0          NaN  \n",
       "22       64.0      NaN        18.0          NaN  \n",
       "23       71.0      NaN        30.0          NaN  \n",
       "24       71.0      NaN        31.0          NaN  \n",
       "25       60.0      NaN        30.0          NaN  \n",
       "26       70.0      NaN        55.0          NaN  \n",
       "27       68.0      NaN        42.0          NaN  \n",
       "28       70.0      NaN        32.0          NaN  \n",
       "29       72.0      NaN        41.0          NaN  \n",
       "30       71.0      NaN        26.0          NaN  \n",
       "...       ...      ...         ...          ...  \n",
       "44774     NaN     73.0         NaN         23.0  \n",
       "44775     NaN     65.0         NaN         53.0  \n",
       "44776     NaN     71.0         NaN         26.0  \n",
       "44777     NaN     71.0         NaN         28.0  \n",
       "44778     NaN     73.0         NaN         36.0  \n",
       "44779     NaN      0.0         NaN         47.0  \n",
       "44780     NaN      0.0         NaN         47.0  \n",
       "44781     NaN      0.0         NaN         32.0  \n",
       "44782     NaN     63.0         NaN         63.0  \n",
       "44783     NaN     65.0         NaN         33.0  \n",
       "44784     NaN     72.0         NaN         37.0  \n",
       "44785     NaN     68.0         NaN         45.0  \n",
       "44786     NaN     65.0         NaN         53.0  \n",
       "44787     NaN     63.0         NaN         80.0  \n",
       "44788     NaN     61.0         NaN         25.0  \n",
       "44789     NaN     68.0         NaN         44.0  \n",
       "44790     NaN     65.0         NaN         47.0  \n",
       "44791     NaN     76.0         NaN         65.0  \n",
       "44792     NaN      0.0         NaN         74.0  \n",
       "44793     NaN     68.0         NaN         40.0  \n",
       "44794     NaN     73.0         NaN         70.0  \n",
       "44795     NaN     66.0         NaN         75.0  \n",
       "44796     NaN     71.0         NaN         56.0  \n",
       "44797     NaN     76.0         NaN         39.0  \n",
       "44798     NaN     71.0         NaN         30.0  \n",
       "44799     NaN     67.0         NaN         54.0  \n",
       "44800     NaN     68.0         NaN         45.0  \n",
       "44801     NaN     79.0         NaN         44.0  \n",
       "44802     NaN     66.0         NaN         29.0  \n",
       "44803     NaN     69.0         NaN         64.0  \n",
       "\n",
       "[34685 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "file = \"data/demographics.csv\"\n",
    "csv = pd.read_csv(file, low_memory=False)\n",
    "\n",
    "csv.drop(columns=['ROW_ID', 'ROW_VERSION', 'appVersion', 'phoneInfo', 'dataGroups', 'uploadDate', 'createdOn', \n",
    "                  'validationErrors', 'userSharingScope', 'NonIdentifiableDemographics.json.patientGoSleepTime', \n",
    "                  'NonIdentifiableDemographics.patientGoSleepTime', 'createdOnTimeZone',\n",
    "                 'NonIdentifiableDemographics.json.patientWakeUpTime', 'NonIdentifiableDemographics.patientWakeUpTime'\n",
    "                 , 'externalId'], \n",
    "         inplace=True)\n",
    "csv.rename(columns={'NonIdentifiableDemographics.json.patientWeightPounds': 'weight', 'NonIdentifiableDemographics.patientWeightPounds': 'weight2', \n",
    "                    'NonIdentifiableDemographics.json.patientBiologicalSex': 'sex', \n",
    "                    'NonIdentifiableDemographics.patientBiologicalSex': 'sex2',\n",
    "                   'NonIdentifiableDemographics.json.patientHeightInches': 'height',\n",
    "                   'NonIdentifiableDemographics.patientHeightInches': 'height2',\n",
    "                   'NonIdentifiableDemographics.json.patientCurrentAge': 'currentAge',\n",
    "                   'NonIdentifiableDemographics.patientCurrentAge': 'currentAge2'}, inplace=True)\n",
    "\n",
    "# drop the test version\n",
    "csv = csv.iloc[7:]\n",
    "csv.index = range(44804)\n",
    "\n",
    "csv.dropna(how='all', subset=['currentAge','currentAge2'], inplace=True)\n",
    "csv.dropna(how='all', subset=['weight', 'weight2'], inplace=True)\n",
    "csv.dropna(how='all', subset=['sex', 'sex2'], inplace=True)\n",
    "csv.dropna(how='all', subset=['height', 'height2'], inplace=True)\n",
    "\n",
    "csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "csv['currentAge'] = csv['currentAge'].fillna(csv['currentAge2'])\n",
    "csv['weight'] = csv['weight'].fillna(csv['weight2'])\n",
    "csv['height'] = csv['height'].fillna(csv['height2'])\n",
    "csv['sex'] = csv['sex'].fillna(csv['sex2'])\n",
    "csv = csv.drop('currentAge2',1)\n",
    "csv = csv.drop('weight2',1)\n",
    "csv = csv.drop('height2',1)\n",
    "csv = csv.drop('sex2',1)\n",
    "\n",
    "# Dropping the duplicate healthCode records... Don't know if this is the right thing to do but can easily be reversed\n",
    "csv = csv.drop_duplicates(subset='healthCode', keep='last', inplace=False)\n",
    "\n",
    "# Dropping the rows with 0 for any metric. This was not caught with the NaN cleaning/merging \n",
    "csv = csv[csv.currentAge != 0]\n",
    "csv = csv[csv.weight != 0]\n",
    "csv = csv[csv.height != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "\n",
    "directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwt/accel_walk_dir'\n",
    "directory = os.fsencode(directory_in_str)\n",
    "\n",
    "final_directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwtwindows'\n",
    "final_directory = os.fsencode(final_directory_in_str)\n",
    "\n",
    "# Set overlap to the amount you want the sliding windows to have in common \n",
    "# Example: If your sliding windows are of length 200 ms (2 seconds), make the overlap 99 for half of the window to overlap \n",
    "def moving_window(accelx, length, overlap, step=1):\n",
    "    streams = it.tee(accelx, length)\n",
    "    return zip(*[it.islice(stream, i, None, step + overlap) for stream, i in zip(streams, it.count(step=step))])\n",
    "\n",
    "def normalize_dataset(dataframe):\n",
    "    return (dataframe - dataframe.mean())\n",
    "\n",
    "# Just get from the 173 valid files we have \n",
    "def create_dataframes(num_of_ms, overlap, fn):\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        # You can choose to get the non mean normalized version by not calling the normalize_dataset function\n",
    "        a_df = normalize_dataset(pd.read_json(fn).set_index('timestamp'))\n",
    "        x = np.asarray(a_df.x)\n",
    "        y = np.asarray(a_df.y)\n",
    "        z = np.asarray(a_df.z)\n",
    "        x_ = list(moving_window(x, num_of_ms, overlap))\n",
    "        y_ = list(moving_window(y, num_of_ms, overlap))\n",
    "        z_ = list(moving_window(z, num_of_ms, overlap))\n",
    "        df = pd.DataFrame({'healthCode': subdir.decode()[subdir.decode().rfind('/')+1:], \n",
    "        'xwindows': x_, 'ywindows': y_, 'zwindows': z_}, columns=['healthCode', 'xwindows', \n",
    "        'ywindows', 'zwindows']).setIndex('healthCode')\n",
    "\n",
    "        if not os.path(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + str(num_of_ms) + str(overlap)):\n",
    "            os.makedirs(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + str(num_of_ms) + str(overlap))\n",
    "        df.to_hdf(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + str(num_of_ms) + str(overlap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-21bc02e969de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m             )\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'frame'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 853\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             decoded = {str(k): v for k, v in compat.iteritems(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools as it\n",
    "\n",
    "directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwt/accel_walk_dir'\n",
    "directory = os.fsencode(directory_in_str)\n",
    "\n",
    "def moving_window(accelx, length, overlap, step=1):\n",
    "    streams = it.tee(accelx, length)\n",
    "    return zip(*[it.islice(stream, i, None, step + overlap) for stream, i in zip(streams, it.count(step=step))])\n",
    "\n",
    "def normalize_dataset(dataframe):\n",
    "    return (dataframe - dataframe.mean())\n",
    "\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        test_df = normalize_dataset(pd.read_json(os.path.join(subdir.decode(), file.decode())).set_index('timestamp'))\n",
    "        x = np.asarray(test_df.x)\n",
    "        y = np.asarray(test_df.y)\n",
    "        z = np.asarray(test_df.z)\n",
    "        x_ = list(moving_window(x, 200, 99))\n",
    "        y_ = list(moving_window(y, 200, 99))\n",
    "        z_ = list(moving_window(z, 200, 99))\n",
    "\n",
    "        df = pd.DataFrame({'healthCode': subdir.decode()[subdir.decode().rfind('/')+1:], \n",
    "                'xwindows': x_, 'ywindows': y_, 'zwindows': z_}, columns=['healthCode', 'xwindows', \n",
    "                'ywindows', 'zwindows']).set_index('healthCode')\n",
    "        df.head()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_df = normalize_dataset(pd.read_json('data/test_accel_old.json')).set_index('timestamp')\n",
    "x = np.asarray(test_df.x)\n",
    "y = np.asarray(test_df.y)\n",
    "z = np.asarray(test_df.z)\n",
    "x_ = list(moving_window(x, 200, 99))\n",
    "y_ = list(moving_window(y, 200, 99))\n",
    "z_ = list(moving_window(z, 200, 99))\n",
    "\n",
    "df = pd.DataFrame({'healthCode': 'hello', \n",
    "            'xwindows': x_, 'ywindows': y_, 'zwindows': z_}, columns=['healthCode', 'xwindows', \n",
    "            'ywindows', 'zwindows']).set_index('healthCode')\n",
    "df.to_hdf('data/df.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, errno\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "\n",
    "directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwt/accel_walk_dir'\n",
    "directory = os.fsencode(directory_in_str)\n",
    "\n",
    "final_directory_in_str = '/scratch/PI/euan/projects/mhc/data/6mwtwindows'\n",
    "final_directory = os.fsencode(final_directory_in_str)\n",
    "\n",
    "# Set overlap to the amount you want the sliding windows to have in common \n",
    "# Example: If your sliding windows are of length 200 ms (2 seconds), make the overlap 99 for half of the window to overlap \n",
    "def moving_window(accelx, length, overlap, step=1):\n",
    "    streams = it.tee(accelx, length)\n",
    "    return zip(*[it.islice(stream, i, None, step + overlap) for stream, i in zip(streams, it.count(step=step))])\n",
    "\n",
    "def normalize_dataset(dataframe):\n",
    "    return (dataframe - dataframe.mean())\n",
    "\n",
    "def create_dataframes(num_of_ms, overlap):\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        i = 0\n",
    "        for file in files:\n",
    "            while (i < 1):\n",
    "                # You can choose to get the non mean normalized version by not calling the normalize_dataset function\n",
    "                a_df = normalize_dataset(pd.read_json(os.path.join(subdir.decode(), file.decode())).set_index('timestamp'))\n",
    "                x = np.asarray(a_df.x)\n",
    "                y = np.asarray(a_df.y)\n",
    "                z = np.asarray(a_df.z)\n",
    "                x_ = list(moving_window(x, num_of_ms, overlap))\n",
    "                y_ = list(moving_window(y, num_of_ms, overlap))\n",
    "                z_ = list(moving_window(z, num_of_ms, overlap))\n",
    "                df = pd.DataFrame({'healthCode': subdir.decode()[subdir.decode().rfind('/')+1:], \n",
    "                'xwindows': x_, 'ywindows': y_, 'zwindows': z_}, columns=['healthCode', 'xwindows', \n",
    "                'ywindows', 'zwindows']).set_index('healthCode')\n",
    "\n",
    "                \n",
    "                if not os.path.exists(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + '/' + str(num_of_ms) + '/' + str(overlap)):\n",
    "                    os.makedirs(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + '/' + str(num_of_ms) + '/' + str(overlap))\n",
    "                df.to_hdf(final_directory.decode() + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + '/' + str(num_of_ms) + '/' + str(overlap) + '/' + subdir.decode()[subdir.decode().rfind('/')+1:] + str(num_of_ms) + str(overlap) +'.h5', key='df', mode='w')\n",
    "                i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/home/users/bhargavy/.local/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['xwindows', 'ywindows', 'zwindows']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-fc5e95da1c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_dataframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-124-06ad376af2d5>\u001b[0m in \u001b[0;36mcreate_dataframes\u001b[0;34m(num_of_ms, overlap)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;31m# You can choose to get the non mean normalized version by not calling the normalize_dataset function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0ma_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_unit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     )\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_from_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \"\"\"\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/software/user/open/python/3.6.1/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "create_dataframes(200, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "newtotal_df  = pd.read_hdf('newtotal_df.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_lowest_num_samples(total_df):\n",
    "    '''\n",
    "    This function finds the minimum number of samples from all of the runs present so that we keep same dimensions\n",
    "    for every run that we have\n",
    "    '''\n",
    "    total = [len(total_df.loc[x].average_accel) for x in list(set(total_df.index))]\n",
    "    return min(total)\n",
    "\n",
    "def min_df(lowest_num_of_samples, total_df):\n",
    "    '''\n",
    "    Returns the dataframe with features for every healthCode present so that there are only the minimum amount of \n",
    "    samples needed\n",
    "    '''\n",
    "    newdf = pd.DataFrame()\n",
    "    unique_healthcodes = list(set(total_df.index))\n",
    "    for elem in unique_healthcodes:\n",
    "        newdf = newdf.append(total_df.loc[elem].iloc[:lowest_num_of_samples])\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newtotal_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-c8e7a0030629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meverything\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_lowest_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewtotal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewtotal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'newtotal_df' is not defined"
     ]
    }
   ],
   "source": [
    "everything = min_df(find_lowest_num_samples(newtotal_df), newtotal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "everything = everything[everything.weight < 400]\n",
    "everything = everything[everything.weight > 80]\n",
    "\n",
    "# this dataframe doesn't have demographic data\n",
    "everything_no_demog = everything.drop(columns=['sex', 'currentAge', 'weight', 'height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>currentAge</th>\n",
       "      <th>fundamental_freq</th>\n",
       "      <th>average_accel</th>\n",
       "      <th>peakcount</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mut_x</th>\n",
       "      <th>...</th>\n",
       "      <th>medf_y</th>\n",
       "      <th>medf_z</th>\n",
       "      <th>cross_xz</th>\n",
       "      <th>cross_yz</th>\n",
       "      <th>spect_cent_x</th>\n",
       "      <th>spect_cent_y</th>\n",
       "      <th>spect_cent_z</th>\n",
       "      <th>average_dist_meanx</th>\n",
       "      <th>average_dist_meany</th>\n",
       "      <th>average_dist_meanz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>108.314444</td>\n",
       "      <td>1.361654</td>\n",
       "      <td>12</td>\n",
       "      <td>2.064969</td>\n",
       "      <td>-0.330143</td>\n",
       "      <td>0.690610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815326</td>\n",
       "      <td>0.261730</td>\n",
       "      <td>-1.108732</td>\n",
       "      <td>1.423415</td>\n",
       "      <td>0.303866</td>\n",
       "      <td>0.484718</td>\n",
       "      <td>0.891400</td>\n",
       "      <td>0.240233</td>\n",
       "      <td>0.241233</td>\n",
       "      <td>0.312021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>95.117992</td>\n",
       "      <td>1.399965</td>\n",
       "      <td>13</td>\n",
       "      <td>2.064969</td>\n",
       "      <td>-0.330143</td>\n",
       "      <td>0.802499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.900119</td>\n",
       "      <td>0.383518</td>\n",
       "      <td>-1.424095</td>\n",
       "      <td>1.614554</td>\n",
       "      <td>0.055270</td>\n",
       "      <td>0.206965</td>\n",
       "      <td>0.505872</td>\n",
       "      <td>0.215864</td>\n",
       "      <td>0.247436</td>\n",
       "      <td>0.306005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>93.161575</td>\n",
       "      <td>1.300919</td>\n",
       "      <td>12</td>\n",
       "      <td>1.786842</td>\n",
       "      <td>-0.142095</td>\n",
       "      <td>0.615637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781222</td>\n",
       "      <td>0.208414</td>\n",
       "      <td>-0.773675</td>\n",
       "      <td>0.980318</td>\n",
       "      <td>0.896903</td>\n",
       "      <td>0.608516</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.192852</td>\n",
       "      <td>0.216332</td>\n",
       "      <td>0.278009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>100.162152</td>\n",
       "      <td>1.274289</td>\n",
       "      <td>10</td>\n",
       "      <td>1.683957</td>\n",
       "      <td>-0.142095</td>\n",
       "      <td>0.531247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779094</td>\n",
       "      <td>0.077215</td>\n",
       "      <td>-0.622452</td>\n",
       "      <td>0.878936</td>\n",
       "      <td>0.177303</td>\n",
       "      <td>0.664331</td>\n",
       "      <td>1.269846</td>\n",
       "      <td>0.169978</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.262656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>108.066819</td>\n",
       "      <td>1.299515</td>\n",
       "      <td>10</td>\n",
       "      <td>1.729218</td>\n",
       "      <td>-0.205279</td>\n",
       "      <td>0.581625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737040</td>\n",
       "      <td>0.084270</td>\n",
       "      <td>-0.669505</td>\n",
       "      <td>0.852864</td>\n",
       "      <td>0.319803</td>\n",
       "      <td>0.922528</td>\n",
       "      <td>1.160783</td>\n",
       "      <td>0.156258</td>\n",
       "      <td>0.195590</td>\n",
       "      <td>0.256213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      weight  height     sex  currentAge  \\\n",
       "healthCode                                                                 \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   247.0    62.0  Female        61.0   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   247.0    62.0  Female        61.0   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   247.0    62.0  Female        61.0   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   247.0    62.0  Female        61.0   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   247.0    62.0  Female        61.0   \n",
       "\n",
       "                                      fundamental_freq  average_accel  \\\n",
       "healthCode                                                              \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        108.314444       1.361654   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         95.117992       1.399965   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         93.161575       1.300919   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        100.162152       1.274289   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        108.066819       1.299515   \n",
       "\n",
       "                                      peakcount       max       min     mut_x  \\\n",
       "healthCode                                                                      \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  2.064969 -0.330143  0.690610   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         13  2.064969 -0.330143  0.802499   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  1.786842 -0.142095  0.615637   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.683957 -0.142095  0.531247   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.729218 -0.205279  0.581625   \n",
       "\n",
       "                                             ...            medf_y    medf_z  \\\n",
       "healthCode                                   ...                               \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.815326  0.261730   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.900119  0.383518   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.781222  0.208414   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.779094  0.077215   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.737040  0.084270   \n",
       "\n",
       "                                      cross_xz  cross_yz  spect_cent_x  \\\n",
       "healthCode                                                               \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -1.108732  1.423415      0.303866   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -1.424095  1.614554      0.055270   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.773675  0.980318      0.896903   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.622452  0.878936      0.177303   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.669505  0.852864      0.319803   \n",
       "\n",
       "                                      spect_cent_y  spect_cent_z  \\\n",
       "healthCode                                                         \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.484718      0.891400   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.206965      0.505872   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.608516      0.523008   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.664331      1.269846   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.922528      1.160783   \n",
       "\n",
       "                                      average_dist_meanx  average_dist_meany  \\\n",
       "healthCode                                                                     \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.240233            0.241233   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.215864            0.247436   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.192852            0.216332   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.169978            0.200500   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.156258            0.195590   \n",
       "\n",
       "                                      average_dist_meanz  \n",
       "healthCode                                                \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.312021  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.306005  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.278009  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.262656  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.256213  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fundamental_freq</th>\n",
       "      <th>average_accel</th>\n",
       "      <th>peakcount</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mut_x</th>\n",
       "      <th>mut_y</th>\n",
       "      <th>mut_z</th>\n",
       "      <th>muf_x</th>\n",
       "      <th>muf_y</th>\n",
       "      <th>...</th>\n",
       "      <th>medf_y</th>\n",
       "      <th>medf_z</th>\n",
       "      <th>cross_xz</th>\n",
       "      <th>cross_yz</th>\n",
       "      <th>spect_cent_x</th>\n",
       "      <th>spect_cent_y</th>\n",
       "      <th>spect_cent_z</th>\n",
       "      <th>average_dist_meanx</th>\n",
       "      <th>average_dist_meany</th>\n",
       "      <th>average_dist_meanz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>108.314444</td>\n",
       "      <td>1.361654</td>\n",
       "      <td>12</td>\n",
       "      <td>2.064969</td>\n",
       "      <td>-0.330143</td>\n",
       "      <td>0.690610</td>\n",
       "      <td>-0.886621</td>\n",
       "      <td>-0.622883</td>\n",
       "      <td>2.408580</td>\n",
       "      <td>2.420899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815326</td>\n",
       "      <td>0.261730</td>\n",
       "      <td>-1.108732</td>\n",
       "      <td>1.423415</td>\n",
       "      <td>0.303866</td>\n",
       "      <td>0.484718</td>\n",
       "      <td>0.891400</td>\n",
       "      <td>0.240233</td>\n",
       "      <td>0.241233</td>\n",
       "      <td>0.312021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>95.117992</td>\n",
       "      <td>1.399965</td>\n",
       "      <td>13</td>\n",
       "      <td>2.064969</td>\n",
       "      <td>-0.330143</td>\n",
       "      <td>0.802499</td>\n",
       "      <td>-0.909826</td>\n",
       "      <td>-0.563515</td>\n",
       "      <td>2.063195</td>\n",
       "      <td>2.432729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.900119</td>\n",
       "      <td>0.383518</td>\n",
       "      <td>-1.424095</td>\n",
       "      <td>1.614554</td>\n",
       "      <td>0.055270</td>\n",
       "      <td>0.206965</td>\n",
       "      <td>0.505872</td>\n",
       "      <td>0.215864</td>\n",
       "      <td>0.247436</td>\n",
       "      <td>0.306005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>93.161575</td>\n",
       "      <td>1.300919</td>\n",
       "      <td>12</td>\n",
       "      <td>1.786842</td>\n",
       "      <td>-0.142095</td>\n",
       "      <td>0.615637</td>\n",
       "      <td>-0.780069</td>\n",
       "      <td>-0.795731</td>\n",
       "      <td>1.537021</td>\n",
       "      <td>1.699596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781222</td>\n",
       "      <td>0.208414</td>\n",
       "      <td>-0.773675</td>\n",
       "      <td>0.980318</td>\n",
       "      <td>0.896903</td>\n",
       "      <td>0.608516</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.192852</td>\n",
       "      <td>0.216332</td>\n",
       "      <td>0.278009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>100.162152</td>\n",
       "      <td>1.274289</td>\n",
       "      <td>10</td>\n",
       "      <td>1.683957</td>\n",
       "      <td>-0.142095</td>\n",
       "      <td>0.531247</td>\n",
       "      <td>-0.750150</td>\n",
       "      <td>-0.853475</td>\n",
       "      <td>1.151398</td>\n",
       "      <td>1.632215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779094</td>\n",
       "      <td>0.077215</td>\n",
       "      <td>-0.622452</td>\n",
       "      <td>0.878936</td>\n",
       "      <td>0.177303</td>\n",
       "      <td>0.664331</td>\n",
       "      <td>1.269846</td>\n",
       "      <td>0.169978</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.262656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>108.066819</td>\n",
       "      <td>1.299515</td>\n",
       "      <td>10</td>\n",
       "      <td>1.729218</td>\n",
       "      <td>-0.205279</td>\n",
       "      <td>0.581625</td>\n",
       "      <td>-0.740917</td>\n",
       "      <td>-0.868740</td>\n",
       "      <td>1.131018</td>\n",
       "      <td>1.579905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737040</td>\n",
       "      <td>0.084270</td>\n",
       "      <td>-0.669505</td>\n",
       "      <td>0.852864</td>\n",
       "      <td>0.319803</td>\n",
       "      <td>0.922528</td>\n",
       "      <td>1.160783</td>\n",
       "      <td>0.156258</td>\n",
       "      <td>0.195590</td>\n",
       "      <td>0.256213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>109.731461</td>\n",
       "      <td>1.307171</td>\n",
       "      <td>8</td>\n",
       "      <td>1.862491</td>\n",
       "      <td>-0.205279</td>\n",
       "      <td>0.613979</td>\n",
       "      <td>-0.713431</td>\n",
       "      <td>-0.877655</td>\n",
       "      <td>1.197633</td>\n",
       "      <td>1.555487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714885</td>\n",
       "      <td>0.182796</td>\n",
       "      <td>-0.699567</td>\n",
       "      <td>0.812884</td>\n",
       "      <td>0.374420</td>\n",
       "      <td>0.966315</td>\n",
       "      <td>1.395159</td>\n",
       "      <td>0.147237</td>\n",
       "      <td>0.194389</td>\n",
       "      <td>0.253153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>107.141324</td>\n",
       "      <td>1.307852</td>\n",
       "      <td>10</td>\n",
       "      <td>1.862491</td>\n",
       "      <td>-0.117244</td>\n",
       "      <td>0.620030</td>\n",
       "      <td>-0.699920</td>\n",
       "      <td>-0.883751</td>\n",
       "      <td>1.157659</td>\n",
       "      <td>1.531361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.726893</td>\n",
       "      <td>0.146422</td>\n",
       "      <td>-0.701589</td>\n",
       "      <td>0.791987</td>\n",
       "      <td>0.341018</td>\n",
       "      <td>0.678090</td>\n",
       "      <td>1.303551</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.190995</td>\n",
       "      <td>0.248046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>103.723405</td>\n",
       "      <td>1.313845</td>\n",
       "      <td>9</td>\n",
       "      <td>1.831361</td>\n",
       "      <td>-0.116085</td>\n",
       "      <td>0.668747</td>\n",
       "      <td>-0.721150</td>\n",
       "      <td>-0.849102</td>\n",
       "      <td>1.293646</td>\n",
       "      <td>1.541653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.706561</td>\n",
       "      <td>0.157716</td>\n",
       "      <td>-0.787594</td>\n",
       "      <td>0.849309</td>\n",
       "      <td>0.539139</td>\n",
       "      <td>0.792449</td>\n",
       "      <td>0.934569</td>\n",
       "      <td>0.135015</td>\n",
       "      <td>0.185874</td>\n",
       "      <td>0.242997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>95.706105</td>\n",
       "      <td>1.338492</td>\n",
       "      <td>9</td>\n",
       "      <td>1.831361</td>\n",
       "      <td>-0.116085</td>\n",
       "      <td>0.723892</td>\n",
       "      <td>-0.692789</td>\n",
       "      <td>-0.866560</td>\n",
       "      <td>1.400238</td>\n",
       "      <td>1.525359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.656978</td>\n",
       "      <td>0.252391</td>\n",
       "      <td>-0.835363</td>\n",
       "      <td>0.799470</td>\n",
       "      <td>0.356895</td>\n",
       "      <td>0.415980</td>\n",
       "      <td>1.094721</td>\n",
       "      <td>0.131864</td>\n",
       "      <td>0.181516</td>\n",
       "      <td>0.239425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>98.245296</td>\n",
       "      <td>1.360542</td>\n",
       "      <td>14</td>\n",
       "      <td>1.714565</td>\n",
       "      <td>-0.149190</td>\n",
       "      <td>0.713559</td>\n",
       "      <td>-0.650981</td>\n",
       "      <td>-0.937036</td>\n",
       "      <td>1.326184</td>\n",
       "      <td>1.586319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.657954</td>\n",
       "      <td>0.146233</td>\n",
       "      <td>-0.761506</td>\n",
       "      <td>0.694724</td>\n",
       "      <td>0.687310</td>\n",
       "      <td>0.729889</td>\n",
       "      <td>0.550284</td>\n",
       "      <td>0.129255</td>\n",
       "      <td>0.177092</td>\n",
       "      <td>0.233075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>100.527171</td>\n",
       "      <td>1.387331</td>\n",
       "      <td>11</td>\n",
       "      <td>1.771999</td>\n",
       "      <td>-0.149190</td>\n",
       "      <td>0.786215</td>\n",
       "      <td>-0.669889</td>\n",
       "      <td>-0.902668</td>\n",
       "      <td>1.717213</td>\n",
       "      <td>1.514250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.682765</td>\n",
       "      <td>0.092975</td>\n",
       "      <td>-0.870989</td>\n",
       "      <td>0.742121</td>\n",
       "      <td>0.374878</td>\n",
       "      <td>0.304298</td>\n",
       "      <td>0.444606</td>\n",
       "      <td>0.129458</td>\n",
       "      <td>0.175094</td>\n",
       "      <td>0.225587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>94.902995</td>\n",
       "      <td>1.391027</td>\n",
       "      <td>7</td>\n",
       "      <td>1.821847</td>\n",
       "      <td>-0.009313</td>\n",
       "      <td>0.828527</td>\n",
       "      <td>-0.741714</td>\n",
       "      <td>-0.807926</td>\n",
       "      <td>1.523948</td>\n",
       "      <td>1.723703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.758441</td>\n",
       "      <td>0.392156</td>\n",
       "      <td>-1.025497</td>\n",
       "      <td>0.918047</td>\n",
       "      <td>0.573125</td>\n",
       "      <td>0.193399</td>\n",
       "      <td>0.262078</td>\n",
       "      <td>0.128364</td>\n",
       "      <td>0.174815</td>\n",
       "      <td>0.222414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>102.487545</td>\n",
       "      <td>1.359509</td>\n",
       "      <td>7</td>\n",
       "      <td>1.821847</td>\n",
       "      <td>-0.078247</td>\n",
       "      <td>0.770966</td>\n",
       "      <td>-0.754207</td>\n",
       "      <td>-0.795563</td>\n",
       "      <td>1.353717</td>\n",
       "      <td>1.694970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756640</td>\n",
       "      <td>0.121150</td>\n",
       "      <td>-0.969083</td>\n",
       "      <td>0.948017</td>\n",
       "      <td>0.878901</td>\n",
       "      <td>0.192182</td>\n",
       "      <td>0.622840</td>\n",
       "      <td>0.126270</td>\n",
       "      <td>0.173775</td>\n",
       "      <td>0.221624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>108.900845</td>\n",
       "      <td>1.344979</td>\n",
       "      <td>6</td>\n",
       "      <td>1.857509</td>\n",
       "      <td>-0.078247</td>\n",
       "      <td>0.760305</td>\n",
       "      <td>-0.730384</td>\n",
       "      <td>-0.807791</td>\n",
       "      <td>1.357898</td>\n",
       "      <td>1.616392</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.719767</td>\n",
       "      <td>0.081930</td>\n",
       "      <td>-0.941214</td>\n",
       "      <td>0.904174</td>\n",
       "      <td>0.712077</td>\n",
       "      <td>0.538247</td>\n",
       "      <td>1.142288</td>\n",
       "      <td>0.125267</td>\n",
       "      <td>0.172130</td>\n",
       "      <td>0.219561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>109.154748</td>\n",
       "      <td>1.342602</td>\n",
       "      <td>10</td>\n",
       "      <td>1.857509</td>\n",
       "      <td>-0.131206</td>\n",
       "      <td>0.752882</td>\n",
       "      <td>-0.746872</td>\n",
       "      <td>-0.798955</td>\n",
       "      <td>1.546340</td>\n",
       "      <td>1.520144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.730288</td>\n",
       "      <td>0.074852</td>\n",
       "      <td>-0.942334</td>\n",
       "      <td>0.934811</td>\n",
       "      <td>0.825119</td>\n",
       "      <td>0.678696</td>\n",
       "      <td>0.906691</td>\n",
       "      <td>0.124248</td>\n",
       "      <td>0.171290</td>\n",
       "      <td>0.217375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>102.646973</td>\n",
       "      <td>1.344636</td>\n",
       "      <td>9</td>\n",
       "      <td>1.802260</td>\n",
       "      <td>-0.131206</td>\n",
       "      <td>0.740430</td>\n",
       "      <td>-0.758812</td>\n",
       "      <td>-0.802888</td>\n",
       "      <td>1.460257</td>\n",
       "      <td>1.555709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755519</td>\n",
       "      <td>0.364381</td>\n",
       "      <td>-0.922208</td>\n",
       "      <td>0.945103</td>\n",
       "      <td>0.749242</td>\n",
       "      <td>0.915445</td>\n",
       "      <td>1.258717</td>\n",
       "      <td>0.123298</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.216757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>94.047589</td>\n",
       "      <td>1.362276</td>\n",
       "      <td>9</td>\n",
       "      <td>1.775034</td>\n",
       "      <td>-0.130712</td>\n",
       "      <td>0.756105</td>\n",
       "      <td>-0.756897</td>\n",
       "      <td>-0.813937</td>\n",
       "      <td>1.394568</td>\n",
       "      <td>1.573560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.757823</td>\n",
       "      <td>0.241106</td>\n",
       "      <td>-0.928949</td>\n",
       "      <td>0.929922</td>\n",
       "      <td>0.398179</td>\n",
       "      <td>0.755275</td>\n",
       "      <td>1.117008</td>\n",
       "      <td>0.122566</td>\n",
       "      <td>0.170022</td>\n",
       "      <td>0.217175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>95.770697</td>\n",
       "      <td>1.379599</td>\n",
       "      <td>12</td>\n",
       "      <td>1.771262</td>\n",
       "      <td>-0.208031</td>\n",
       "      <td>0.776573</td>\n",
       "      <td>-0.759795</td>\n",
       "      <td>-0.813358</td>\n",
       "      <td>1.329132</td>\n",
       "      <td>1.761010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.787883</td>\n",
       "      <td>0.069861</td>\n",
       "      <td>-0.954774</td>\n",
       "      <td>0.934146</td>\n",
       "      <td>0.493444</td>\n",
       "      <td>0.931416</td>\n",
       "      <td>0.519440</td>\n",
       "      <td>0.120759</td>\n",
       "      <td>0.169525</td>\n",
       "      <td>0.218042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>99.687678</td>\n",
       "      <td>1.387466</td>\n",
       "      <td>13</td>\n",
       "      <td>1.825576</td>\n",
       "      <td>-0.208031</td>\n",
       "      <td>0.778579</td>\n",
       "      <td>-0.750619</td>\n",
       "      <td>-0.826945</td>\n",
       "      <td>1.428243</td>\n",
       "      <td>1.872350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761371</td>\n",
       "      <td>0.078687</td>\n",
       "      <td>-0.941513</td>\n",
       "      <td>0.907701</td>\n",
       "      <td>0.446762</td>\n",
       "      <td>0.695264</td>\n",
       "      <td>0.405988</td>\n",
       "      <td>0.119078</td>\n",
       "      <td>0.168535</td>\n",
       "      <td>0.219156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>98.898877</td>\n",
       "      <td>1.394423</td>\n",
       "      <td>9</td>\n",
       "      <td>1.860749</td>\n",
       "      <td>-0.102235</td>\n",
       "      <td>0.781270</td>\n",
       "      <td>-0.729907</td>\n",
       "      <td>-0.853349</td>\n",
       "      <td>1.403245</td>\n",
       "      <td>1.710714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.742465</td>\n",
       "      <td>0.162758</td>\n",
       "      <td>-0.915533</td>\n",
       "      <td>0.855344</td>\n",
       "      <td>0.597968</td>\n",
       "      <td>0.415603</td>\n",
       "      <td>0.624520</td>\n",
       "      <td>0.118110</td>\n",
       "      <td>0.167335</td>\n",
       "      <td>0.220526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>96.307548</td>\n",
       "      <td>1.378818</td>\n",
       "      <td>6</td>\n",
       "      <td>1.860749</td>\n",
       "      <td>-0.057689</td>\n",
       "      <td>0.787840</td>\n",
       "      <td>-0.747305</td>\n",
       "      <td>-0.814065</td>\n",
       "      <td>1.585836</td>\n",
       "      <td>1.891071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755465</td>\n",
       "      <td>0.336637</td>\n",
       "      <td>-0.967785</td>\n",
       "      <td>0.917991</td>\n",
       "      <td>0.274690</td>\n",
       "      <td>0.081796</td>\n",
       "      <td>0.347779</td>\n",
       "      <td>0.117879</td>\n",
       "      <td>0.166682</td>\n",
       "      <td>0.220755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>96.702952</td>\n",
       "      <td>1.349875</td>\n",
       "      <td>6</td>\n",
       "      <td>1.828100</td>\n",
       "      <td>-0.029004</td>\n",
       "      <td>0.764451</td>\n",
       "      <td>-0.767287</td>\n",
       "      <td>-0.782714</td>\n",
       "      <td>1.464625</td>\n",
       "      <td>1.787889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.740771</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>-0.976667</td>\n",
       "      <td>0.980291</td>\n",
       "      <td>0.393992</td>\n",
       "      <td>0.102864</td>\n",
       "      <td>0.831110</td>\n",
       "      <td>0.118133</td>\n",
       "      <td>0.166568</td>\n",
       "      <td>0.219411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>109.502374</td>\n",
       "      <td>1.355172</td>\n",
       "      <td>7</td>\n",
       "      <td>1.854060</td>\n",
       "      <td>-0.051702</td>\n",
       "      <td>0.753059</td>\n",
       "      <td>-0.749572</td>\n",
       "      <td>-0.814916</td>\n",
       "      <td>1.405809</td>\n",
       "      <td>1.519122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692027</td>\n",
       "      <td>0.228329</td>\n",
       "      <td>-0.924094</td>\n",
       "      <td>0.919815</td>\n",
       "      <td>0.875586</td>\n",
       "      <td>0.621358</td>\n",
       "      <td>1.191681</td>\n",
       "      <td>0.117878</td>\n",
       "      <td>0.166404</td>\n",
       "      <td>0.220085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>116.394760</td>\n",
       "      <td>1.380513</td>\n",
       "      <td>8</td>\n",
       "      <td>1.854060</td>\n",
       "      <td>-0.051702</td>\n",
       "      <td>0.816185</td>\n",
       "      <td>-0.776699</td>\n",
       "      <td>-0.721390</td>\n",
       "      <td>1.881259</td>\n",
       "      <td>1.738262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781398</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>-1.131406</td>\n",
       "      <td>1.076670</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.786356</td>\n",
       "      <td>1.240218</td>\n",
       "      <td>0.119135</td>\n",
       "      <td>0.166836</td>\n",
       "      <td>0.223415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>109.615936</td>\n",
       "      <td>1.510821</td>\n",
       "      <td>12</td>\n",
       "      <td>2.360111</td>\n",
       "      <td>-0.102887</td>\n",
       "      <td>1.124904</td>\n",
       "      <td>-0.621356</td>\n",
       "      <td>-0.352783</td>\n",
       "      <td>3.616662</td>\n",
       "      <td>2.766881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.730265</td>\n",
       "      <td>0.760603</td>\n",
       "      <td>-3.188658</td>\n",
       "      <td>1.761300</td>\n",
       "      <td>0.877253</td>\n",
       "      <td>0.789743</td>\n",
       "      <td>0.669656</td>\n",
       "      <td>0.130391</td>\n",
       "      <td>0.174915</td>\n",
       "      <td>0.228530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>107.197481</td>\n",
       "      <td>1.521793</td>\n",
       "      <td>18</td>\n",
       "      <td>2.542108</td>\n",
       "      <td>-0.278029</td>\n",
       "      <td>1.305427</td>\n",
       "      <td>-0.007060</td>\n",
       "      <td>-0.205313</td>\n",
       "      <td>3.929681</td>\n",
       "      <td>3.263623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.599603</td>\n",
       "      <td>-6.358237</td>\n",
       "      <td>0.034385</td>\n",
       "      <td>1.398453</td>\n",
       "      <td>1.141195</td>\n",
       "      <td>0.276229</td>\n",
       "      <td>0.140732</td>\n",
       "      <td>0.186457</td>\n",
       "      <td>0.231050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>97.611163</td>\n",
       "      <td>1.337596</td>\n",
       "      <td>18</td>\n",
       "      <td>2.787768</td>\n",
       "      <td>-0.367846</td>\n",
       "      <td>1.085107</td>\n",
       "      <td>0.493045</td>\n",
       "      <td>-0.272621</td>\n",
       "      <td>4.004222</td>\n",
       "      <td>3.797662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416234</td>\n",
       "      <td>1.163063</td>\n",
       "      <td>-3.980283</td>\n",
       "      <td>-1.808539</td>\n",
       "      <td>2.427015</td>\n",
       "      <td>0.693736</td>\n",
       "      <td>0.076705</td>\n",
       "      <td>0.147303</td>\n",
       "      <td>0.189583</td>\n",
       "      <td>0.231789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>84.728459</td>\n",
       "      <td>1.137462</td>\n",
       "      <td>16</td>\n",
       "      <td>2.787768</td>\n",
       "      <td>-0.805225</td>\n",
       "      <td>0.682007</td>\n",
       "      <td>0.689005</td>\n",
       "      <td>-0.306396</td>\n",
       "      <td>2.982157</td>\n",
       "      <td>3.858923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645383</td>\n",
       "      <td>1.260064</td>\n",
       "      <td>-2.225903</td>\n",
       "      <td>-2.248741</td>\n",
       "      <td>1.381585</td>\n",
       "      <td>0.481171</td>\n",
       "      <td>0.062616</td>\n",
       "      <td>0.154285</td>\n",
       "      <td>0.193580</td>\n",
       "      <td>0.230438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>74.483441</td>\n",
       "      <td>0.948787</td>\n",
       "      <td>12</td>\n",
       "      <td>1.710222</td>\n",
       "      <td>-1.275452</td>\n",
       "      <td>0.269216</td>\n",
       "      <td>0.738074</td>\n",
       "      <td>-0.372125</td>\n",
       "      <td>1.953287</td>\n",
       "      <td>2.489452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700643</td>\n",
       "      <td>0.612980</td>\n",
       "      <td>-0.723455</td>\n",
       "      <td>-1.983402</td>\n",
       "      <td>0.348549</td>\n",
       "      <td>0.496770</td>\n",
       "      <td>0.170647</td>\n",
       "      <td>0.156555</td>\n",
       "      <td>0.195372</td>\n",
       "      <td>0.231140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90839249-5057-4ccc-b0ce-a73dad2be07c</th>\n",
       "      <td>59.160786</td>\n",
       "      <td>0.774666</td>\n",
       "      <td>9</td>\n",
       "      <td>1.710222</td>\n",
       "      <td>-2.584695</td>\n",
       "      <td>-0.087773</td>\n",
       "      <td>0.564067</td>\n",
       "      <td>-0.340849</td>\n",
       "      <td>1.892667</td>\n",
       "      <td>2.283208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526914</td>\n",
       "      <td>0.245872</td>\n",
       "      <td>0.257513</td>\n",
       "      <td>-1.654890</td>\n",
       "      <td>0.198529</td>\n",
       "      <td>0.454449</td>\n",
       "      <td>0.040465</td>\n",
       "      <td>0.161543</td>\n",
       "      <td>0.197066</td>\n",
       "      <td>0.231756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>54.670532</td>\n",
       "      <td>0.575156</td>\n",
       "      <td>13</td>\n",
       "      <td>1.084443</td>\n",
       "      <td>-2.989565</td>\n",
       "      <td>-0.060434</td>\n",
       "      <td>0.366474</td>\n",
       "      <td>-0.177837</td>\n",
       "      <td>1.240506</td>\n",
       "      <td>1.557306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390761</td>\n",
       "      <td>0.286877</td>\n",
       "      <td>0.339828</td>\n",
       "      <td>-2.060733</td>\n",
       "      <td>0.108185</td>\n",
       "      <td>0.591215</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.283205</td>\n",
       "      <td>0.207867</td>\n",
       "      <td>0.134309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>50.197878</td>\n",
       "      <td>0.590773</td>\n",
       "      <td>13</td>\n",
       "      <td>0.995646</td>\n",
       "      <td>-2.989565</td>\n",
       "      <td>-0.003278</td>\n",
       "      <td>0.329506</td>\n",
       "      <td>-0.188336</td>\n",
       "      <td>1.476970</td>\n",
       "      <td>1.496544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389953</td>\n",
       "      <td>0.075689</td>\n",
       "      <td>0.017404</td>\n",
       "      <td>-1.749560</td>\n",
       "      <td>0.285561</td>\n",
       "      <td>0.262477</td>\n",
       "      <td>0.033367</td>\n",
       "      <td>0.283366</td>\n",
       "      <td>0.207964</td>\n",
       "      <td>0.134221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>47.782384</td>\n",
       "      <td>0.590482</td>\n",
       "      <td>13</td>\n",
       "      <td>0.942986</td>\n",
       "      <td>-2.138058</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>0.315417</td>\n",
       "      <td>-0.135908</td>\n",
       "      <td>1.563046</td>\n",
       "      <td>1.666211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392547</td>\n",
       "      <td>0.248879</td>\n",
       "      <td>-0.268926</td>\n",
       "      <td>-2.320806</td>\n",
       "      <td>0.252182</td>\n",
       "      <td>0.439522</td>\n",
       "      <td>0.092253</td>\n",
       "      <td>0.283636</td>\n",
       "      <td>0.208019</td>\n",
       "      <td>0.134122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>42.196222</td>\n",
       "      <td>0.556906</td>\n",
       "      <td>16</td>\n",
       "      <td>0.864719</td>\n",
       "      <td>-2.138058</td>\n",
       "      <td>0.055710</td>\n",
       "      <td>0.293009</td>\n",
       "      <td>-0.084476</td>\n",
       "      <td>1.468887</td>\n",
       "      <td>1.447788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367362</td>\n",
       "      <td>0.075561</td>\n",
       "      <td>-0.659481</td>\n",
       "      <td>-3.468569</td>\n",
       "      <td>0.297095</td>\n",
       "      <td>0.200665</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.283847</td>\n",
       "      <td>0.208008</td>\n",
       "      <td>0.134009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>39.810042</td>\n",
       "      <td>0.527231</td>\n",
       "      <td>15</td>\n",
       "      <td>0.843019</td>\n",
       "      <td>-2.010558</td>\n",
       "      <td>0.039838</td>\n",
       "      <td>0.267278</td>\n",
       "      <td>-0.009021</td>\n",
       "      <td>1.491368</td>\n",
       "      <td>1.334600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304961</td>\n",
       "      <td>0.084338</td>\n",
       "      <td>-4.416305</td>\n",
       "      <td>-29.629503</td>\n",
       "      <td>0.223166</td>\n",
       "      <td>0.113958</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>0.283988</td>\n",
       "      <td>0.207988</td>\n",
       "      <td>0.133984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>36.931195</td>\n",
       "      <td>0.503638</td>\n",
       "      <td>14</td>\n",
       "      <td>0.764068</td>\n",
       "      <td>-1.442573</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.240355</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>1.537252</td>\n",
       "      <td>1.522780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220977</td>\n",
       "      <td>0.302821</td>\n",
       "      <td>0.117769</td>\n",
       "      <td>3.151337</td>\n",
       "      <td>0.092346</td>\n",
       "      <td>0.163031</td>\n",
       "      <td>0.074937</td>\n",
       "      <td>0.284105</td>\n",
       "      <td>0.207942</td>\n",
       "      <td>0.133973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>34.658806</td>\n",
       "      <td>0.460887</td>\n",
       "      <td>15</td>\n",
       "      <td>0.764068</td>\n",
       "      <td>-1.790348</td>\n",
       "      <td>-0.016127</td>\n",
       "      <td>0.154874</td>\n",
       "      <td>0.088969</td>\n",
       "      <td>1.355097</td>\n",
       "      <td>1.697312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160941</td>\n",
       "      <td>0.131571</td>\n",
       "      <td>-0.181271</td>\n",
       "      <td>1.740769</td>\n",
       "      <td>0.080994</td>\n",
       "      <td>0.167767</td>\n",
       "      <td>0.020826</td>\n",
       "      <td>0.284131</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.133917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>32.293427</td>\n",
       "      <td>0.413331</td>\n",
       "      <td>16</td>\n",
       "      <td>0.702907</td>\n",
       "      <td>-1.833830</td>\n",
       "      <td>-0.042679</td>\n",
       "      <td>0.055726</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>1.363648</td>\n",
       "      <td>1.123566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044463</td>\n",
       "      <td>0.171553</td>\n",
       "      <td>-1.249398</td>\n",
       "      <td>1.631330</td>\n",
       "      <td>0.071188</td>\n",
       "      <td>0.077944</td>\n",
       "      <td>0.020183</td>\n",
       "      <td>0.283994</td>\n",
       "      <td>0.207949</td>\n",
       "      <td>0.133869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>29.552085</td>\n",
       "      <td>0.380679</td>\n",
       "      <td>16</td>\n",
       "      <td>0.643823</td>\n",
       "      <td>-2.261571</td>\n",
       "      <td>-0.029943</td>\n",
       "      <td>0.058551</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>1.431346</td>\n",
       "      <td>1.380150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.072429</td>\n",
       "      <td>139.884578</td>\n",
       "      <td>-273.532282</td>\n",
       "      <td>0.108464</td>\n",
       "      <td>0.055813</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.283855</td>\n",
       "      <td>0.207907</td>\n",
       "      <td>0.133806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>28.628681</td>\n",
       "      <td>0.388151</td>\n",
       "      <td>15</td>\n",
       "      <td>0.748551</td>\n",
       "      <td>-2.261571</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>0.121179</td>\n",
       "      <td>-0.001118</td>\n",
       "      <td>1.501596</td>\n",
       "      <td>1.056335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080848</td>\n",
       "      <td>0.088312</td>\n",
       "      <td>-12.723873</td>\n",
       "      <td>-108.346334</td>\n",
       "      <td>0.044698</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.283832</td>\n",
       "      <td>0.207777</td>\n",
       "      <td>0.133723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>31.202012</td>\n",
       "      <td>0.424769</td>\n",
       "      <td>12</td>\n",
       "      <td>0.748551</td>\n",
       "      <td>-2.296559</td>\n",
       "      <td>0.027899</td>\n",
       "      <td>0.161286</td>\n",
       "      <td>-0.007585</td>\n",
       "      <td>1.290107</td>\n",
       "      <td>1.100962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113425</td>\n",
       "      <td>0.072110</td>\n",
       "      <td>-3.678264</td>\n",
       "      <td>-21.264081</td>\n",
       "      <td>0.082740</td>\n",
       "      <td>0.058674</td>\n",
       "      <td>0.025675</td>\n",
       "      <td>0.283891</td>\n",
       "      <td>0.207667</td>\n",
       "      <td>0.133650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>37.043244</td>\n",
       "      <td>0.474132</td>\n",
       "      <td>9</td>\n",
       "      <td>0.811739</td>\n",
       "      <td>-2.296559</td>\n",
       "      <td>0.044889</td>\n",
       "      <td>0.215733</td>\n",
       "      <td>0.020089</td>\n",
       "      <td>1.468869</td>\n",
       "      <td>1.291631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174560</td>\n",
       "      <td>0.237978</td>\n",
       "      <td>2.234494</td>\n",
       "      <td>10.738798</td>\n",
       "      <td>0.114589</td>\n",
       "      <td>0.046153</td>\n",
       "      <td>0.068277</td>\n",
       "      <td>0.283968</td>\n",
       "      <td>0.207623</td>\n",
       "      <td>0.133653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>40.417721</td>\n",
       "      <td>0.521556</td>\n",
       "      <td>13</td>\n",
       "      <td>0.811739</td>\n",
       "      <td>-2.106328</td>\n",
       "      <td>0.071501</td>\n",
       "      <td>0.263963</td>\n",
       "      <td>0.051385</td>\n",
       "      <td>1.597287</td>\n",
       "      <td>1.274305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277282</td>\n",
       "      <td>0.086551</td>\n",
       "      <td>1.391487</td>\n",
       "      <td>5.136993</td>\n",
       "      <td>0.221140</td>\n",
       "      <td>0.064596</td>\n",
       "      <td>0.041588</td>\n",
       "      <td>0.284096</td>\n",
       "      <td>0.207568</td>\n",
       "      <td>0.133740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>75.082048</td>\n",
       "      <td>0.854830</td>\n",
       "      <td>8</td>\n",
       "      <td>1.886988</td>\n",
       "      <td>-1.942437</td>\n",
       "      <td>-0.156788</td>\n",
       "      <td>-0.100397</td>\n",
       "      <td>-0.219808</td>\n",
       "      <td>3.007575</td>\n",
       "      <td>2.863405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142211</td>\n",
       "      <td>0.882256</td>\n",
       "      <td>0.713297</td>\n",
       "      <td>0.456749</td>\n",
       "      <td>1.174703</td>\n",
       "      <td>1.360654</td>\n",
       "      <td>0.701078</td>\n",
       "      <td>0.284697</td>\n",
       "      <td>0.208582</td>\n",
       "      <td>0.134190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>94.444034</td>\n",
       "      <td>1.329242</td>\n",
       "      <td>10</td>\n",
       "      <td>1.886988</td>\n",
       "      <td>-0.720750</td>\n",
       "      <td>-0.597080</td>\n",
       "      <td>-0.750786</td>\n",
       "      <td>-0.553879</td>\n",
       "      <td>3.399014</td>\n",
       "      <td>3.539193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.995751</td>\n",
       "      <td>0.383466</td>\n",
       "      <td>1.077998</td>\n",
       "      <td>1.355506</td>\n",
       "      <td>1.566478</td>\n",
       "      <td>1.597249</td>\n",
       "      <td>0.434970</td>\n",
       "      <td>0.284928</td>\n",
       "      <td>0.209312</td>\n",
       "      <td>0.134474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>87.495524</td>\n",
       "      <td>1.165725</td>\n",
       "      <td>10</td>\n",
       "      <td>1.811632</td>\n",
       "      <td>-1.141026</td>\n",
       "      <td>-0.420132</td>\n",
       "      <td>-0.614889</td>\n",
       "      <td>-0.542789</td>\n",
       "      <td>2.771241</td>\n",
       "      <td>3.365093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918069</td>\n",
       "      <td>0.584309</td>\n",
       "      <td>0.774024</td>\n",
       "      <td>1.132832</td>\n",
       "      <td>0.914419</td>\n",
       "      <td>1.417420</td>\n",
       "      <td>0.700633</td>\n",
       "      <td>0.285448</td>\n",
       "      <td>0.210122</td>\n",
       "      <td>0.134747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>54.148387</td>\n",
       "      <td>0.686534</td>\n",
       "      <td>11</td>\n",
       "      <td>1.510674</td>\n",
       "      <td>-2.140450</td>\n",
       "      <td>0.042709</td>\n",
       "      <td>-0.012121</td>\n",
       "      <td>-0.304625</td>\n",
       "      <td>2.166259</td>\n",
       "      <td>2.603800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140143</td>\n",
       "      <td>0.289127</td>\n",
       "      <td>-0.140202</td>\n",
       "      <td>0.039789</td>\n",
       "      <td>0.541762</td>\n",
       "      <td>0.814258</td>\n",
       "      <td>0.195182</td>\n",
       "      <td>0.285778</td>\n",
       "      <td>0.210579</td>\n",
       "      <td>0.134944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>38.922347</td>\n",
       "      <td>0.505641</td>\n",
       "      <td>10</td>\n",
       "      <td>0.985312</td>\n",
       "      <td>-2.140450</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.149271</td>\n",
       "      <td>-0.123074</td>\n",
       "      <td>1.594438</td>\n",
       "      <td>1.395415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235526</td>\n",
       "      <td>0.088317</td>\n",
       "      <td>-1.002111</td>\n",
       "      <td>-1.212861</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.187069</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>0.285859</td>\n",
       "      <td>0.210689</td>\n",
       "      <td>0.134856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>46.782520</td>\n",
       "      <td>0.581770</td>\n",
       "      <td>13</td>\n",
       "      <td>1.053941</td>\n",
       "      <td>-1.637924</td>\n",
       "      <td>0.058261</td>\n",
       "      <td>0.335409</td>\n",
       "      <td>-0.106074</td>\n",
       "      <td>1.535914</td>\n",
       "      <td>1.903042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364928</td>\n",
       "      <td>0.158951</td>\n",
       "      <td>-0.549252</td>\n",
       "      <td>-3.162031</td>\n",
       "      <td>0.106726</td>\n",
       "      <td>0.398723</td>\n",
       "      <td>0.020272</td>\n",
       "      <td>0.285814</td>\n",
       "      <td>0.210847</td>\n",
       "      <td>0.134881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>57.402264</td>\n",
       "      <td>0.693930</td>\n",
       "      <td>17</td>\n",
       "      <td>1.053941</td>\n",
       "      <td>-1.637924</td>\n",
       "      <td>-0.036074</td>\n",
       "      <td>0.538527</td>\n",
       "      <td>-0.093952</td>\n",
       "      <td>1.625960</td>\n",
       "      <td>1.667349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520362</td>\n",
       "      <td>0.123037</td>\n",
       "      <td>0.383964</td>\n",
       "      <td>-5.731964</td>\n",
       "      <td>0.220850</td>\n",
       "      <td>0.242931</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>0.285831</td>\n",
       "      <td>0.210763</td>\n",
       "      <td>0.134990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>59.193564</td>\n",
       "      <td>0.718177</td>\n",
       "      <td>16</td>\n",
       "      <td>1.047500</td>\n",
       "      <td>-1.377616</td>\n",
       "      <td>-0.016416</td>\n",
       "      <td>0.510769</td>\n",
       "      <td>-0.093306</td>\n",
       "      <td>1.583041</td>\n",
       "      <td>1.875385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532638</td>\n",
       "      <td>0.131984</td>\n",
       "      <td>0.175934</td>\n",
       "      <td>-5.474108</td>\n",
       "      <td>0.472589</td>\n",
       "      <td>0.631294</td>\n",
       "      <td>0.059678</td>\n",
       "      <td>0.286101</td>\n",
       "      <td>0.210636</td>\n",
       "      <td>0.135071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>55.269961</td>\n",
       "      <td>0.720331</td>\n",
       "      <td>16</td>\n",
       "      <td>1.036543</td>\n",
       "      <td>-1.377616</td>\n",
       "      <td>0.044006</td>\n",
       "      <td>0.461338</td>\n",
       "      <td>-0.104996</td>\n",
       "      <td>1.749718</td>\n",
       "      <td>1.598822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534621</td>\n",
       "      <td>0.088217</td>\n",
       "      <td>-0.419126</td>\n",
       "      <td>-4.393870</td>\n",
       "      <td>0.527972</td>\n",
       "      <td>0.231336</td>\n",
       "      <td>0.015047</td>\n",
       "      <td>0.286480</td>\n",
       "      <td>0.210557</td>\n",
       "      <td>0.135106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>51.777941</td>\n",
       "      <td>0.733484</td>\n",
       "      <td>16</td>\n",
       "      <td>1.224945</td>\n",
       "      <td>-0.926932</td>\n",
       "      <td>0.048026</td>\n",
       "      <td>0.443718</td>\n",
       "      <td>-0.147762</td>\n",
       "      <td>1.745421</td>\n",
       "      <td>1.674620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520987</td>\n",
       "      <td>0.090344</td>\n",
       "      <td>-0.325023</td>\n",
       "      <td>-3.002924</td>\n",
       "      <td>0.500751</td>\n",
       "      <td>0.140482</td>\n",
       "      <td>0.023202</td>\n",
       "      <td>0.286942</td>\n",
       "      <td>0.210523</td>\n",
       "      <td>0.135128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>53.430303</td>\n",
       "      <td>0.733542</td>\n",
       "      <td>20</td>\n",
       "      <td>1.224945</td>\n",
       "      <td>-0.877499</td>\n",
       "      <td>0.073468</td>\n",
       "      <td>0.437851</td>\n",
       "      <td>-0.153555</td>\n",
       "      <td>1.743833</td>\n",
       "      <td>1.748031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511786</td>\n",
       "      <td>0.166433</td>\n",
       "      <td>-0.478449</td>\n",
       "      <td>-2.851425</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.199524</td>\n",
       "      <td>0.041826</td>\n",
       "      <td>0.287370</td>\n",
       "      <td>0.210571</td>\n",
       "      <td>0.135136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>51.214433</td>\n",
       "      <td>0.693997</td>\n",
       "      <td>17</td>\n",
       "      <td>1.200535</td>\n",
       "      <td>-0.923485</td>\n",
       "      <td>0.118693</td>\n",
       "      <td>0.376886</td>\n",
       "      <td>-0.115565</td>\n",
       "      <td>1.815211</td>\n",
       "      <td>1.703896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467521</td>\n",
       "      <td>0.071888</td>\n",
       "      <td>-1.027066</td>\n",
       "      <td>-3.261252</td>\n",
       "      <td>0.094648</td>\n",
       "      <td>0.300684</td>\n",
       "      <td>0.022210</td>\n",
       "      <td>0.287790</td>\n",
       "      <td>0.210652</td>\n",
       "      <td>0.135053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>44.914665</td>\n",
       "      <td>0.650373</td>\n",
       "      <td>14</td>\n",
       "      <td>1.085397</td>\n",
       "      <td>-1.012870</td>\n",
       "      <td>0.088389</td>\n",
       "      <td>0.365390</td>\n",
       "      <td>-0.158675</td>\n",
       "      <td>1.829881</td>\n",
       "      <td>1.595899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434356</td>\n",
       "      <td>0.068317</td>\n",
       "      <td>-0.557043</td>\n",
       "      <td>-2.302763</td>\n",
       "      <td>0.175848</td>\n",
       "      <td>0.314835</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>0.288108</td>\n",
       "      <td>0.210628</td>\n",
       "      <td>0.134981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>54.813194</td>\n",
       "      <td>0.705982</td>\n",
       "      <td>9</td>\n",
       "      <td>1.310744</td>\n",
       "      <td>-1.132053</td>\n",
       "      <td>0.063241</td>\n",
       "      <td>0.222270</td>\n",
       "      <td>-0.219398</td>\n",
       "      <td>2.026275</td>\n",
       "      <td>3.165813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350760</td>\n",
       "      <td>0.090294</td>\n",
       "      <td>-0.288250</td>\n",
       "      <td>-1.013090</td>\n",
       "      <td>0.513440</td>\n",
       "      <td>1.006450</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.288429</td>\n",
       "      <td>0.210976</td>\n",
       "      <td>0.135117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>69.794588</td>\n",
       "      <td>0.975835</td>\n",
       "      <td>6</td>\n",
       "      <td>1.797117</td>\n",
       "      <td>-1.132053</td>\n",
       "      <td>-0.244063</td>\n",
       "      <td>-0.287646</td>\n",
       "      <td>-0.366261</td>\n",
       "      <td>2.087223</td>\n",
       "      <td>2.383438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191880</td>\n",
       "      <td>0.343909</td>\n",
       "      <td>0.666364</td>\n",
       "      <td>0.785358</td>\n",
       "      <td>0.382773</td>\n",
       "      <td>0.100276</td>\n",
       "      <td>0.231170</td>\n",
       "      <td>0.289133</td>\n",
       "      <td>0.212087</td>\n",
       "      <td>0.135395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>70.422743</td>\n",
       "      <td>0.860847</td>\n",
       "      <td>10</td>\n",
       "      <td>1.797117</td>\n",
       "      <td>-2.514068</td>\n",
       "      <td>-0.237525</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>-0.339755</td>\n",
       "      <td>2.910221</td>\n",
       "      <td>2.676493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020616</td>\n",
       "      <td>0.163606</td>\n",
       "      <td>0.699107</td>\n",
       "      <td>0.581294</td>\n",
       "      <td>0.926911</td>\n",
       "      <td>1.080601</td>\n",
       "      <td>0.117749</td>\n",
       "      <td>0.289590</td>\n",
       "      <td>0.213048</td>\n",
       "      <td>0.135599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eacffd55-4883-41de-ade0-828d3ed3873d</th>\n",
       "      <td>47.536576</td>\n",
       "      <td>0.609779</td>\n",
       "      <td>12</td>\n",
       "      <td>1.198004</td>\n",
       "      <td>-2.514068</td>\n",
       "      <td>0.138246</td>\n",
       "      <td>0.256023</td>\n",
       "      <td>-0.177436</td>\n",
       "      <td>1.871819</td>\n",
       "      <td>1.651358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288756</td>\n",
       "      <td>0.106597</td>\n",
       "      <td>-0.779132</td>\n",
       "      <td>-1.442906</td>\n",
       "      <td>0.643658</td>\n",
       "      <td>0.127020</td>\n",
       "      <td>0.128023</td>\n",
       "      <td>0.289851</td>\n",
       "      <td>0.213211</td>\n",
       "      <td>0.135550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60896 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fundamental_freq  average_accel  \\\n",
       "healthCode                                                              \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        108.314444       1.361654   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         95.117992       1.399965   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         93.161575       1.300919   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        100.162152       1.274289   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        108.066819       1.299515   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        109.731461       1.307171   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        107.141324       1.307852   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        103.723405       1.313845   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         95.706105       1.338492   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         98.245296       1.360542   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        100.527171       1.387331   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         94.902995       1.391027   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        102.487545       1.359509   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        108.900845       1.344979   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        109.154748       1.342602   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        102.646973       1.344636   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         94.047589       1.362276   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         95.770697       1.379599   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         99.687678       1.387466   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         98.898877       1.394423   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         96.307548       1.378818   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         96.702952       1.349875   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        109.502374       1.355172   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        116.394760       1.380513   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        109.615936       1.510821   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c        107.197481       1.521793   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         97.611163       1.337596   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         84.728459       1.137462   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         74.483441       0.948787   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         59.160786       0.774666   \n",
       "...                                                ...            ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         54.670532       0.575156   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         50.197878       0.590773   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         47.782384       0.590482   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         42.196222       0.556906   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         39.810042       0.527231   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         36.931195       0.503638   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         34.658806       0.460887   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         32.293427       0.413331   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         29.552085       0.380679   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         28.628681       0.388151   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         31.202012       0.424769   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         37.043244       0.474132   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         40.417721       0.521556   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         75.082048       0.854830   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         94.444034       1.329242   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         87.495524       1.165725   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         54.148387       0.686534   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         38.922347       0.505641   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         46.782520       0.581770   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         57.402264       0.693930   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         59.193564       0.718177   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         55.269961       0.720331   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         51.777941       0.733484   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         53.430303       0.733542   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         51.214433       0.693997   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         44.914665       0.650373   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         54.813194       0.705982   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         69.794588       0.975835   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         70.422743       0.860847   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         47.536576       0.609779   \n",
       "\n",
       "                                      peakcount       max       min     mut_x  \\\n",
       "healthCode                                                                      \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  2.064969 -0.330143  0.690610   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         13  2.064969 -0.330143  0.802499   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  1.786842 -0.142095  0.615637   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.683957 -0.142095  0.531247   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.729218 -0.205279  0.581625   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          8  1.862491 -0.205279  0.613979   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.862491 -0.117244  0.620030   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.831361 -0.116085  0.668747   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.831361 -0.116085  0.723892   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         14  1.714565 -0.149190  0.713559   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         11  1.771999 -0.149190  0.786215   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          7  1.821847 -0.009313  0.828527   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          7  1.821847 -0.078247  0.770966   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          6  1.857509 -0.078247  0.760305   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         10  1.857509 -0.131206  0.752882   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.802260 -0.131206  0.740430   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.775034 -0.130712  0.756105   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  1.771262 -0.208031  0.776573   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         13  1.825576 -0.208031  0.778579   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.860749 -0.102235  0.781270   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          6  1.860749 -0.057689  0.787840   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          6  1.828100 -0.029004  0.764451   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          7  1.854060 -0.051702  0.753059   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          8  1.854060 -0.051702  0.816185   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  2.360111 -0.102887  1.124904   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         18  2.542108 -0.278029  1.305427   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         18  2.787768 -0.367846  1.085107   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         16  2.787768 -0.805225  0.682007   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         12  1.710222 -1.275452  0.269216   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c          9  1.710222 -2.584695 -0.087773   \n",
       "...                                         ...       ...       ...       ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         13  1.084443 -2.989565 -0.060434   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         13  0.995646 -2.989565 -0.003278   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         13  0.942986 -2.138058  0.036549   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  0.864719 -2.138058  0.055710   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         15  0.843019 -2.010558  0.039838   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         14  0.764068 -1.442573  0.008982   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         15  0.764068 -1.790348 -0.016127   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  0.702907 -1.833830 -0.042679   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  0.643823 -2.261571 -0.029943   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         15  0.748551 -2.261571  0.014231   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         12  0.748551 -2.296559  0.027899   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d          9  0.811739 -2.296559  0.044889   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         13  0.811739 -2.106328  0.071501   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d          8  1.886988 -1.942437 -0.156788   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         10  1.886988 -0.720750 -0.597080   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         10  1.811632 -1.141026 -0.420132   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         11  1.510674 -2.140450  0.042709   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         10  0.985312 -2.140450  0.123333   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         13  1.053941 -1.637924  0.058261   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         17  1.053941 -1.637924 -0.036074   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  1.047500 -1.377616 -0.016416   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  1.036543 -1.377616  0.044006   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         16  1.224945 -0.926932  0.048026   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         20  1.224945 -0.877499  0.073468   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         17  1.200535 -0.923485  0.118693   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         14  1.085397 -1.012870  0.088389   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d          9  1.310744 -1.132053  0.063241   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d          6  1.797117 -1.132053 -0.244063   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         10  1.797117 -2.514068 -0.237525   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         12  1.198004 -2.514068  0.138246   \n",
       "\n",
       "                                         mut_y     mut_z     muf_x     muf_y  \\\n",
       "healthCode                                                                     \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.886621 -0.622883  2.408580  2.420899   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.909826 -0.563515  2.063195  2.432729   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.780069 -0.795731  1.537021  1.699596   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.750150 -0.853475  1.151398  1.632215   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.740917 -0.868740  1.131018  1.579905   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.713431 -0.877655  1.197633  1.555487   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.699920 -0.883751  1.157659  1.531361   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.721150 -0.849102  1.293646  1.541653   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.692789 -0.866560  1.400238  1.525359   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.650981 -0.937036  1.326184  1.586319   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.669889 -0.902668  1.717213  1.514250   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.741714 -0.807926  1.523948  1.723703   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.754207 -0.795563  1.353717  1.694970   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.730384 -0.807791  1.357898  1.616392   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.746872 -0.798955  1.546340  1.520144   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.758812 -0.802888  1.460257  1.555709   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.756897 -0.813937  1.394568  1.573560   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.759795 -0.813358  1.329132  1.761010   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.750619 -0.826945  1.428243  1.872350   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.729907 -0.853349  1.403245  1.710714   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.747305 -0.814065  1.585836  1.891071   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.767287 -0.782714  1.464625  1.787889   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.749572 -0.814916  1.405809  1.519122   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.776699 -0.721390  1.881259  1.738262   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.621356 -0.352783  3.616662  2.766881   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c -0.007060 -0.205313  3.929681  3.263623   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c  0.493045 -0.272621  4.004222  3.797662   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c  0.689005 -0.306396  2.982157  3.858923   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c  0.738074 -0.372125  1.953287  2.489452   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c  0.564067 -0.340849  1.892667  2.283208   \n",
       "...                                        ...       ...       ...       ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.366474 -0.177837  1.240506  1.557306   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.329506 -0.188336  1.476970  1.496544   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.315417 -0.135908  1.563046  1.666211   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.293009 -0.084476  1.468887  1.447788   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.267278 -0.009021  1.491368  1.334600   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.240355  0.076271  1.537252  1.522780   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.154874  0.088969  1.355097  1.697312   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.055726  0.034160  1.363648  1.123566   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.058551 -0.000214  1.431346  1.380150   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.121179 -0.001118  1.501596  1.056335   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.161286 -0.007585  1.290107  1.100962   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.215733  0.020089  1.468869  1.291631   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.263963  0.051385  1.597287  1.274305   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.100397 -0.219808  3.007575  2.863405   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.750786 -0.553879  3.399014  3.539193   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.614889 -0.542789  2.771241  3.365093   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.012121 -0.304625  2.166259  2.603800   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.149271 -0.123074  1.594438  1.395415   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.335409 -0.106074  1.535914  1.903042   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.538527 -0.093952  1.625960  1.667349   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.510769 -0.093306  1.583041  1.875385   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.461338 -0.104996  1.749718  1.598822   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.443718 -0.147762  1.745421  1.674620   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.437851 -0.153555  1.743833  1.748031   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.376886 -0.115565  1.815211  1.703896   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.365390 -0.158675  1.829881  1.595899   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.222270 -0.219398  2.026275  3.165813   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.287646 -0.366261  2.087223  2.383438   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d -0.197497 -0.339755  2.910221  2.676493   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  0.256023 -0.177436  1.871819  1.651358   \n",
       "\n",
       "                                             ...            medf_y    medf_z  \\\n",
       "healthCode                                   ...                               \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.815326  0.261730   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.900119  0.383518   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.781222  0.208414   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.779094  0.077215   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.737040  0.084270   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.714885  0.182796   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.726893  0.146422   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.706561  0.157716   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.656978  0.252391   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.657954  0.146233   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.682765  0.092975   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.758441  0.392156   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.756640  0.121150   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.719767  0.081930   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.730288  0.074852   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.755519  0.364381   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.757823  0.241106   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.787883  0.069861   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.761371  0.078687   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.742465  0.162758   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.755465  0.336637   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.740771  0.078777   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.692027  0.228329   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.781398  0.792999   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...         -0.730265  0.760603   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...          0.135800  0.599603   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...          0.416234  1.163063   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...          0.645383  1.260064   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...          0.700643  0.612980   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c         ...          0.526914  0.245872   \n",
       "...                                          ...               ...       ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.390761  0.286877   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.389953  0.075689   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.392547  0.248879   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.367362  0.075561   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.304961  0.084338   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.220977  0.302821   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.160941  0.131571   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.044463  0.171553   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.001189  0.072429   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.080848  0.088312   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.113425  0.072110   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.174560  0.237978   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.277282  0.086551   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.142211  0.882256   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...         -0.995751  0.383466   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...         -0.918069  0.584309   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.140143  0.289127   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.235526  0.088317   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.364928  0.158951   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.520362  0.123037   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.532638  0.131984   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.534621  0.088217   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.520987  0.090344   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.511786  0.166433   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.467521  0.071888   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.434356  0.068317   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.350760  0.090294   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...         -0.191880  0.343909   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...         -0.020616  0.163606   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d         ...          0.288756  0.106597   \n",
       "\n",
       "                                        cross_xz    cross_yz  spect_cent_x  \\\n",
       "healthCode                                                                   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -1.108732    1.423415      0.303866   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -1.424095    1.614554      0.055270   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.773675    0.980318      0.896903   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.622452    0.878936      0.177303   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.669505    0.852864      0.319803   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.699567    0.812884      0.374420   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.701589    0.791987      0.341018   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.787594    0.849309      0.539139   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.835363    0.799470      0.356895   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.761506    0.694724      0.687310   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.870989    0.742121      0.374878   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -1.025497    0.918047      0.573125   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.969083    0.948017      0.878901   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.941214    0.904174      0.712077   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.942334    0.934811      0.825119   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.922208    0.945103      0.749242   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.928949    0.929922      0.398179   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.954774    0.934146      0.493444   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.941513    0.907701      0.446762   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.915533    0.855344      0.597968   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.967785    0.917991      0.274690   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.976667    0.980291      0.393992   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.924094    0.919815      0.875586   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -1.131406    1.076670      0.583398   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -3.188658    1.761300      0.877253   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -6.358237    0.034385      1.398453   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -3.980283   -1.808539      2.427015   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -2.225903   -2.248741      1.381585   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c   -0.723455   -1.983402      0.348549   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c    0.257513   -1.654890      0.198529   \n",
       "...                                          ...         ...           ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.339828   -2.060733      0.108185   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.017404   -1.749560      0.285561   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.268926   -2.320806      0.252182   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.659481   -3.468569      0.297095   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -4.416305  -29.629503      0.223166   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.117769    3.151337      0.092346   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.181271    1.740769      0.080994   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -1.249398    1.631330      0.071188   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  139.884578 -273.532282      0.108464   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d  -12.723873 -108.346334      0.044698   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -3.678264  -21.264081      0.082740   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    2.234494   10.738798      0.114589   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    1.391487    5.136993      0.221140   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.713297    0.456749      1.174703   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    1.077998    1.355506      1.566478   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.774024    1.132832      0.914419   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.140202    0.039789      0.541762   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -1.002111   -1.212861      0.035937   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.549252   -3.162031      0.106726   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.383964   -5.731964      0.220850   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.175934   -5.474108      0.472589   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.419126   -4.393870      0.527972   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.325023   -3.002924      0.500751   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.478449   -2.851425      0.167300   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -1.027066   -3.261252      0.094648   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.557043   -2.302763      0.175848   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.288250   -1.013090      0.513440   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.666364    0.785358      0.382773   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d    0.699107    0.581294      0.926911   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d   -0.779132   -1.442906      0.643658   \n",
       "\n",
       "                                      spect_cent_y  spect_cent_z  \\\n",
       "healthCode                                                         \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.484718      0.891400   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.206965      0.505872   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.608516      0.523008   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.664331      1.269846   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.922528      1.160783   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.966315      1.395159   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.678090      1.303551   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.792449      0.934569   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.415980      1.094721   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.729889      0.550284   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.304298      0.444606   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.193399      0.262078   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.192182      0.622840   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.538247      1.142288   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.678696      0.906691   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.915445      1.258717   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.755275      1.117008   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.931416      0.519440   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.695264      0.405988   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.415603      0.624520   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.081796      0.347779   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.102864      0.831110   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.621358      1.191681   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.786356      1.240218   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.789743      0.669656   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      1.141195      0.276229   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.693736      0.076705   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.481171      0.062616   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.496770      0.170647   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c      0.454449      0.040465   \n",
       "...                                            ...           ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.591215      0.036640   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.262477      0.033367   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.439522      0.092253   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.200665      0.017361   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.113958      0.019837   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.163031      0.074937   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.167767      0.020826   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.077944      0.020183   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.055813      0.030208   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.013184      0.002369   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.058674      0.025675   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.046153      0.068277   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.064596      0.041588   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      1.360654      0.701078   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      1.597249      0.434970   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      1.417420      0.700633   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.814258      0.195182   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.187069      0.012596   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.398723      0.020272   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.242931      0.013952   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.631294      0.059678   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.231336      0.015047   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.140482      0.023202   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.199524      0.041826   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.300684      0.022210   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.314835      0.032902   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      1.006450      0.003416   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.100276      0.231170   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      1.080601      0.117749   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d      0.127020      0.128023   \n",
       "\n",
       "                                      average_dist_meanx  average_dist_meany  \\\n",
       "healthCode                                                                     \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.240233            0.241233   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.215864            0.247436   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.192852            0.216332   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.169978            0.200500   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.156258            0.195590   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.147237            0.194389   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.139344            0.190995   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.135015            0.185874   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.131864            0.181516   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.129255            0.177092   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.129458            0.175094   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.128364            0.174815   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.126270            0.173775   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.125267            0.172130   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.124248            0.171290   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.123298            0.170575   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.122566            0.170022   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.120759            0.169525   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.119078            0.168535   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.118110            0.167335   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.117879            0.166682   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.118133            0.166568   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.117878            0.166404   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.119135            0.166836   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.130391            0.174915   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.140732            0.186457   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.147303            0.189583   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.154285            0.193580   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.156555            0.195372   \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.161543            0.197066   \n",
       "...                                                  ...                 ...   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283205            0.207867   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283366            0.207964   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283636            0.208019   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283847            0.208008   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283988            0.207988   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.284105            0.207942   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.284131            0.207921   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283994            0.207949   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283855            0.207907   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283832            0.207777   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283891            0.207667   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.283968            0.207623   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.284096            0.207568   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.284697            0.208582   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.284928            0.209312   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.285448            0.210122   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.285778            0.210579   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.285859            0.210689   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.285814            0.210847   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.285831            0.210763   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.286101            0.210636   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.286480            0.210557   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.286942            0.210523   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.287370            0.210571   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.287790            0.210652   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.288108            0.210628   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.288429            0.210976   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.289133            0.212087   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.289590            0.213048   \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.289851            0.213211   \n",
       "\n",
       "                                      average_dist_meanz  \n",
       "healthCode                                                \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.312021  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.306005  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.278009  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.262656  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.256213  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.253153  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.248046  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.242997  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.239425  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.233075  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.225587  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.222414  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.221624  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.219561  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.217375  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.216757  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.217175  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.218042  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.219156  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.220526  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.220755  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.219411  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.220085  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.223415  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.228530  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.231050  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.231789  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.230438  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.231140  \n",
       "90839249-5057-4ccc-b0ce-a73dad2be07c            0.231756  \n",
       "...                                                  ...  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134309  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134221  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134122  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134009  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133984  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133973  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133917  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133869  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133806  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133723  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133650  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133653  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.133740  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134190  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134474  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134747  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134944  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134856  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134881  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134990  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135071  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135106  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135128  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135136  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135053  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.134981  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135117  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135395  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135599  \n",
       "eacffd55-4883-41de-ade0-828d3ed3873d            0.135550  \n",
       "\n",
       "[60896 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything_no_demog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BMI = []\n",
    "for q in list(set(everything_no_demog.index.values)):\n",
    "    temp = []\n",
    "    temp.append(((everything.loc[q].weight.values) / (((everything.loc[q].height.values)**2))) * 703)\n",
    "    BMI.append(temp)\n",
    "    \n",
    "BMI = np.array(BMI)\n",
    "BMI = BMI.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code inserts BMI directly\n",
    "#everything_no_demog.insert(25, 'BMI', BMI)\n",
    "\n",
    "# This code inserts sex into the no demog df so that it can be used for training/testing\n",
    "everything_no_demog.insert(25, 'sex', everything.sex.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  22.9s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  23.2s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  23.4s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  23.2s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  24.5s\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  3.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.1min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.2min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.2min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 1.9min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 1.9min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 1.9min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 1.9min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 1.9min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.1min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  18.2s\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  18.5s\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.1min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.1min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.1min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.1min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  18.5s\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  18.2s\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  18.0s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.8min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.8min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.8min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.9min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.9min\n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 6.2min\n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 6.0min\n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=10.0min\n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 4.7min\n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 4.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  50 | elapsed: 13.9min remaining:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 4.7min\n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total= 8.9min\n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total= 8.9min\n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total= 8.8min\n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total= 8.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 14.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [10, 31, 52, 73, 94, 115, 136, 157, 178, 200], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower the number of trees to reduce overfitting\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "numOfTotalHC = 173\n",
    "numOfTrainHC = 103\n",
    "numOfTestHC = 70\n",
    "\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "# One-hot encode ouput\n",
    "training = everything_no_demog.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = everything_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(newtotal_df)):]\n",
    "\n",
    "#uniques, labelings = pd.factorize(training.sex.values)\n",
    "#training.drop(['sex'], axis=1, inplace=True)\n",
    "#training.insert(25, 'sex_encoded', uniques)\n",
    "\n",
    "X = np.array(training.iloc[:, 0:25])\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y = np.array(training.iloc[:, 25])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_mixed = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixed = np.concatenate((y_train, y_test), axis=0)\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfopts = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rfopts, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 80,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 94}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "numOfTotalHC = 173\n",
    "numOfTrainHC = 103\n",
    "numOfTestHC = 70\n",
    "\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "# One-hot encode ouput\n",
    "training = everything_no_demog.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = everything_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(newtotal_df)):]\n",
    "\n",
    "#uniques, labelings = pd.factorize(training.sex.values)\n",
    "#training.drop(['sex'], axis=1, inplace=True)\n",
    "#training.insert(25, 'sex_encoded', uniques)\n",
    "\n",
    "X = np.array(training.iloc[:, 0:25])\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y = np.array(training.iloc[:, 25])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "newrf = RandomForestClassifier(n_estimators=200, max_depth=50, min_samples_split=2, min_samples_leaf=2, bootstrap=False)\n",
    "scores_old = cross_val_score(newrf, X_scaled, y, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (24640, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-42b493d576fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#cohen_kappa_score(testing.iloc[:, 25], newrf.predict(testing.iloc[:, 0:25]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#confusion_matrix(testing.iloc[:, 25], newrf.predict(testing.iloc[:, 0:25]), sample_weight=sample_weight)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m     return _average_binary_score(_binary_uninterpolated_average_precision,\n\u001b[1;32m    198\u001b[0m                                  \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_uninterpolated_average_precision\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    189\u001b[0m             y_true, y_score, sample_weight=None):\n\u001b[1;32m    190\u001b[0m         precision, recall, thresholds = precision_recall_curve(\n\u001b[0;32m--> 191\u001b[0;31m             y_true, y_score, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Return the step function integral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# The following works because the last entry of precision is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[1;32m    440\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                                              sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (24640, 2)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "sample_weight = np.array([4 if i == 'Female' else 1 for i in list(testing.iloc[:, 25])])\n",
    "newrf.score(testing.iloc[:, 0:25], testing.iloc[:, 25], sample_weight=sample_weight)\n",
    "#cohen_kappa_score(testing.iloc[:, 25], newrf.predict(testing.iloc[:, 0:25]))\n",
    "#confusion_matrix(testing.iloc[:, 25], newrf.predict(testing.iloc[:, 0:25]), sample_weight=sample_weight) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling the males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numOfTotalHC = 173\n",
    "numOfTrainHC = 103\n",
    "numOfTestHC = 70\n",
    "\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "# One-hot encode ouput\n",
    "training = everything_no_demog.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = everything_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(newtotal_df)):]\n",
    "\n",
    "Xmale = np.array(choppedmale_train.iloc[:, 0:25])\n",
    "Xfemale = np.array(female_train.iloc[:, 0:25])\n",
    "X_scaledmale = preprocessing.scale(Xmale)\n",
    "X_scaledfemale = preprocessing.scale(Xfemale)\n",
    "\n",
    "X_scaledtotal = np.array(list(X_scaledmale)+list(X_scaledfemale))\n",
    "y_total = np.array(list(choppedmale_train.iloc[:, 25]) + list(female_train.iloc[:, 25]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaledtotal, y_total, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "X_mixedequal = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixedequal = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "\n",
    "# Taking from the training \n",
    "female_train = training.loc[training['sex'] == 'Female']\n",
    "male_train = training.loc[training['sex'] == 'Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframe with the downsampled males\n",
    "choppedmale_train = male_train.iloc[0:9000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_zero, label = pd.factorize(y_mixedequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9152"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(male_zero).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11152"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(choppedmale_train))\n",
    "len(female_train)\n",
    "len(male_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18152"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_mixedequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [18152, 11152]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-800fc21cb919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mrf_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'average_precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Fit the random search model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_mixedequal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmale_zero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# Regenerate parameter iterable for each fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [18152, 11152]"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "numOfTotalHC = 173\n",
    "numOfTrainHC = 103\n",
    "numOfTestHC = 70\n",
    "\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "# One-hot encode ouput\n",
    "training = everything_no_demog.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = everything_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(newtotal_df)):]\n",
    "\n",
    "#uniques, labelings = pd.factorize(training.sex.values)\n",
    "#training.drop(['sex'], axis=1, inplace=True)\n",
    "#training.insert(25, 'sex_encoded', uniques)\n",
    "\n",
    "Xmale = np.array(choppedmale_train.iloc[:, 0:25])\n",
    "Xfemale = np.array(female_train.iloc[:, 0:25])\n",
    "X_scaledmale = preprocessing.scale(Xmale)\n",
    "X_scaledfemale = preprocessing.scale(Xfemale)\n",
    "\n",
    "X_scaledtotal = np.array(list(X_scaledmale)+list(X_scaledfemale))\n",
    "y_total = np.array(list(choppedmale_train.iloc[:, 25]) + list(female_train.iloc[:, 25]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaledtotal, y_total, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "X_mixedequal = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixedequal = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "dsrf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = dsrf, param_distributions = random_grid, n_iter = 20, scoring='average_precision', cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_mixedequal, male_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 50,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsrf = RandomForestClassifier(n_estimators=200, max_depth=50, min_samples_split=2, min_samples_leaf=2, bootstrap=False, random_state=42)\n",
    "dsrf.fit(X_mixedequal, male_zero)\n",
    "scores = cross_val_score(dsrf, X_mixedequal, male_zero, cv=5, scoring='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99992559, 0.99997768, 0.99994408, 0.9998837 , 0.99998214])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9152"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(female_train.iloc[:, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_one = [1 for x in range(0, 5632)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7959872159090909"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrf.score(female.iloc[:, 0:25], female_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(male.iloc[:, 25])\n",
    "male_zero_test = [0 for y in range(0, 19008)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19681186868686867"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrf.score(male.iloc[:, 0:25], male_zero_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24640"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totallabel = [1 if x=='Female' else 0 for x in testing.iloc[:, 25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5632"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(totallabel).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33376623376623377"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrf.score(testing.iloc[:, 0:25], totallabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.009267840593141896"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "#sample_weight = np.array([4 if i == 'Female' else 1 for i in list(testing.iloc[:, 25])])\n",
    "#newrf.score(testing.iloc[:, 0:25], testing.iloc[:, 25], sample_weight=sample_weight)\n",
    "cohen_kappa_score(testing.iloc[:, 25], dsrf.predict(testing.iloc[:, 0:25]))\n",
    "#confusion_matrix(testing.iloc[:, 25], dsrf.predict(testing.iloc[:, 0:25])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numOfTotalHC = 173\n",
    "numOfTrainHC = 103\n",
    "numOfTestHC = 70\n",
    "testing = everything_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(newtotal_df)):]\n",
    "\n",
    "female = testing.loc[testing['sex'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fundamental_freq</th>\n",
       "      <th>average_accel</th>\n",
       "      <th>peakcount</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mut_x</th>\n",
       "      <th>mut_y</th>\n",
       "      <th>mut_z</th>\n",
       "      <th>muf_x</th>\n",
       "      <th>muf_y</th>\n",
       "      <th>...</th>\n",
       "      <th>medf_z</th>\n",
       "      <th>cross_xz</th>\n",
       "      <th>cross_yz</th>\n",
       "      <th>spect_cent_x</th>\n",
       "      <th>spect_cent_y</th>\n",
       "      <th>spect_cent_z</th>\n",
       "      <th>average_dist_meanx</th>\n",
       "      <th>average_dist_meany</th>\n",
       "      <th>average_dist_meanz</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1a254ea6-2875-4394-9b92-515f89aac1c0</th>\n",
       "      <td>123.003682</td>\n",
       "      <td>1.761073</td>\n",
       "      <td>10</td>\n",
       "      <td>2.644966</td>\n",
       "      <td>0.265567</td>\n",
       "      <td>-0.220573</td>\n",
       "      <td>-1.519599</td>\n",
       "      <td>-0.739240</td>\n",
       "      <td>1.983707</td>\n",
       "      <td>3.083983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282210</td>\n",
       "      <td>0.298378</td>\n",
       "      <td>2.055623</td>\n",
       "      <td>0.229315</td>\n",
       "      <td>1.465557</td>\n",
       "      <td>0.832902</td>\n",
       "      <td>0.230915</td>\n",
       "      <td>0.189005</td>\n",
       "      <td>0.264621</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1a254ea6-2875-4394-9b92-515f89aac1c0</th>\n",
       "      <td>120.408201</td>\n",
       "      <td>1.742037</td>\n",
       "      <td>13</td>\n",
       "      <td>2.644966</td>\n",
       "      <td>0.143988</td>\n",
       "      <td>-0.270648</td>\n",
       "      <td>-1.482989</td>\n",
       "      <td>-0.726592</td>\n",
       "      <td>1.983050</td>\n",
       "      <td>2.995173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284106</td>\n",
       "      <td>0.372490</td>\n",
       "      <td>2.041019</td>\n",
       "      <td>0.087680</td>\n",
       "      <td>1.637327</td>\n",
       "      <td>0.897205</td>\n",
       "      <td>0.230161</td>\n",
       "      <td>0.202340</td>\n",
       "      <td>0.301559</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1a254ea6-2875-4394-9b92-515f89aac1c0</th>\n",
       "      <td>112.320329</td>\n",
       "      <td>1.638993</td>\n",
       "      <td>12</td>\n",
       "      <td>2.506517</td>\n",
       "      <td>0.143988</td>\n",
       "      <td>-0.210871</td>\n",
       "      <td>-1.288581</td>\n",
       "      <td>-0.883986</td>\n",
       "      <td>1.580715</td>\n",
       "      <td>3.059265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478444</td>\n",
       "      <td>0.238546</td>\n",
       "      <td>1.457694</td>\n",
       "      <td>0.282907</td>\n",
       "      <td>2.576500</td>\n",
       "      <td>0.348468</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>0.184547</td>\n",
       "      <td>0.315410</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1a254ea6-2875-4394-9b92-515f89aac1c0</th>\n",
       "      <td>111.140727</td>\n",
       "      <td>1.565864</td>\n",
       "      <td>20</td>\n",
       "      <td>3.112473</td>\n",
       "      <td>-0.430623</td>\n",
       "      <td>-0.600329</td>\n",
       "      <td>-0.939812</td>\n",
       "      <td>-0.573548</td>\n",
       "      <td>3.857549</td>\n",
       "      <td>4.052695</td>\n",
       "      <td>...</td>\n",
       "      <td>2.647426</td>\n",
       "      <td>1.046692</td>\n",
       "      <td>1.638592</td>\n",
       "      <td>0.613110</td>\n",
       "      <td>1.370520</td>\n",
       "      <td>1.541681</td>\n",
       "      <td>0.274628</td>\n",
       "      <td>0.239210</td>\n",
       "      <td>0.362077</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1a254ea6-2875-4394-9b92-515f89aac1c0</th>\n",
       "      <td>104.537138</td>\n",
       "      <td>1.232072</td>\n",
       "      <td>19</td>\n",
       "      <td>3.112473</td>\n",
       "      <td>-1.048801</td>\n",
       "      <td>-0.729662</td>\n",
       "      <td>-0.353179</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>4.181419</td>\n",
       "      <td>4.843472</td>\n",
       "      <td>...</td>\n",
       "      <td>3.211494</td>\n",
       "      <td>2245.883523</td>\n",
       "      <td>1087.078214</td>\n",
       "      <td>0.209053</td>\n",
       "      <td>0.661385</td>\n",
       "      <td>1.787723</td>\n",
       "      <td>0.312203</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>0.382888</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fundamental_freq  average_accel  \\\n",
       "healthCode                                                              \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0        123.003682       1.761073   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0        120.408201       1.742037   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0        112.320329       1.638993   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0        111.140727       1.565864   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0        104.537138       1.232072   \n",
       "\n",
       "                                      peakcount       max       min     mut_x  \\\n",
       "healthCode                                                                      \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0         10  2.644966  0.265567 -0.220573   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0         13  2.644966  0.143988 -0.270648   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0         12  2.506517  0.143988 -0.210871   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0         20  3.112473 -0.430623 -0.600329   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0         19  3.112473 -1.048801 -0.729662   \n",
       "\n",
       "                                         mut_y     mut_z     muf_x     muf_y  \\\n",
       "healthCode                                                                     \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0 -1.519599 -0.739240  1.983707  3.083983   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0 -1.482989 -0.726592  1.983050  2.995173   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0 -1.288581 -0.883986  1.580715  3.059265   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0 -0.939812 -0.573548  3.857549  4.052695   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0 -0.353179 -0.000325  4.181419  4.843472   \n",
       "\n",
       "                                       ...      medf_z     cross_xz  \\\n",
       "healthCode                             ...                            \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0   ...    0.282210     0.298378   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0   ...    0.284106     0.372490   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0   ...    0.478444     0.238546   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0   ...    2.647426     1.046692   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0   ...    3.211494  2245.883523   \n",
       "\n",
       "                                         cross_yz  spect_cent_x  spect_cent_y  \\\n",
       "healthCode                                                                      \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0     2.055623      0.229315      1.465557   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0     2.041019      0.087680      1.637327   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0     1.457694      0.282907      2.576500   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0     1.638592      0.613110      1.370520   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  1087.078214      0.209053      0.661385   \n",
       "\n",
       "                                      spect_cent_z  average_dist_meanx  \\\n",
       "healthCode                                                               \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0      0.832902            0.230915   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0      0.897205            0.230161   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0      0.348468            0.214125   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0      1.541681            0.274628   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0      1.787723            0.312203   \n",
       "\n",
       "                                      average_dist_meany  average_dist_meanz  \\\n",
       "healthCode                                                                     \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0            0.189005            0.264621   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0            0.202340            0.301559   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0            0.184547            0.315410   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0            0.239210            0.362077   \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0            0.297326            0.382888   \n",
       "\n",
       "                                         sex  \n",
       "healthCode                                    \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  Female  \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  Female  \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  Female  \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  Female  \n",
       "1a254ea6-2875-4394-9b92-515f89aac1c0  Female  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fundamental_freq</th>\n",
       "      <th>average_accel</th>\n",
       "      <th>peakcount</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mut_x</th>\n",
       "      <th>mut_y</th>\n",
       "      <th>mut_z</th>\n",
       "      <th>muf_x</th>\n",
       "      <th>muf_y</th>\n",
       "      <th>...</th>\n",
       "      <th>medf_z</th>\n",
       "      <th>cross_xz</th>\n",
       "      <th>cross_yz</th>\n",
       "      <th>spect_cent_x</th>\n",
       "      <th>spect_cent_y</th>\n",
       "      <th>spect_cent_z</th>\n",
       "      <th>average_dist_meanx</th>\n",
       "      <th>average_dist_meany</th>\n",
       "      <th>average_dist_meanz</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>84.093790</td>\n",
       "      <td>1.183311</td>\n",
       "      <td>17</td>\n",
       "      <td>1.735415</td>\n",
       "      <td>-0.093085</td>\n",
       "      <td>0.544209</td>\n",
       "      <td>-0.835330</td>\n",
       "      <td>-0.556319</td>\n",
       "      <td>1.711133</td>\n",
       "      <td>1.428328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345499</td>\n",
       "      <td>-0.978232</td>\n",
       "      <td>1.501529</td>\n",
       "      <td>0.401588</td>\n",
       "      <td>0.635471</td>\n",
       "      <td>0.261587</td>\n",
       "      <td>0.189971</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>0.219167</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>92.089151</td>\n",
       "      <td>1.342022</td>\n",
       "      <td>22</td>\n",
       "      <td>1.903300</td>\n",
       "      <td>-0.093085</td>\n",
       "      <td>0.839665</td>\n",
       "      <td>-0.898862</td>\n",
       "      <td>-0.440043</td>\n",
       "      <td>2.086170</td>\n",
       "      <td>1.598540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399225</td>\n",
       "      <td>-1.908143</td>\n",
       "      <td>2.042669</td>\n",
       "      <td>0.079886</td>\n",
       "      <td>0.668962</td>\n",
       "      <td>0.220937</td>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.070069</td>\n",
       "      <td>0.225696</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>104.641810</td>\n",
       "      <td>1.389768</td>\n",
       "      <td>21</td>\n",
       "      <td>2.007266</td>\n",
       "      <td>-0.088764</td>\n",
       "      <td>0.942869</td>\n",
       "      <td>-0.922103</td>\n",
       "      <td>-0.364584</td>\n",
       "      <td>2.173094</td>\n",
       "      <td>1.834422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400768</td>\n",
       "      <td>-2.586148</td>\n",
       "      <td>2.529189</td>\n",
       "      <td>1.086869</td>\n",
       "      <td>1.027991</td>\n",
       "      <td>0.568184</td>\n",
       "      <td>0.182744</td>\n",
       "      <td>0.078027</td>\n",
       "      <td>0.211303</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>79.819556</td>\n",
       "      <td>1.157167</td>\n",
       "      <td>19</td>\n",
       "      <td>2.007266</td>\n",
       "      <td>-0.781718</td>\n",
       "      <td>0.769605</td>\n",
       "      <td>-0.632780</td>\n",
       "      <td>-0.461603</td>\n",
       "      <td>2.016581</td>\n",
       "      <td>2.401082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201667</td>\n",
       "      <td>-1.667245</td>\n",
       "      <td>1.370832</td>\n",
       "      <td>0.607490</td>\n",
       "      <td>1.018372</td>\n",
       "      <td>0.019616</td>\n",
       "      <td>0.183512</td>\n",
       "      <td>0.128274</td>\n",
       "      <td>0.214012</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>72.891574</td>\n",
       "      <td>0.944486</td>\n",
       "      <td>17</td>\n",
       "      <td>1.329425</td>\n",
       "      <td>-0.781718</td>\n",
       "      <td>0.599926</td>\n",
       "      <td>-0.339092</td>\n",
       "      <td>-0.584421</td>\n",
       "      <td>1.330641</td>\n",
       "      <td>1.309831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291241</td>\n",
       "      <td>-1.026531</td>\n",
       "      <td>0.580219</td>\n",
       "      <td>0.715500</td>\n",
       "      <td>0.188665</td>\n",
       "      <td>0.331627</td>\n",
       "      <td>0.165407</td>\n",
       "      <td>0.136041</td>\n",
       "      <td>0.215774</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>66.836892</td>\n",
       "      <td>0.906129</td>\n",
       "      <td>14</td>\n",
       "      <td>1.276772</td>\n",
       "      <td>-0.666723</td>\n",
       "      <td>0.567256</td>\n",
       "      <td>-0.304049</td>\n",
       "      <td>-0.560532</td>\n",
       "      <td>1.236783</td>\n",
       "      <td>1.375709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192802</td>\n",
       "      <td>-1.011996</td>\n",
       "      <td>0.542428</td>\n",
       "      <td>0.214774</td>\n",
       "      <td>0.047958</td>\n",
       "      <td>0.079783</td>\n",
       "      <td>0.154599</td>\n",
       "      <td>0.144718</td>\n",
       "      <td>0.214896</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>60.719927</td>\n",
       "      <td>0.850874</td>\n",
       "      <td>13</td>\n",
       "      <td>1.276772</td>\n",
       "      <td>-0.666723</td>\n",
       "      <td>0.552406</td>\n",
       "      <td>-0.296679</td>\n",
       "      <td>-0.490727</td>\n",
       "      <td>1.277836</td>\n",
       "      <td>1.575615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546107</td>\n",
       "      <td>-1.125689</td>\n",
       "      <td>0.604570</td>\n",
       "      <td>0.264018</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.212707</td>\n",
       "      <td>0.145825</td>\n",
       "      <td>0.149558</td>\n",
       "      <td>0.212353</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>61.370547</td>\n",
       "      <td>0.831472</td>\n",
       "      <td>13</td>\n",
       "      <td>1.254676</td>\n",
       "      <td>-0.550120</td>\n",
       "      <td>0.580600</td>\n",
       "      <td>-0.250549</td>\n",
       "      <td>-0.453239</td>\n",
       "      <td>1.327007</td>\n",
       "      <td>1.598099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084389</td>\n",
       "      <td>-1.281004</td>\n",
       "      <td>0.552797</td>\n",
       "      <td>0.473761</td>\n",
       "      <td>0.030326</td>\n",
       "      <td>0.220903</td>\n",
       "      <td>0.140423</td>\n",
       "      <td>0.153129</td>\n",
       "      <td>0.207136</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>66.212932</td>\n",
       "      <td>0.831623</td>\n",
       "      <td>9</td>\n",
       "      <td>1.254676</td>\n",
       "      <td>-0.526269</td>\n",
       "      <td>0.601940</td>\n",
       "      <td>-0.178678</td>\n",
       "      <td>-0.460331</td>\n",
       "      <td>1.289884</td>\n",
       "      <td>1.665117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340095</td>\n",
       "      <td>-1.307624</td>\n",
       "      <td>0.388151</td>\n",
       "      <td>0.556822</td>\n",
       "      <td>0.106259</td>\n",
       "      <td>0.624609</td>\n",
       "      <td>0.135938</td>\n",
       "      <td>0.155627</td>\n",
       "      <td>0.203303</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>60.579467</td>\n",
       "      <td>0.815940</td>\n",
       "      <td>11</td>\n",
       "      <td>1.154157</td>\n",
       "      <td>-0.667954</td>\n",
       "      <td>0.588794</td>\n",
       "      <td>-0.176729</td>\n",
       "      <td>-0.457068</td>\n",
       "      <td>1.148517</td>\n",
       "      <td>1.491882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150211</td>\n",
       "      <td>-1.288199</td>\n",
       "      <td>0.386658</td>\n",
       "      <td>0.185172</td>\n",
       "      <td>0.123464</td>\n",
       "      <td>0.379450</td>\n",
       "      <td>0.129763</td>\n",
       "      <td>0.156769</td>\n",
       "      <td>0.201240</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>59.077575</td>\n",
       "      <td>0.817936</td>\n",
       "      <td>15</td>\n",
       "      <td>1.128464</td>\n",
       "      <td>-0.667954</td>\n",
       "      <td>0.583666</td>\n",
       "      <td>-0.220211</td>\n",
       "      <td>-0.465978</td>\n",
       "      <td>1.111319</td>\n",
       "      <td>1.302529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254868</td>\n",
       "      <td>-1.252562</td>\n",
       "      <td>0.472578</td>\n",
       "      <td>0.467362</td>\n",
       "      <td>0.184988</td>\n",
       "      <td>0.248037</td>\n",
       "      <td>0.123476</td>\n",
       "      <td>0.155946</td>\n",
       "      <td>0.198892</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>60.646997</td>\n",
       "      <td>0.820878</td>\n",
       "      <td>18</td>\n",
       "      <td>1.090094</td>\n",
       "      <td>-0.776631</td>\n",
       "      <td>0.567537</td>\n",
       "      <td>-0.219909</td>\n",
       "      <td>-0.496696</td>\n",
       "      <td>0.940857</td>\n",
       "      <td>1.216790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180884</td>\n",
       "      <td>-1.142624</td>\n",
       "      <td>0.442744</td>\n",
       "      <td>0.285164</td>\n",
       "      <td>0.018012</td>\n",
       "      <td>0.440142</td>\n",
       "      <td>0.117182</td>\n",
       "      <td>0.155380</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>54.489166</td>\n",
       "      <td>0.782678</td>\n",
       "      <td>12</td>\n",
       "      <td>1.090094</td>\n",
       "      <td>-0.776631</td>\n",
       "      <td>0.514440</td>\n",
       "      <td>-0.207049</td>\n",
       "      <td>-0.481604</td>\n",
       "      <td>0.916877</td>\n",
       "      <td>1.300558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525174</td>\n",
       "      <td>-1.068182</td>\n",
       "      <td>0.429917</td>\n",
       "      <td>0.238048</td>\n",
       "      <td>0.094047</td>\n",
       "      <td>0.231297</td>\n",
       "      <td>0.112997</td>\n",
       "      <td>0.156545</td>\n",
       "      <td>0.195434</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>52.910412</td>\n",
       "      <td>0.729400</td>\n",
       "      <td>8</td>\n",
       "      <td>1.028011</td>\n",
       "      <td>-0.703446</td>\n",
       "      <td>0.483433</td>\n",
       "      <td>-0.197842</td>\n",
       "      <td>-0.438156</td>\n",
       "      <td>0.964371</td>\n",
       "      <td>1.275265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063238</td>\n",
       "      <td>-1.103335</td>\n",
       "      <td>0.451534</td>\n",
       "      <td>0.302710</td>\n",
       "      <td>0.072282</td>\n",
       "      <td>0.178837</td>\n",
       "      <td>0.109271</td>\n",
       "      <td>0.156524</td>\n",
       "      <td>0.193544</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>57.266872</td>\n",
       "      <td>0.728959</td>\n",
       "      <td>8</td>\n",
       "      <td>1.081256</td>\n",
       "      <td>-0.823816</td>\n",
       "      <td>0.488750</td>\n",
       "      <td>-0.157379</td>\n",
       "      <td>-0.452355</td>\n",
       "      <td>0.925394</td>\n",
       "      <td>1.333243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264525</td>\n",
       "      <td>-1.080458</td>\n",
       "      <td>0.347910</td>\n",
       "      <td>0.304506</td>\n",
       "      <td>0.086258</td>\n",
       "      <td>0.551066</td>\n",
       "      <td>0.105975</td>\n",
       "      <td>0.155633</td>\n",
       "      <td>0.191828</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>50.170137</td>\n",
       "      <td>0.727835</td>\n",
       "      <td>8</td>\n",
       "      <td>1.081256</td>\n",
       "      <td>-0.839114</td>\n",
       "      <td>0.467077</td>\n",
       "      <td>-0.154210</td>\n",
       "      <td>-0.459784</td>\n",
       "      <td>0.908797</td>\n",
       "      <td>1.585312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093361</td>\n",
       "      <td>-1.015863</td>\n",
       "      <td>0.335398</td>\n",
       "      <td>0.151139</td>\n",
       "      <td>0.141883</td>\n",
       "      <td>0.227174</td>\n",
       "      <td>0.103199</td>\n",
       "      <td>0.155599</td>\n",
       "      <td>0.191978</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>52.340432</td>\n",
       "      <td>0.732129</td>\n",
       "      <td>12</td>\n",
       "      <td>1.093421</td>\n",
       "      <td>-0.839114</td>\n",
       "      <td>0.449070</td>\n",
       "      <td>-0.183110</td>\n",
       "      <td>-0.469360</td>\n",
       "      <td>0.922036</td>\n",
       "      <td>1.193293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318459</td>\n",
       "      <td>-0.956771</td>\n",
       "      <td>0.390128</td>\n",
       "      <td>0.239547</td>\n",
       "      <td>0.074789</td>\n",
       "      <td>0.281503</td>\n",
       "      <td>0.101150</td>\n",
       "      <td>0.156027</td>\n",
       "      <td>0.191443</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>56.027040</td>\n",
       "      <td>0.753457</td>\n",
       "      <td>15</td>\n",
       "      <td>1.093421</td>\n",
       "      <td>-0.792955</td>\n",
       "      <td>0.443907</td>\n",
       "      <td>-0.184973</td>\n",
       "      <td>-0.508436</td>\n",
       "      <td>0.917616</td>\n",
       "      <td>1.457874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136323</td>\n",
       "      <td>-0.873083</td>\n",
       "      <td>0.363809</td>\n",
       "      <td>0.212675</td>\n",
       "      <td>0.130208</td>\n",
       "      <td>0.357410</td>\n",
       "      <td>0.099332</td>\n",
       "      <td>0.157155</td>\n",
       "      <td>0.189383</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>49.949909</td>\n",
       "      <td>0.724066</td>\n",
       "      <td>12</td>\n",
       "      <td>1.043737</td>\n",
       "      <td>-0.841776</td>\n",
       "      <td>0.426953</td>\n",
       "      <td>-0.188452</td>\n",
       "      <td>-0.476689</td>\n",
       "      <td>0.811547</td>\n",
       "      <td>1.381015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602169</td>\n",
       "      <td>-0.895665</td>\n",
       "      <td>0.395335</td>\n",
       "      <td>0.221417</td>\n",
       "      <td>0.097678</td>\n",
       "      <td>0.257579</td>\n",
       "      <td>0.097011</td>\n",
       "      <td>0.158279</td>\n",
       "      <td>0.188860</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>51.389303</td>\n",
       "      <td>0.682249</td>\n",
       "      <td>9</td>\n",
       "      <td>1.043737</td>\n",
       "      <td>-0.841776</td>\n",
       "      <td>0.436159</td>\n",
       "      <td>-0.178748</td>\n",
       "      <td>-0.413089</td>\n",
       "      <td>0.818255</td>\n",
       "      <td>1.254024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071291</td>\n",
       "      <td>-1.055849</td>\n",
       "      <td>0.432710</td>\n",
       "      <td>0.207117</td>\n",
       "      <td>0.048559</td>\n",
       "      <td>0.149732</td>\n",
       "      <td>0.094774</td>\n",
       "      <td>0.158338</td>\n",
       "      <td>0.188561</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>52.732006</td>\n",
       "      <td>0.693535</td>\n",
       "      <td>10</td>\n",
       "      <td>0.977790</td>\n",
       "      <td>-0.806267</td>\n",
       "      <td>0.470510</td>\n",
       "      <td>-0.110734</td>\n",
       "      <td>-0.412024</td>\n",
       "      <td>0.926819</td>\n",
       "      <td>1.352405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325562</td>\n",
       "      <td>-1.141947</td>\n",
       "      <td>0.268755</td>\n",
       "      <td>0.216126</td>\n",
       "      <td>0.085050</td>\n",
       "      <td>0.557988</td>\n",
       "      <td>0.093004</td>\n",
       "      <td>0.158651</td>\n",
       "      <td>0.188337</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>47.317359</td>\n",
       "      <td>0.690296</td>\n",
       "      <td>13</td>\n",
       "      <td>0.965234</td>\n",
       "      <td>-0.817927</td>\n",
       "      <td>0.473044</td>\n",
       "      <td>-0.083274</td>\n",
       "      <td>-0.405087</td>\n",
       "      <td>1.023133</td>\n",
       "      <td>1.492721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079998</td>\n",
       "      <td>-1.167761</td>\n",
       "      <td>0.205571</td>\n",
       "      <td>0.114224</td>\n",
       "      <td>0.079382</td>\n",
       "      <td>0.181422</td>\n",
       "      <td>0.091857</td>\n",
       "      <td>0.159138</td>\n",
       "      <td>0.188416</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>47.524138</td>\n",
       "      <td>0.677049</td>\n",
       "      <td>14</td>\n",
       "      <td>0.984435</td>\n",
       "      <td>-0.817927</td>\n",
       "      <td>0.443769</td>\n",
       "      <td>-0.127068</td>\n",
       "      <td>-0.410505</td>\n",
       "      <td>0.975527</td>\n",
       "      <td>1.161857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232476</td>\n",
       "      <td>-1.081033</td>\n",
       "      <td>0.309542</td>\n",
       "      <td>0.250347</td>\n",
       "      <td>0.047741</td>\n",
       "      <td>0.199895</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.159051</td>\n",
       "      <td>0.187830</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>50.222342</td>\n",
       "      <td>0.693170</td>\n",
       "      <td>12</td>\n",
       "      <td>1.009179</td>\n",
       "      <td>-0.753237</td>\n",
       "      <td>0.417634</td>\n",
       "      <td>-0.112645</td>\n",
       "      <td>-0.461099</td>\n",
       "      <td>0.953749</td>\n",
       "      <td>1.378508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114812</td>\n",
       "      <td>-0.905737</td>\n",
       "      <td>0.244297</td>\n",
       "      <td>0.225142</td>\n",
       "      <td>0.087129</td>\n",
       "      <td>0.188352</td>\n",
       "      <td>0.090826</td>\n",
       "      <td>0.159677</td>\n",
       "      <td>0.186687</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>47.562180</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>16</td>\n",
       "      <td>1.009179</td>\n",
       "      <td>-0.879924</td>\n",
       "      <td>0.412683</td>\n",
       "      <td>-0.096128</td>\n",
       "      <td>-0.440835</td>\n",
       "      <td>0.919188</td>\n",
       "      <td>1.372138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447942</td>\n",
       "      <td>-0.936138</td>\n",
       "      <td>0.218059</td>\n",
       "      <td>0.223929</td>\n",
       "      <td>0.139713</td>\n",
       "      <td>0.210784</td>\n",
       "      <td>0.090084</td>\n",
       "      <td>0.160999</td>\n",
       "      <td>0.186059</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>48.086073</td>\n",
       "      <td>0.652171</td>\n",
       "      <td>13</td>\n",
       "      <td>0.928534</td>\n",
       "      <td>-0.974157</td>\n",
       "      <td>0.424066</td>\n",
       "      <td>-0.106277</td>\n",
       "      <td>-0.392351</td>\n",
       "      <td>0.985433</td>\n",
       "      <td>1.305142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223360</td>\n",
       "      <td>-1.080833</td>\n",
       "      <td>0.270873</td>\n",
       "      <td>0.262044</td>\n",
       "      <td>0.051334</td>\n",
       "      <td>0.082530</td>\n",
       "      <td>0.089379</td>\n",
       "      <td>0.161034</td>\n",
       "      <td>0.186297</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>53.161722</td>\n",
       "      <td>0.655214</td>\n",
       "      <td>11</td>\n",
       "      <td>0.981923</td>\n",
       "      <td>-0.974157</td>\n",
       "      <td>0.428843</td>\n",
       "      <td>-0.068646</td>\n",
       "      <td>-0.403066</td>\n",
       "      <td>0.891935</td>\n",
       "      <td>1.289719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165922</td>\n",
       "      <td>-1.063952</td>\n",
       "      <td>0.170308</td>\n",
       "      <td>0.292010</td>\n",
       "      <td>0.064838</td>\n",
       "      <td>0.321055</td>\n",
       "      <td>0.088590</td>\n",
       "      <td>0.160524</td>\n",
       "      <td>0.186907</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>47.851912</td>\n",
       "      <td>0.663243</td>\n",
       "      <td>14</td>\n",
       "      <td>0.981923</td>\n",
       "      <td>-0.846179</td>\n",
       "      <td>0.427271</td>\n",
       "      <td>-0.063014</td>\n",
       "      <td>-0.412555</td>\n",
       "      <td>0.888985</td>\n",
       "      <td>1.505170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118265</td>\n",
       "      <td>-1.035671</td>\n",
       "      <td>0.152741</td>\n",
       "      <td>0.081480</td>\n",
       "      <td>0.075957</td>\n",
       "      <td>0.337841</td>\n",
       "      <td>0.087782</td>\n",
       "      <td>0.160868</td>\n",
       "      <td>0.186899</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>47.062869</td>\n",
       "      <td>0.653979</td>\n",
       "      <td>13</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>-0.879855</td>\n",
       "      <td>0.414558</td>\n",
       "      <td>-0.109252</td>\n",
       "      <td>-0.419064</td>\n",
       "      <td>0.916248</td>\n",
       "      <td>1.151151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216568</td>\n",
       "      <td>-0.989248</td>\n",
       "      <td>0.260706</td>\n",
       "      <td>0.292007</td>\n",
       "      <td>0.045208</td>\n",
       "      <td>0.205164</td>\n",
       "      <td>0.087120</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.185676</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2d81032-d514-4db0-967e-cd7da168e149</th>\n",
       "      <td>48.359012</td>\n",
       "      <td>0.666127</td>\n",
       "      <td>11</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>-0.916209</td>\n",
       "      <td>0.401627</td>\n",
       "      <td>-0.105635</td>\n",
       "      <td>-0.447256</td>\n",
       "      <td>0.897409</td>\n",
       "      <td>1.341643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132778</td>\n",
       "      <td>-0.897979</td>\n",
       "      <td>0.236184</td>\n",
       "      <td>0.139868</td>\n",
       "      <td>0.047521</td>\n",
       "      <td>0.196802</td>\n",
       "      <td>0.086639</td>\n",
       "      <td>0.161122</td>\n",
       "      <td>0.184212</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>33.699412</td>\n",
       "      <td>0.394525</td>\n",
       "      <td>4</td>\n",
       "      <td>2.488131</td>\n",
       "      <td>-4.740152</td>\n",
       "      <td>-0.000945</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.018906</td>\n",
       "      <td>2.201475</td>\n",
       "      <td>2.853616</td>\n",
       "      <td>...</td>\n",
       "      <td>1.349337</td>\n",
       "      <td>-0.050001</td>\n",
       "      <td>1.409520</td>\n",
       "      <td>0.060396</td>\n",
       "      <td>0.090188</td>\n",
       "      <td>0.086844</td>\n",
       "      <td>0.176555</td>\n",
       "      <td>0.270928</td>\n",
       "      <td>0.195683</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>41.092642</td>\n",
       "      <td>0.426695</td>\n",
       "      <td>5</td>\n",
       "      <td>2.553589</td>\n",
       "      <td>-4.605173</td>\n",
       "      <td>0.023754</td>\n",
       "      <td>0.024253</td>\n",
       "      <td>0.011580</td>\n",
       "      <td>2.444617</td>\n",
       "      <td>3.040302</td>\n",
       "      <td>...</td>\n",
       "      <td>1.424939</td>\n",
       "      <td>2.051249</td>\n",
       "      <td>2.094354</td>\n",
       "      <td>0.032865</td>\n",
       "      <td>0.070991</td>\n",
       "      <td>0.046991</td>\n",
       "      <td>0.176612</td>\n",
       "      <td>0.270914</td>\n",
       "      <td>0.195651</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>39.844115</td>\n",
       "      <td>0.441173</td>\n",
       "      <td>5</td>\n",
       "      <td>2.553589</td>\n",
       "      <td>-3.488670</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>0.046437</td>\n",
       "      <td>0.048633</td>\n",
       "      <td>2.228174</td>\n",
       "      <td>3.038582</td>\n",
       "      <td>...</td>\n",
       "      <td>1.823158</td>\n",
       "      <td>0.507656</td>\n",
       "      <td>0.954833</td>\n",
       "      <td>0.090202</td>\n",
       "      <td>0.163323</td>\n",
       "      <td>0.065669</td>\n",
       "      <td>0.176631</td>\n",
       "      <td>0.270953</td>\n",
       "      <td>0.195694</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>33.990233</td>\n",
       "      <td>0.381190</td>\n",
       "      <td>3</td>\n",
       "      <td>2.456892</td>\n",
       "      <td>-3.488670</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.042064</td>\n",
       "      <td>0.042018</td>\n",
       "      <td>2.194068</td>\n",
       "      <td>3.174564</td>\n",
       "      <td>...</td>\n",
       "      <td>1.538098</td>\n",
       "      <td>0.202440</td>\n",
       "      <td>1.001080</td>\n",
       "      <td>0.065904</td>\n",
       "      <td>0.421853</td>\n",
       "      <td>0.153407</td>\n",
       "      <td>0.176540</td>\n",
       "      <td>0.270885</td>\n",
       "      <td>0.195670</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>36.596536</td>\n",
       "      <td>0.351145</td>\n",
       "      <td>6</td>\n",
       "      <td>2.256753</td>\n",
       "      <td>-3.753878</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.047136</td>\n",
       "      <td>-0.008704</td>\n",
       "      <td>1.982170</td>\n",
       "      <td>2.458227</td>\n",
       "      <td>...</td>\n",
       "      <td>1.996064</td>\n",
       "      <td>-1.000267</td>\n",
       "      <td>-5.415576</td>\n",
       "      <td>0.021555</td>\n",
       "      <td>0.066779</td>\n",
       "      <td>0.097862</td>\n",
       "      <td>0.176476</td>\n",
       "      <td>0.270659</td>\n",
       "      <td>0.195627</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>46.962502</td>\n",
       "      <td>0.399457</td>\n",
       "      <td>6</td>\n",
       "      <td>3.179257</td>\n",
       "      <td>-3.753878</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.057871</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>2.865049</td>\n",
       "      <td>3.056349</td>\n",
       "      <td>...</td>\n",
       "      <td>2.249411</td>\n",
       "      <td>0.605059</td>\n",
       "      <td>2.495986</td>\n",
       "      <td>0.195102</td>\n",
       "      <td>0.134399</td>\n",
       "      <td>0.081127</td>\n",
       "      <td>0.176452</td>\n",
       "      <td>0.270530</td>\n",
       "      <td>0.195676</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>42.504275</td>\n",
       "      <td>0.483105</td>\n",
       "      <td>5</td>\n",
       "      <td>3.179257</td>\n",
       "      <td>-3.312276</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.031497</td>\n",
       "      <td>0.012761</td>\n",
       "      <td>2.412987</td>\n",
       "      <td>3.478398</td>\n",
       "      <td>...</td>\n",
       "      <td>2.028575</td>\n",
       "      <td>0.293017</td>\n",
       "      <td>2.468202</td>\n",
       "      <td>0.123892</td>\n",
       "      <td>0.460889</td>\n",
       "      <td>0.430166</td>\n",
       "      <td>0.176563</td>\n",
       "      <td>0.270572</td>\n",
       "      <td>0.195783</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>44.011560</td>\n",
       "      <td>0.523093</td>\n",
       "      <td>7</td>\n",
       "      <td>2.874730</td>\n",
       "      <td>-2.809744</td>\n",
       "      <td>0.030977</td>\n",
       "      <td>0.020090</td>\n",
       "      <td>-0.005138</td>\n",
       "      <td>2.601326</td>\n",
       "      <td>3.438861</td>\n",
       "      <td>...</td>\n",
       "      <td>2.278638</td>\n",
       "      <td>-6.029174</td>\n",
       "      <td>-3.910174</td>\n",
       "      <td>0.064946</td>\n",
       "      <td>0.081196</td>\n",
       "      <td>0.084503</td>\n",
       "      <td>0.176798</td>\n",
       "      <td>0.270627</td>\n",
       "      <td>0.195907</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>40.760349</td>\n",
       "      <td>0.478213</td>\n",
       "      <td>7</td>\n",
       "      <td>2.449592</td>\n",
       "      <td>-2.805747</td>\n",
       "      <td>0.024132</td>\n",
       "      <td>0.051986</td>\n",
       "      <td>0.056283</td>\n",
       "      <td>2.393157</td>\n",
       "      <td>3.091913</td>\n",
       "      <td>...</td>\n",
       "      <td>2.704538</td>\n",
       "      <td>0.428764</td>\n",
       "      <td>0.923661</td>\n",
       "      <td>0.206964</td>\n",
       "      <td>0.177844</td>\n",
       "      <td>0.298659</td>\n",
       "      <td>0.176897</td>\n",
       "      <td>0.270645</td>\n",
       "      <td>0.196057</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>34.206680</td>\n",
       "      <td>0.386189</td>\n",
       "      <td>4</td>\n",
       "      <td>2.034640</td>\n",
       "      <td>-3.463871</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.044637</td>\n",
       "      <td>0.022708</td>\n",
       "      <td>1.893155</td>\n",
       "      <td>2.868716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.957451</td>\n",
       "      <td>0.193689</td>\n",
       "      <td>1.965734</td>\n",
       "      <td>0.033526</td>\n",
       "      <td>0.214497</td>\n",
       "      <td>0.135096</td>\n",
       "      <td>0.176834</td>\n",
       "      <td>0.270527</td>\n",
       "      <td>0.196081</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>33.121097</td>\n",
       "      <td>0.331535</td>\n",
       "      <td>4</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>-3.686302</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>0.048679</td>\n",
       "      <td>-0.021680</td>\n",
       "      <td>1.758883</td>\n",
       "      <td>2.096453</td>\n",
       "      <td>...</td>\n",
       "      <td>1.101897</td>\n",
       "      <td>-0.786310</td>\n",
       "      <td>-2.245372</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0.014297</td>\n",
       "      <td>0.176741</td>\n",
       "      <td>0.270250</td>\n",
       "      <td>0.196026</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>42.131904</td>\n",
       "      <td>0.387436</td>\n",
       "      <td>5</td>\n",
       "      <td>2.340950</td>\n",
       "      <td>-3.686302</td>\n",
       "      <td>-0.002789</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>0.012354</td>\n",
       "      <td>2.512638</td>\n",
       "      <td>3.057120</td>\n",
       "      <td>...</td>\n",
       "      <td>2.047413</td>\n",
       "      <td>-0.225721</td>\n",
       "      <td>4.744701</td>\n",
       "      <td>0.130985</td>\n",
       "      <td>0.156075</td>\n",
       "      <td>0.107059</td>\n",
       "      <td>0.176718</td>\n",
       "      <td>0.270115</td>\n",
       "      <td>0.196026</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>35.837287</td>\n",
       "      <td>0.423619</td>\n",
       "      <td>5</td>\n",
       "      <td>2.946559</td>\n",
       "      <td>-4.821471</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>0.025583</td>\n",
       "      <td>0.026002</td>\n",
       "      <td>2.520030</td>\n",
       "      <td>3.255887</td>\n",
       "      <td>...</td>\n",
       "      <td>2.140077</td>\n",
       "      <td>-0.068661</td>\n",
       "      <td>0.983882</td>\n",
       "      <td>0.049802</td>\n",
       "      <td>0.172835</td>\n",
       "      <td>0.020812</td>\n",
       "      <td>0.176716</td>\n",
       "      <td>0.270117</td>\n",
       "      <td>0.196030</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>44.604078</td>\n",
       "      <td>0.450639</td>\n",
       "      <td>6</td>\n",
       "      <td>2.946559</td>\n",
       "      <td>-4.821471</td>\n",
       "      <td>0.025081</td>\n",
       "      <td>0.029632</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>2.571582</td>\n",
       "      <td>3.331263</td>\n",
       "      <td>...</td>\n",
       "      <td>2.457532</td>\n",
       "      <td>2.612058</td>\n",
       "      <td>3.086060</td>\n",
       "      <td>0.027734</td>\n",
       "      <td>0.040254</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>0.176784</td>\n",
       "      <td>0.270142</td>\n",
       "      <td>0.196064</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>38.768165</td>\n",
       "      <td>0.450894</td>\n",
       "      <td>8</td>\n",
       "      <td>2.479426</td>\n",
       "      <td>-2.544354</td>\n",
       "      <td>0.027490</td>\n",
       "      <td>0.049789</td>\n",
       "      <td>0.033054</td>\n",
       "      <td>2.303296</td>\n",
       "      <td>3.019905</td>\n",
       "      <td>...</td>\n",
       "      <td>1.954176</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>1.506296</td>\n",
       "      <td>0.151709</td>\n",
       "      <td>0.070110</td>\n",
       "      <td>0.197753</td>\n",
       "      <td>0.176865</td>\n",
       "      <td>0.270140</td>\n",
       "      <td>0.196128</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>38.400170</td>\n",
       "      <td>0.402072</td>\n",
       "      <td>6</td>\n",
       "      <td>2.296475</td>\n",
       "      <td>-3.080866</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.050558</td>\n",
       "      <td>0.044784</td>\n",
       "      <td>2.307597</td>\n",
       "      <td>2.790476</td>\n",
       "      <td>...</td>\n",
       "      <td>1.898310</td>\n",
       "      <td>0.156283</td>\n",
       "      <td>1.128940</td>\n",
       "      <td>0.141662</td>\n",
       "      <td>0.412233</td>\n",
       "      <td>0.141182</td>\n",
       "      <td>0.176873</td>\n",
       "      <td>0.270060</td>\n",
       "      <td>0.196115</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>37.907620</td>\n",
       "      <td>0.373443</td>\n",
       "      <td>7</td>\n",
       "      <td>2.296475</td>\n",
       "      <td>-3.685416</td>\n",
       "      <td>0.043849</td>\n",
       "      <td>0.027390</td>\n",
       "      <td>-0.000979</td>\n",
       "      <td>2.134161</td>\n",
       "      <td>2.584280</td>\n",
       "      <td>...</td>\n",
       "      <td>1.767748</td>\n",
       "      <td>-44.786502</td>\n",
       "      <td>-27.975977</td>\n",
       "      <td>0.010990</td>\n",
       "      <td>0.072177</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>0.176878</td>\n",
       "      <td>0.269877</td>\n",
       "      <td>0.196059</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>43.837148</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>8</td>\n",
       "      <td>2.093182</td>\n",
       "      <td>-3.685416</td>\n",
       "      <td>0.058329</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>0.020193</td>\n",
       "      <td>2.346901</td>\n",
       "      <td>2.551869</td>\n",
       "      <td>...</td>\n",
       "      <td>1.338291</td>\n",
       "      <td>2.888614</td>\n",
       "      <td>2.157031</td>\n",
       "      <td>0.103010</td>\n",
       "      <td>0.081799</td>\n",
       "      <td>0.079521</td>\n",
       "      <td>0.176909</td>\n",
       "      <td>0.269724</td>\n",
       "      <td>0.196025</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>35.613878</td>\n",
       "      <td>0.403518</td>\n",
       "      <td>6</td>\n",
       "      <td>2.601856</td>\n",
       "      <td>-3.605283</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>0.046148</td>\n",
       "      <td>0.039193</td>\n",
       "      <td>1.945042</td>\n",
       "      <td>3.280692</td>\n",
       "      <td>...</td>\n",
       "      <td>1.423864</td>\n",
       "      <td>0.097612</td>\n",
       "      <td>1.177461</td>\n",
       "      <td>0.060015</td>\n",
       "      <td>0.163271</td>\n",
       "      <td>0.041792</td>\n",
       "      <td>0.176881</td>\n",
       "      <td>0.269703</td>\n",
       "      <td>0.195995</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>38.432927</td>\n",
       "      <td>0.433664</td>\n",
       "      <td>4</td>\n",
       "      <td>3.099438</td>\n",
       "      <td>-3.605283</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>2.383460</td>\n",
       "      <td>3.544895</td>\n",
       "      <td>...</td>\n",
       "      <td>1.749727</td>\n",
       "      <td>0.442626</td>\n",
       "      <td>0.585848</td>\n",
       "      <td>0.037062</td>\n",
       "      <td>0.036308</td>\n",
       "      <td>0.067015</td>\n",
       "      <td>0.176874</td>\n",
       "      <td>0.269750</td>\n",
       "      <td>0.195981</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>45.038068</td>\n",
       "      <td>0.506678</td>\n",
       "      <td>5</td>\n",
       "      <td>3.156926</td>\n",
       "      <td>-2.732547</td>\n",
       "      <td>0.036037</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.033509</td>\n",
       "      <td>2.596333</td>\n",
       "      <td>3.866258</td>\n",
       "      <td>...</td>\n",
       "      <td>2.602581</td>\n",
       "      <td>1.075424</td>\n",
       "      <td>1.006128</td>\n",
       "      <td>0.092786</td>\n",
       "      <td>0.085866</td>\n",
       "      <td>0.354102</td>\n",
       "      <td>0.176939</td>\n",
       "      <td>0.269931</td>\n",
       "      <td>0.196098</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>47.077936</td>\n",
       "      <td>0.514612</td>\n",
       "      <td>5</td>\n",
       "      <td>3.504014</td>\n",
       "      <td>-2.931715</td>\n",
       "      <td>0.036455</td>\n",
       "      <td>0.054035</td>\n",
       "      <td>0.040633</td>\n",
       "      <td>2.569577</td>\n",
       "      <td>3.968068</td>\n",
       "      <td>...</td>\n",
       "      <td>3.372458</td>\n",
       "      <td>0.897183</td>\n",
       "      <td>1.329817</td>\n",
       "      <td>0.135340</td>\n",
       "      <td>0.242441</td>\n",
       "      <td>0.373736</td>\n",
       "      <td>0.177003</td>\n",
       "      <td>0.270140</td>\n",
       "      <td>0.196198</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>42.204691</td>\n",
       "      <td>0.461851</td>\n",
       "      <td>3</td>\n",
       "      <td>3.504014</td>\n",
       "      <td>-2.931715</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>0.055554</td>\n",
       "      <td>0.057810</td>\n",
       "      <td>2.471465</td>\n",
       "      <td>3.920354</td>\n",
       "      <td>...</td>\n",
       "      <td>2.169439</td>\n",
       "      <td>0.203499</td>\n",
       "      <td>0.960981</td>\n",
       "      <td>0.137618</td>\n",
       "      <td>0.543534</td>\n",
       "      <td>0.081059</td>\n",
       "      <td>0.177006</td>\n",
       "      <td>0.270260</td>\n",
       "      <td>0.196207</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>35.286031</td>\n",
       "      <td>0.391984</td>\n",
       "      <td>3</td>\n",
       "      <td>3.038900</td>\n",
       "      <td>-2.727730</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>0.010647</td>\n",
       "      <td>0.024240</td>\n",
       "      <td>1.808518</td>\n",
       "      <td>3.115942</td>\n",
       "      <td>...</td>\n",
       "      <td>1.992673</td>\n",
       "      <td>0.718040</td>\n",
       "      <td>0.439226</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.134739</td>\n",
       "      <td>0.068655</td>\n",
       "      <td>0.176909</td>\n",
       "      <td>0.270229</td>\n",
       "      <td>0.196146</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>44.773859</td>\n",
       "      <td>0.403493</td>\n",
       "      <td>3</td>\n",
       "      <td>3.591787</td>\n",
       "      <td>-2.727730</td>\n",
       "      <td>0.038813</td>\n",
       "      <td>0.037128</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>2.368200</td>\n",
       "      <td>3.426757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.054065</td>\n",
       "      <td>4.526310</td>\n",
       "      <td>4.329802</td>\n",
       "      <td>0.108537</td>\n",
       "      <td>0.202708</td>\n",
       "      <td>0.029745</td>\n",
       "      <td>0.176882</td>\n",
       "      <td>0.270191</td>\n",
       "      <td>0.196112</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>54.725356</td>\n",
       "      <td>0.476077</td>\n",
       "      <td>4</td>\n",
       "      <td>3.631156</td>\n",
       "      <td>-2.773240</td>\n",
       "      <td>0.029824</td>\n",
       "      <td>0.093349</td>\n",
       "      <td>0.033430</td>\n",
       "      <td>2.328272</td>\n",
       "      <td>3.838714</td>\n",
       "      <td>...</td>\n",
       "      <td>3.001195</td>\n",
       "      <td>0.892145</td>\n",
       "      <td>2.792374</td>\n",
       "      <td>0.139531</td>\n",
       "      <td>0.580975</td>\n",
       "      <td>0.204056</td>\n",
       "      <td>0.176971</td>\n",
       "      <td>0.270296</td>\n",
       "      <td>0.196161</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>44.990705</td>\n",
       "      <td>0.482222</td>\n",
       "      <td>5</td>\n",
       "      <td>3.631156</td>\n",
       "      <td>-2.902449</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>0.045467</td>\n",
       "      <td>0.020995</td>\n",
       "      <td>2.484590</td>\n",
       "      <td>4.231413</td>\n",
       "      <td>...</td>\n",
       "      <td>2.279981</td>\n",
       "      <td>0.738450</td>\n",
       "      <td>2.165646</td>\n",
       "      <td>0.109443</td>\n",
       "      <td>0.435058</td>\n",
       "      <td>0.394613</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.270468</td>\n",
       "      <td>0.196197</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>45.635983</td>\n",
       "      <td>0.483523</td>\n",
       "      <td>5</td>\n",
       "      <td>3.346397</td>\n",
       "      <td>-4.063206</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>2.591126</td>\n",
       "      <td>4.092937</td>\n",
       "      <td>...</td>\n",
       "      <td>2.140551</td>\n",
       "      <td>2.471754</td>\n",
       "      <td>0.621104</td>\n",
       "      <td>0.057675</td>\n",
       "      <td>0.032472</td>\n",
       "      <td>0.248053</td>\n",
       "      <td>0.176982</td>\n",
       "      <td>0.270639</td>\n",
       "      <td>0.196220</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>47.204448</td>\n",
       "      <td>0.516681</td>\n",
       "      <td>4</td>\n",
       "      <td>3.556607</td>\n",
       "      <td>-4.063206</td>\n",
       "      <td>0.038955</td>\n",
       "      <td>0.022661</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>2.612172</td>\n",
       "      <td>4.130016</td>\n",
       "      <td>...</td>\n",
       "      <td>2.342015</td>\n",
       "      <td>1.389024</td>\n",
       "      <td>0.808022</td>\n",
       "      <td>0.060645</td>\n",
       "      <td>0.051170</td>\n",
       "      <td>0.260613</td>\n",
       "      <td>0.177037</td>\n",
       "      <td>0.270865</td>\n",
       "      <td>0.196286</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334f60c-e07a-4a04-af88-8e3037bf023a</th>\n",
       "      <td>42.683070</td>\n",
       "      <td>0.513878</td>\n",
       "      <td>4</td>\n",
       "      <td>3.556607</td>\n",
       "      <td>-2.874092</td>\n",
       "      <td>0.043061</td>\n",
       "      <td>0.049850</td>\n",
       "      <td>0.044573</td>\n",
       "      <td>2.478109</td>\n",
       "      <td>4.003384</td>\n",
       "      <td>...</td>\n",
       "      <td>2.310064</td>\n",
       "      <td>0.966067</td>\n",
       "      <td>1.118379</td>\n",
       "      <td>0.027444</td>\n",
       "      <td>0.249147</td>\n",
       "      <td>0.086739</td>\n",
       "      <td>0.177081</td>\n",
       "      <td>0.271091</td>\n",
       "      <td>0.196358</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19008 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fundamental_freq  average_accel  \\\n",
       "healthCode                                                              \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         84.093790       1.183311   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         92.089151       1.342022   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149        104.641810       1.389768   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         79.819556       1.157167   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         72.891574       0.944486   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         66.836892       0.906129   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         60.719927       0.850874   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         61.370547       0.831472   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         66.212932       0.831623   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         60.579467       0.815940   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         59.077575       0.817936   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         60.646997       0.820878   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         54.489166       0.782678   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         52.910412       0.729400   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         57.266872       0.728959   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         50.170137       0.727835   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         52.340432       0.732129   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         56.027040       0.753457   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         49.949909       0.724066   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         51.389303       0.682249   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         52.732006       0.693535   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         47.317359       0.690296   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         47.524138       0.677049   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         50.222342       0.693170   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         47.562180       0.680756   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         48.086073       0.652171   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         53.161722       0.655214   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         47.851912       0.663243   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         47.062869       0.653979   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         48.359012       0.666127   \n",
       "...                                                ...            ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         33.699412       0.394525   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         41.092642       0.426695   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         39.844115       0.441173   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         33.990233       0.381190   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         36.596536       0.351145   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         46.962502       0.399457   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         42.504275       0.483105   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         44.011560       0.523093   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         40.760349       0.478213   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         34.206680       0.386189   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         33.121097       0.331535   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         42.131904       0.387436   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         35.837287       0.423619   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         44.604078       0.450639   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         38.768165       0.450894   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         38.400170       0.402072   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         37.907620       0.373443   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         43.837148       0.387100   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         35.613878       0.403518   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         38.432927       0.433664   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         45.038068       0.506678   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         47.077936       0.514612   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         42.204691       0.461851   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         35.286031       0.391984   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         44.773859       0.403493   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         54.725356       0.476077   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         44.990705       0.482222   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         45.635983       0.483523   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         47.204448       0.516681   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a         42.683070       0.513878   \n",
       "\n",
       "                                      peakcount       max       min     mut_x  \\\n",
       "healthCode                                                                      \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         17  1.735415 -0.093085  0.544209   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         22  1.903300 -0.093085  0.839665   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         21  2.007266 -0.088764  0.942869   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         19  2.007266 -0.781718  0.769605   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         17  1.329425 -0.781718  0.599926   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         14  1.276772 -0.666723  0.567256   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         13  1.276772 -0.666723  0.552406   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         13  1.254676 -0.550120  0.580600   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149          9  1.254676 -0.526269  0.601940   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         11  1.154157 -0.667954  0.588794   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         15  1.128464 -0.667954  0.583666   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         18  1.090094 -0.776631  0.567537   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         12  1.090094 -0.776631  0.514440   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149          8  1.028011 -0.703446  0.483433   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149          8  1.081256 -0.823816  0.488750   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149          8  1.081256 -0.839114  0.467077   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         12  1.093421 -0.839114  0.449070   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         15  1.093421 -0.792955  0.443907   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         12  1.043737 -0.841776  0.426953   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149          9  1.043737 -0.841776  0.436159   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         10  0.977790 -0.806267  0.470510   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         13  0.965234 -0.817927  0.473044   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         14  0.984435 -0.817927  0.443769   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         12  1.009179 -0.753237  0.417634   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         16  1.009179 -0.879924  0.412683   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         13  0.928534 -0.974157  0.424066   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         11  0.981923 -0.974157  0.428843   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         14  0.981923 -0.846179  0.427271   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         13  0.996672 -0.879855  0.414558   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149         11  0.996672 -0.916209  0.401627   \n",
       "...                                         ...       ...       ...       ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  2.488131 -4.740152 -0.000945   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  2.553589 -4.605173  0.023754   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  2.553589 -3.488670  0.024689   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          3  2.456892 -3.488670  0.008506   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          6  2.256753 -3.753878  0.008706   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          6  3.179257 -3.753878  0.014029   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  3.179257 -3.312276  0.003739   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          7  2.874730 -2.809744  0.030977   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          7  2.449592 -2.805747  0.024132   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  2.034640 -3.463871  0.004398   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  2.153820 -3.686302  0.017047   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  2.340950 -3.686302 -0.002789   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  2.946559 -4.821471 -0.001785   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          6  2.946559 -4.821471  0.025081   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          8  2.479426 -2.544354  0.027490   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          6  2.296475 -3.080866  0.006999   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          7  2.296475 -3.685416  0.043849   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          8  2.093182 -3.685416  0.058329   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          6  2.601856 -3.605283  0.003826   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  3.099438 -3.605283  0.010333   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  3.156926 -2.732547  0.036037   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  3.504014 -2.931715  0.036455   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          3  3.504014 -2.931715  0.011764   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          3  3.038900 -2.727730  0.017405   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          3  3.591787 -2.727730  0.038813   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  3.631156 -2.773240  0.029824   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  3.631156 -2.902449  0.015503   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          5  3.346397 -4.063206  0.025547   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  3.556607 -4.063206  0.038955   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a          4  3.556607 -2.874092  0.043061   \n",
       "\n",
       "                                         mut_y     mut_z     muf_x     muf_y  \\\n",
       "healthCode                                                                     \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.835330 -0.556319  1.711133  1.428328   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.898862 -0.440043  2.086170  1.598540   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.922103 -0.364584  2.173094  1.834422   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.632780 -0.461603  2.016581  2.401082   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.339092 -0.584421  1.330641  1.309831   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.304049 -0.560532  1.236783  1.375709   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.296679 -0.490727  1.277836  1.575615   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.250549 -0.453239  1.327007  1.598099   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.178678 -0.460331  1.289884  1.665117   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.176729 -0.457068  1.148517  1.491882   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.220211 -0.465978  1.111319  1.302529   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.219909 -0.496696  0.940857  1.216790   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.207049 -0.481604  0.916877  1.300558   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.197842 -0.438156  0.964371  1.275265   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.157379 -0.452355  0.925394  1.333243   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.154210 -0.459784  0.908797  1.585312   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.183110 -0.469360  0.922036  1.193293   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.184973 -0.508436  0.917616  1.457874   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.188452 -0.476689  0.811547  1.381015   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.178748 -0.413089  0.818255  1.254024   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.110734 -0.412024  0.926819  1.352405   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.083274 -0.405087  1.023133  1.492721   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.127068 -0.410505  0.975527  1.161857   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.112645 -0.461099  0.953749  1.378508   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.096128 -0.440835  0.919188  1.372138   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.106277 -0.392351  0.985433  1.305142   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.068646 -0.403066  0.891935  1.289719   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.063014 -0.412555  0.888985  1.505170   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.109252 -0.419064  0.916248  1.151151   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149 -0.105635 -0.447256  0.897409  1.341643   \n",
       "...                                        ...       ...       ...       ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.026649  0.018906  2.201475  2.853616   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.024253  0.011580  2.444617  3.040302   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.046437  0.048633  2.228174  3.038582   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.042064  0.042018  2.194068  3.174564   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.047136 -0.008704  1.982170  2.458227   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.057871  0.023185  2.865049  3.056349   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.031497  0.012761  2.412987  3.478398   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.020090 -0.005138  2.601326  3.438861   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.051986  0.056283  2.393157  3.091913   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.044637  0.022708  1.893155  2.868716   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.048679 -0.021680  1.758883  2.096453   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.058617  0.012354  2.512638  3.057120   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.025583  0.026002  2.520030  3.255887   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.029632  0.009602  2.571582  3.331263   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.049789  0.033054  2.303296  3.019905   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.050558  0.044784  2.307597  2.790476   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.027390 -0.000979  2.134161  2.584280   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.043556  0.020193  2.346901  2.551869   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.046148  0.039193  1.945042  3.280692   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.013677  0.023345  2.383460  3.544895   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.033715  0.033509  2.596333  3.866258   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.054035  0.040633  2.569577  3.968068   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.055554  0.057810  2.471465  3.920354   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.010647  0.024240  1.808518  3.115942   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.037128  0.008575  2.368200  3.426757   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.093349  0.033430  2.328272  3.838714   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.045467  0.020995  2.484590  4.231413   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.006419  0.010335  2.591126  4.092937   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.022661  0.028045  2.612172  4.130016   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  0.049850  0.044573  2.478109  4.003384   \n",
       "\n",
       "                                      ...     medf_z   cross_xz   cross_yz  \\\n",
       "healthCode                            ...                                    \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.345499  -0.978232   1.501529   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.399225  -1.908143   2.042669   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.400768  -2.586148   2.529189   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.201667  -1.667245   1.370832   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.291241  -1.026531   0.580219   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.192802  -1.011996   0.542428   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.546107  -1.125689   0.604570   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.084389  -1.281004   0.552797   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.340095  -1.307624   0.388151   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.150211  -1.288199   0.386658   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.254868  -1.252562   0.472578   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.180884  -1.142624   0.442744   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.525174  -1.068182   0.429917   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.063238  -1.103335   0.451534   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.264525  -1.080458   0.347910   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.093361  -1.015863   0.335398   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.318459  -0.956771   0.390128   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.136323  -0.873083   0.363809   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.602169  -0.895665   0.395335   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.071291  -1.055849   0.432710   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.325562  -1.141947   0.268755   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.079998  -1.167761   0.205571   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.232476  -1.081033   0.309542   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.114812  -0.905737   0.244297   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.447942  -0.936138   0.218059   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.223360  -1.080833   0.270873   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.165922  -1.063952   0.170308   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.118265  -1.035671   0.152741   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.216568  -0.989248   0.260706   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  ...   0.132778  -0.897979   0.236184   \n",
       "...                                   ...        ...        ...        ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.349337  -0.050001   1.409520   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.424939   2.051249   2.094354   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.823158   0.507656   0.954833   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.538098   0.202440   1.001080   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.996064  -1.000267  -5.415576   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.249411   0.605059   2.495986   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.028575   0.293017   2.468202   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.278638  -6.029174  -3.910174   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.704538   0.428764   0.923661   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.957451   0.193689   1.965734   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.101897  -0.786310  -2.245372   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.047413  -0.225721   4.744701   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.140077  -0.068661   0.983882   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.457532   2.612058   3.086060   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.954176   0.831683   1.506296   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.898310   0.156283   1.128940   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.767748 -44.786502 -27.975977   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.338291   2.888614   2.157031   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.423864   0.097612   1.177461   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.749727   0.442626   0.585848   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.602581   1.075424   1.006128   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   3.372458   0.897183   1.329817   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.169439   0.203499   0.960981   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   1.992673   0.718040   0.439226   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.054065   4.526310   4.329802   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   3.001195   0.892145   2.792374   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.279981   0.738450   2.165646   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.140551   2.471754   0.621104   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.342015   1.389024   0.808022   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  ...   2.310064   0.966067   1.118379   \n",
       "\n",
       "                                      spect_cent_x  spect_cent_y  \\\n",
       "healthCode                                                         \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.401588      0.635471   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.079886      0.668962   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      1.086869      1.027991   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.607490      1.018372   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.715500      0.188665   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.214774      0.047958   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.264018      0.079070   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.473761      0.030326   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.556822      0.106259   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.185172      0.123464   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.467362      0.184988   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.285164      0.018012   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.238048      0.094047   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.302710      0.072282   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.304506      0.086258   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.151139      0.141883   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.239547      0.074789   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.212675      0.130208   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.221417      0.097678   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.207117      0.048559   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.216126      0.085050   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.114224      0.079382   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.250347      0.047741   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.225142      0.087129   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.223929      0.139713   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.262044      0.051334   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.292010      0.064838   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.081480      0.075957   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.292007      0.045208   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.139868      0.047521   \n",
       "...                                            ...           ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.060396      0.090188   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.032865      0.070991   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.090202      0.163323   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.065904      0.421853   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.021555      0.066779   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.195102      0.134399   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.123892      0.460889   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.064946      0.081196   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.206964      0.177844   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.033526      0.214497   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.009352      0.017789   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.130985      0.156075   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.049802      0.172835   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.027734      0.040254   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.151709      0.070110   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.141662      0.412233   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.010990      0.072177   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.103010      0.081799   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.060015      0.163271   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.037062      0.036308   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.092786      0.085866   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.135340      0.242441   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.137618      0.543534   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.002565      0.134739   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.108537      0.202708   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.139531      0.580975   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.109443      0.435058   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.057675      0.032472   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.060645      0.051170   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.027444      0.249147   \n",
       "\n",
       "                                      spect_cent_z  average_dist_meanx  \\\n",
       "healthCode                                                               \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.261587            0.189971   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.220937            0.181666   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.568184            0.182744   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.019616            0.183512   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.331627            0.165407   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.079783            0.154599   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.212707            0.145825   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.220903            0.140423   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.624609            0.135938   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.379450            0.129763   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.248037            0.123476   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.440142            0.117182   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.231297            0.112997   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.178837            0.109271   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.551066            0.105975   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.227174            0.103199   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.281503            0.101150   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.357410            0.099332   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.257579            0.097011   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.149732            0.094774   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.557988            0.093004   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.181422            0.091857   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.199895            0.091300   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.188352            0.090826   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.210784            0.090084   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.082530            0.089379   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.321055            0.088590   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.337841            0.087782   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.205164            0.087120   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149      0.196802            0.086639   \n",
       "...                                            ...                 ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.086844            0.176555   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.046991            0.176612   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.065669            0.176631   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.153407            0.176540   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.097862            0.176476   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.081127            0.176452   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.430166            0.176563   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.084503            0.176798   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.298659            0.176897   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.135096            0.176834   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.014297            0.176741   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.107059            0.176718   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.020812            0.176716   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.131417            0.176784   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.197753            0.176865   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.141182            0.176873   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.027619            0.176878   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.079521            0.176909   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.041792            0.176881   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.067015            0.176874   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.354102            0.176939   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.373736            0.177003   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.081059            0.177006   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.068655            0.176909   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.029745            0.176882   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.204056            0.176971   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.394613            0.176991   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.248053            0.176982   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.260613            0.177037   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a      0.086739            0.177081   \n",
       "\n",
       "                                      average_dist_meany  average_dist_meanz  \\\n",
       "healthCode                                                                     \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.066015            0.219167   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.070069            0.225696   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.078027            0.211303   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.128274            0.214012   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.136041            0.215774   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.144718            0.214896   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.149558            0.212353   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.153129            0.207136   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.155627            0.203303   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.156769            0.201240   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.155946            0.198892   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.155380            0.196078   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.156545            0.195434   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.156524            0.193544   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.155633            0.191828   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.155599            0.191978   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.156027            0.191443   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.157155            0.189383   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.158279            0.188860   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.158338            0.188561   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.158651            0.188337   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.159138            0.188416   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.159051            0.187830   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.159677            0.186687   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.160999            0.186059   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.161034            0.186297   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.160524            0.186907   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.160868            0.186899   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.160787            0.185676   \n",
       "c2d81032-d514-4db0-967e-cd7da168e149            0.161122            0.184212   \n",
       "...                                                  ...                 ...   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270928            0.195683   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270914            0.195651   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270953            0.195694   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270885            0.195670   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270659            0.195627   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270530            0.195676   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270572            0.195783   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270627            0.195907   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270645            0.196057   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270527            0.196081   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270250            0.196026   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270115            0.196026   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270117            0.196030   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270142            0.196064   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270140            0.196128   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270060            0.196115   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.269877            0.196059   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.269724            0.196025   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.269703            0.195995   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.269750            0.195981   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.269931            0.196098   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270140            0.196198   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270260            0.196207   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270229            0.196146   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270191            0.196112   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270296            0.196161   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270468            0.196197   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270639            0.196220   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.270865            0.196286   \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a            0.271091            0.196358   \n",
       "\n",
       "                                       sex  \n",
       "healthCode                                  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "c2d81032-d514-4db0-967e-cd7da168e149  Male  \n",
       "...                                    ...  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "4334f60c-e07a-4a04-af88-8e3037bf023a  Male  \n",
       "\n",
       "[19008 rows x 26 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male = testing.loc[testing['sex'] == 'Male']\n",
    "male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7040"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_male=[]\n",
    "for i in range(0, len(list(male.iloc[:, 25]))):\n",
    "    if list(clf.predict(male.iloc[:, 0:25]))[i] != male.iloc[:, 25][i]:\n",
    "        results_male.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4576"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20064"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chopped_male = male_train.iloc[0:4576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4576"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chopped_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models with over 300 unique subjects\n",
    "\n",
    "1. Random Forest Classification\n",
    "2. Random Forest Regression\n",
    "2. K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO READ IN THE H5 FILE\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tengaps_total  = pd.read_hdf('tengaps_total.h5', 'df')\n",
    "\n",
    "# Min number of samples is 352... total subjects after filtering is 311\n",
    "tengaps_total = min_df(find_lowest_num_samples(tengaps_total), tengaps_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fundamental_freq</th>\n",
       "      <th>average_accel</th>\n",
       "      <th>peakcount</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mut_x</th>\n",
       "      <th>mut_y</th>\n",
       "      <th>mut_z</th>\n",
       "      <th>muf_x</th>\n",
       "      <th>muf_y</th>\n",
       "      <th>...</th>\n",
       "      <th>medf_z</th>\n",
       "      <th>cross_xz</th>\n",
       "      <th>cross_yz</th>\n",
       "      <th>spect_cent_x</th>\n",
       "      <th>spect_cent_y</th>\n",
       "      <th>spect_cent_z</th>\n",
       "      <th>average_dist_meanx</th>\n",
       "      <th>average_dist_meany</th>\n",
       "      <th>average_dist_meanz</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>67.085782</td>\n",
       "      <td>0.954858</td>\n",
       "      <td>14</td>\n",
       "      <td>1.264397</td>\n",
       "      <td>-0.289971</td>\n",
       "      <td>-0.534878</td>\n",
       "      <td>-0.069511</td>\n",
       "      <td>-0.771628</td>\n",
       "      <td>0.944891</td>\n",
       "      <td>0.738003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174295</td>\n",
       "      <td>0.693181</td>\n",
       "      <td>0.090084</td>\n",
       "      <td>0.238413</td>\n",
       "      <td>0.027467</td>\n",
       "      <td>1.127965</td>\n",
       "      <td>0.076262</td>\n",
       "      <td>0.075348</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>63.795418</td>\n",
       "      <td>0.934924</td>\n",
       "      <td>13</td>\n",
       "      <td>1.138931</td>\n",
       "      <td>-0.253882</td>\n",
       "      <td>-0.506954</td>\n",
       "      <td>-0.103759</td>\n",
       "      <td>-0.766953</td>\n",
       "      <td>0.916676</td>\n",
       "      <td>0.501419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172362</td>\n",
       "      <td>0.660998</td>\n",
       "      <td>0.135288</td>\n",
       "      <td>0.314994</td>\n",
       "      <td>0.012541</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.072738</td>\n",
       "      <td>0.069466</td>\n",
       "      <td>0.088834</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>65.103583</td>\n",
       "      <td>0.931793</td>\n",
       "      <td>13</td>\n",
       "      <td>1.138931</td>\n",
       "      <td>-0.330068</td>\n",
       "      <td>-0.499181</td>\n",
       "      <td>-0.082214</td>\n",
       "      <td>-0.769834</td>\n",
       "      <td>0.859019</td>\n",
       "      <td>0.494451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166739</td>\n",
       "      <td>0.648426</td>\n",
       "      <td>0.106794</td>\n",
       "      <td>0.271671</td>\n",
       "      <td>0.023342</td>\n",
       "      <td>0.681087</td>\n",
       "      <td>0.067990</td>\n",
       "      <td>0.068576</td>\n",
       "      <td>0.092119</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>66.238475</td>\n",
       "      <td>0.946918</td>\n",
       "      <td>11</td>\n",
       "      <td>1.111950</td>\n",
       "      <td>-0.330068</td>\n",
       "      <td>-0.509581</td>\n",
       "      <td>-0.053556</td>\n",
       "      <td>-0.783584</td>\n",
       "      <td>0.945719</td>\n",
       "      <td>0.445917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040059</td>\n",
       "      <td>0.650320</td>\n",
       "      <td>0.068347</td>\n",
       "      <td>0.241556</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.797826</td>\n",
       "      <td>0.070011</td>\n",
       "      <td>0.067201</td>\n",
       "      <td>0.092783</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>63.286927</td>\n",
       "      <td>0.927726</td>\n",
       "      <td>10</td>\n",
       "      <td>1.111950</td>\n",
       "      <td>-0.305990</td>\n",
       "      <td>-0.480510</td>\n",
       "      <td>-0.057301</td>\n",
       "      <td>-0.780704</td>\n",
       "      <td>0.928506</td>\n",
       "      <td>0.574811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150732</td>\n",
       "      <td>0.615483</td>\n",
       "      <td>0.073397</td>\n",
       "      <td>0.256973</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.323727</td>\n",
       "      <td>0.071155</td>\n",
       "      <td>0.066718</td>\n",
       "      <td>0.090758</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>62.957114</td>\n",
       "      <td>0.909125</td>\n",
       "      <td>12</td>\n",
       "      <td>1.092683</td>\n",
       "      <td>-0.379909</td>\n",
       "      <td>-0.476771</td>\n",
       "      <td>-0.055130</td>\n",
       "      <td>-0.762466</td>\n",
       "      <td>0.874466</td>\n",
       "      <td>0.415136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186134</td>\n",
       "      <td>0.625301</td>\n",
       "      <td>0.072305</td>\n",
       "      <td>0.146630</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.792151</td>\n",
       "      <td>0.068916</td>\n",
       "      <td>0.064779</td>\n",
       "      <td>0.090519</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>66.226994</td>\n",
       "      <td>0.934234</td>\n",
       "      <td>12</td>\n",
       "      <td>1.148762</td>\n",
       "      <td>-0.379909</td>\n",
       "      <td>-0.510586</td>\n",
       "      <td>-0.047011</td>\n",
       "      <td>-0.773262</td>\n",
       "      <td>0.850504</td>\n",
       "      <td>0.363455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102905</td>\n",
       "      <td>0.660302</td>\n",
       "      <td>0.060796</td>\n",
       "      <td>0.395388</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.632894</td>\n",
       "      <td>0.068502</td>\n",
       "      <td>0.062522</td>\n",
       "      <td>0.088770</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>65.436068</td>\n",
       "      <td>0.958884</td>\n",
       "      <td>9</td>\n",
       "      <td>1.148762</td>\n",
       "      <td>-0.217064</td>\n",
       "      <td>-0.534148</td>\n",
       "      <td>-0.046814</td>\n",
       "      <td>-0.789749</td>\n",
       "      <td>0.820175</td>\n",
       "      <td>0.359124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049214</td>\n",
       "      <td>0.676352</td>\n",
       "      <td>0.059277</td>\n",
       "      <td>0.198089</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>0.478479</td>\n",
       "      <td>0.067823</td>\n",
       "      <td>0.060693</td>\n",
       "      <td>0.085879</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>69.620523</td>\n",
       "      <td>0.984328</td>\n",
       "      <td>11</td>\n",
       "      <td>1.249605</td>\n",
       "      <td>-0.217064</td>\n",
       "      <td>-0.560564</td>\n",
       "      <td>-0.044535</td>\n",
       "      <td>-0.798351</td>\n",
       "      <td>0.920737</td>\n",
       "      <td>0.411789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048028</td>\n",
       "      <td>0.702152</td>\n",
       "      <td>0.055784</td>\n",
       "      <td>0.362078</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.568121</td>\n",
       "      <td>0.065979</td>\n",
       "      <td>0.059962</td>\n",
       "      <td>0.085895</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>65.600549</td>\n",
       "      <td>0.956504</td>\n",
       "      <td>6</td>\n",
       "      <td>1.249605</td>\n",
       "      <td>-0.200400</td>\n",
       "      <td>-0.527813</td>\n",
       "      <td>-0.003825</td>\n",
       "      <td>-0.788620</td>\n",
       "      <td>0.849760</td>\n",
       "      <td>0.443316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106975</td>\n",
       "      <td>0.669287</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.236350</td>\n",
       "      <td>0.019285</td>\n",
       "      <td>0.376152</td>\n",
       "      <td>0.065443</td>\n",
       "      <td>0.058832</td>\n",
       "      <td>0.084310</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>62.692366</td>\n",
       "      <td>0.915588</td>\n",
       "      <td>10</td>\n",
       "      <td>1.043506</td>\n",
       "      <td>-0.155986</td>\n",
       "      <td>-0.476333</td>\n",
       "      <td>0.037848</td>\n",
       "      <td>-0.779430</td>\n",
       "      <td>0.693798</td>\n",
       "      <td>0.283654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041018</td>\n",
       "      <td>0.611130</td>\n",
       "      <td>-0.048559</td>\n",
       "      <td>0.265534</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.659814</td>\n",
       "      <td>0.062251</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>0.078660</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>64.653065</td>\n",
       "      <td>0.910956</td>\n",
       "      <td>11</td>\n",
       "      <td>1.058875</td>\n",
       "      <td>-0.395313</td>\n",
       "      <td>-0.464231</td>\n",
       "      <td>0.051783</td>\n",
       "      <td>-0.778352</td>\n",
       "      <td>0.774116</td>\n",
       "      <td>0.289797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071172</td>\n",
       "      <td>0.596429</td>\n",
       "      <td>-0.066529</td>\n",
       "      <td>0.218246</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.612663</td>\n",
       "      <td>0.061782</td>\n",
       "      <td>0.054715</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>63.594047</td>\n",
       "      <td>0.924236</td>\n",
       "      <td>11</td>\n",
       "      <td>1.107832</td>\n",
       "      <td>-0.395313</td>\n",
       "      <td>-0.471030</td>\n",
       "      <td>0.064635</td>\n",
       "      <td>-0.784763</td>\n",
       "      <td>0.968877</td>\n",
       "      <td>0.434174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135187</td>\n",
       "      <td>0.600220</td>\n",
       "      <td>-0.082363</td>\n",
       "      <td>0.325600</td>\n",
       "      <td>0.014517</td>\n",
       "      <td>0.750520</td>\n",
       "      <td>0.063319</td>\n",
       "      <td>0.054911</td>\n",
       "      <td>0.075436</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>68.210807</td>\n",
       "      <td>0.932986</td>\n",
       "      <td>12</td>\n",
       "      <td>1.120446</td>\n",
       "      <td>-0.359916</td>\n",
       "      <td>-0.491304</td>\n",
       "      <td>0.041242</td>\n",
       "      <td>-0.784748</td>\n",
       "      <td>0.850870</td>\n",
       "      <td>0.397725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068432</td>\n",
       "      <td>0.626066</td>\n",
       "      <td>-0.052554</td>\n",
       "      <td>0.211159</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.766621</td>\n",
       "      <td>0.063790</td>\n",
       "      <td>0.054852</td>\n",
       "      <td>0.075310</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>60.632964</td>\n",
       "      <td>0.890667</td>\n",
       "      <td>13</td>\n",
       "      <td>1.120446</td>\n",
       "      <td>-0.392977</td>\n",
       "      <td>-0.443334</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>-0.763810</td>\n",
       "      <td>0.830313</td>\n",
       "      <td>0.374351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145532</td>\n",
       "      <td>0.580425</td>\n",
       "      <td>-0.002076</td>\n",
       "      <td>0.163394</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.452960</td>\n",
       "      <td>0.063791</td>\n",
       "      <td>0.054894</td>\n",
       "      <td>0.075121</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>60.546090</td>\n",
       "      <td>0.874371</td>\n",
       "      <td>15</td>\n",
       "      <td>1.061445</td>\n",
       "      <td>-0.392977</td>\n",
       "      <td>-0.414754</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>-0.758657</td>\n",
       "      <td>0.848571</td>\n",
       "      <td>0.407986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027377</td>\n",
       "      <td>0.546694</td>\n",
       "      <td>-0.002988</td>\n",
       "      <td>0.192699</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.591684</td>\n",
       "      <td>0.064051</td>\n",
       "      <td>0.055479</td>\n",
       "      <td>0.075558</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>59.790683</td>\n",
       "      <td>0.855578</td>\n",
       "      <td>14</td>\n",
       "      <td>1.061445</td>\n",
       "      <td>-0.384322</td>\n",
       "      <td>-0.391439</td>\n",
       "      <td>0.022985</td>\n",
       "      <td>-0.748136</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>0.411247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112565</td>\n",
       "      <td>0.523219</td>\n",
       "      <td>-0.030723</td>\n",
       "      <td>0.161024</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>0.758911</td>\n",
       "      <td>0.064786</td>\n",
       "      <td>0.056283</td>\n",
       "      <td>0.075330</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>57.360890</td>\n",
       "      <td>0.831971</td>\n",
       "      <td>10</td>\n",
       "      <td>1.013798</td>\n",
       "      <td>-0.335147</td>\n",
       "      <td>-0.353427</td>\n",
       "      <td>0.025571</td>\n",
       "      <td>-0.741990</td>\n",
       "      <td>0.738707</td>\n",
       "      <td>0.494519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027193</td>\n",
       "      <td>0.476323</td>\n",
       "      <td>-0.034462</td>\n",
       "      <td>0.147918</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.598078</td>\n",
       "      <td>0.063991</td>\n",
       "      <td>0.057532</td>\n",
       "      <td>0.075354</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>58.154674</td>\n",
       "      <td>0.830002</td>\n",
       "      <td>9</td>\n",
       "      <td>1.162445</td>\n",
       "      <td>-0.437504</td>\n",
       "      <td>-0.367034</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>-0.731961</td>\n",
       "      <td>0.701466</td>\n",
       "      <td>0.515345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032848</td>\n",
       "      <td>0.501439</td>\n",
       "      <td>-0.035609</td>\n",
       "      <td>0.040231</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.594211</td>\n",
       "      <td>0.062993</td>\n",
       "      <td>0.058459</td>\n",
       "      <td>0.076930</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>55.315161</td>\n",
       "      <td>0.794198</td>\n",
       "      <td>10</td>\n",
       "      <td>1.162445</td>\n",
       "      <td>-0.502105</td>\n",
       "      <td>-0.326042</td>\n",
       "      <td>-0.006285</td>\n",
       "      <td>-0.704335</td>\n",
       "      <td>0.804711</td>\n",
       "      <td>0.496162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110738</td>\n",
       "      <td>0.462908</td>\n",
       "      <td>0.008924</td>\n",
       "      <td>0.119833</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.603580</td>\n",
       "      <td>0.063918</td>\n",
       "      <td>0.059872</td>\n",
       "      <td>0.078990</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>52.780136</td>\n",
       "      <td>0.753188</td>\n",
       "      <td>11</td>\n",
       "      <td>1.030213</td>\n",
       "      <td>-0.502105</td>\n",
       "      <td>-0.282951</td>\n",
       "      <td>-0.024918</td>\n",
       "      <td>-0.682193</td>\n",
       "      <td>0.748362</td>\n",
       "      <td>0.488581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046876</td>\n",
       "      <td>0.414767</td>\n",
       "      <td>0.036526</td>\n",
       "      <td>0.092451</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.568530</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.060780</td>\n",
       "      <td>0.079731</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>52.894673</td>\n",
       "      <td>0.711603</td>\n",
       "      <td>14</td>\n",
       "      <td>1.174667</td>\n",
       "      <td>-1.471883</td>\n",
       "      <td>-0.249338</td>\n",
       "      <td>0.036152</td>\n",
       "      <td>-0.624678</td>\n",
       "      <td>1.386751</td>\n",
       "      <td>1.086806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585580</td>\n",
       "      <td>0.399146</td>\n",
       "      <td>-0.057872</td>\n",
       "      <td>0.194690</td>\n",
       "      <td>0.056801</td>\n",
       "      <td>0.490418</td>\n",
       "      <td>0.066443</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>0.082444</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>46.761131</td>\n",
       "      <td>0.618119</td>\n",
       "      <td>19</td>\n",
       "      <td>1.174667</td>\n",
       "      <td>-1.755507</td>\n",
       "      <td>-0.050172</td>\n",
       "      <td>0.248194</td>\n",
       "      <td>-0.285224</td>\n",
       "      <td>1.511354</td>\n",
       "      <td>1.585861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615039</td>\n",
       "      <td>0.175905</td>\n",
       "      <td>-0.870170</td>\n",
       "      <td>0.210071</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>0.527406</td>\n",
       "      <td>0.072911</td>\n",
       "      <td>0.069775</td>\n",
       "      <td>0.092801</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>37.631491</td>\n",
       "      <td>0.511707</td>\n",
       "      <td>25</td>\n",
       "      <td>0.918106</td>\n",
       "      <td>-3.284295</td>\n",
       "      <td>0.170182</td>\n",
       "      <td>0.180029</td>\n",
       "      <td>-0.063882</td>\n",
       "      <td>1.620267</td>\n",
       "      <td>1.855273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349716</td>\n",
       "      <td>-2.664000</td>\n",
       "      <td>-2.818149</td>\n",
       "      <td>0.046273</td>\n",
       "      <td>0.175368</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>0.077946</td>\n",
       "      <td>0.078599</td>\n",
       "      <td>0.097122</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>44.106746</td>\n",
       "      <td>0.569364</td>\n",
       "      <td>24</td>\n",
       "      <td>1.161511</td>\n",
       "      <td>-3.284295</td>\n",
       "      <td>0.207179</td>\n",
       "      <td>-0.057366</td>\n",
       "      <td>-0.198674</td>\n",
       "      <td>1.882485</td>\n",
       "      <td>1.867747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660298</td>\n",
       "      <td>-1.042808</td>\n",
       "      <td>0.288746</td>\n",
       "      <td>0.285638</td>\n",
       "      <td>0.073846</td>\n",
       "      <td>0.061787</td>\n",
       "      <td>0.085492</td>\n",
       "      <td>0.084775</td>\n",
       "      <td>0.103727</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>44.843415</td>\n",
       "      <td>0.611570</td>\n",
       "      <td>23</td>\n",
       "      <td>1.287563</td>\n",
       "      <td>-1.774269</td>\n",
       "      <td>0.137964</td>\n",
       "      <td>-0.201438</td>\n",
       "      <td>-0.147749</td>\n",
       "      <td>2.219901</td>\n",
       "      <td>2.274327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673942</td>\n",
       "      <td>-0.933773</td>\n",
       "      <td>1.363385</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>0.086704</td>\n",
       "      <td>0.116680</td>\n",
       "      <td>0.092395</td>\n",
       "      <td>0.092359</td>\n",
       "      <td>0.110029</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>35.471330</td>\n",
       "      <td>0.466006</td>\n",
       "      <td>19</td>\n",
       "      <td>1.287563</td>\n",
       "      <td>-2.121439</td>\n",
       "      <td>0.094504</td>\n",
       "      <td>-0.282201</td>\n",
       "      <td>-0.078991</td>\n",
       "      <td>2.109373</td>\n",
       "      <td>2.325445</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053766</td>\n",
       "      <td>-1.196385</td>\n",
       "      <td>3.572549</td>\n",
       "      <td>0.048290</td>\n",
       "      <td>0.167465</td>\n",
       "      <td>0.071125</td>\n",
       "      <td>0.095814</td>\n",
       "      <td>0.096121</td>\n",
       "      <td>0.111838</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>25.679023</td>\n",
       "      <td>0.328498</td>\n",
       "      <td>12</td>\n",
       "      <td>1.256009</td>\n",
       "      <td>-2.525567</td>\n",
       "      <td>0.109291</td>\n",
       "      <td>-0.185570</td>\n",
       "      <td>-0.066015</td>\n",
       "      <td>1.945332</td>\n",
       "      <td>1.885167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990695</td>\n",
       "      <td>-1.655540</td>\n",
       "      <td>2.811010</td>\n",
       "      <td>0.070494</td>\n",
       "      <td>0.016316</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.096954</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.111802</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>24.267882</td>\n",
       "      <td>0.272414</td>\n",
       "      <td>18</td>\n",
       "      <td>0.838937</td>\n",
       "      <td>-2.525567</td>\n",
       "      <td>0.150805</td>\n",
       "      <td>-0.089829</td>\n",
       "      <td>0.060713</td>\n",
       "      <td>1.550522</td>\n",
       "      <td>1.413614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769227</td>\n",
       "      <td>2.483891</td>\n",
       "      <td>-1.479556</td>\n",
       "      <td>0.184992</td>\n",
       "      <td>0.055043</td>\n",
       "      <td>0.037350</td>\n",
       "      <td>0.096286</td>\n",
       "      <td>0.096844</td>\n",
       "      <td>0.111552</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95537bd-e2cd-432a-8f3f-501800ec5e2e</th>\n",
       "      <td>19.578273</td>\n",
       "      <td>0.274975</td>\n",
       "      <td>20</td>\n",
       "      <td>0.613648</td>\n",
       "      <td>-2.375303</td>\n",
       "      <td>0.157841</td>\n",
       "      <td>-0.074430</td>\n",
       "      <td>0.154899</td>\n",
       "      <td>0.938614</td>\n",
       "      <td>0.785898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651089</td>\n",
       "      <td>1.018994</td>\n",
       "      <td>-0.480505</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.015430</td>\n",
       "      <td>0.053263</td>\n",
       "      <td>0.094895</td>\n",
       "      <td>0.096245</td>\n",
       "      <td>0.111110</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>174.706946</td>\n",
       "      <td>2.034269</td>\n",
       "      <td>13</td>\n",
       "      <td>4.710333</td>\n",
       "      <td>-1.171275</td>\n",
       "      <td>-0.036977</td>\n",
       "      <td>-0.358137</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>6.361396</td>\n",
       "      <td>8.825400</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370133</td>\n",
       "      <td>0.170066</td>\n",
       "      <td>1.647149</td>\n",
       "      <td>1.875171</td>\n",
       "      <td>5.481855</td>\n",
       "      <td>1.933417</td>\n",
       "      <td>0.704383</td>\n",
       "      <td>0.915790</td>\n",
       "      <td>0.668040</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>144.212367</td>\n",
       "      <td>1.930601</td>\n",
       "      <td>12</td>\n",
       "      <td>4.644733</td>\n",
       "      <td>-1.171275</td>\n",
       "      <td>-0.109766</td>\n",
       "      <td>-0.218760</td>\n",
       "      <td>-0.123272</td>\n",
       "      <td>7.321057</td>\n",
       "      <td>6.352910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650892</td>\n",
       "      <td>0.890435</td>\n",
       "      <td>1.774611</td>\n",
       "      <td>0.909478</td>\n",
       "      <td>1.102413</td>\n",
       "      <td>0.801904</td>\n",
       "      <td>0.704768</td>\n",
       "      <td>0.916569</td>\n",
       "      <td>0.668796</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>162.674692</td>\n",
       "      <td>2.030165</td>\n",
       "      <td>9</td>\n",
       "      <td>6.040651</td>\n",
       "      <td>-0.733896</td>\n",
       "      <td>0.023096</td>\n",
       "      <td>-0.104038</td>\n",
       "      <td>-0.148624</td>\n",
       "      <td>7.660468</td>\n",
       "      <td>6.998384</td>\n",
       "      <td>...</td>\n",
       "      <td>1.344519</td>\n",
       "      <td>-0.155398</td>\n",
       "      <td>0.700010</td>\n",
       "      <td>0.355164</td>\n",
       "      <td>0.563702</td>\n",
       "      <td>0.751472</td>\n",
       "      <td>0.705495</td>\n",
       "      <td>0.917298</td>\n",
       "      <td>0.669915</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>195.441310</td>\n",
       "      <td>2.238836</td>\n",
       "      <td>9</td>\n",
       "      <td>6.040651</td>\n",
       "      <td>-0.153889</td>\n",
       "      <td>0.013914</td>\n",
       "      <td>-0.181022</td>\n",
       "      <td>-0.330799</td>\n",
       "      <td>8.089426</td>\n",
       "      <td>8.008158</td>\n",
       "      <td>...</td>\n",
       "      <td>1.546752</td>\n",
       "      <td>-0.042063</td>\n",
       "      <td>0.547227</td>\n",
       "      <td>0.709349</td>\n",
       "      <td>5.324022</td>\n",
       "      <td>0.565444</td>\n",
       "      <td>0.706641</td>\n",
       "      <td>0.918229</td>\n",
       "      <td>0.671376</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>164.124277</td>\n",
       "      <td>2.181733</td>\n",
       "      <td>9</td>\n",
       "      <td>4.764572</td>\n",
       "      <td>-0.196148</td>\n",
       "      <td>0.140554</td>\n",
       "      <td>-0.173421</td>\n",
       "      <td>-0.260175</td>\n",
       "      <td>7.057437</td>\n",
       "      <td>7.147127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758394</td>\n",
       "      <td>-0.540228</td>\n",
       "      <td>0.666558</td>\n",
       "      <td>1.621264</td>\n",
       "      <td>1.817138</td>\n",
       "      <td>1.598413</td>\n",
       "      <td>0.707670</td>\n",
       "      <td>0.919386</td>\n",
       "      <td>0.672535</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>161.177924</td>\n",
       "      <td>2.008431</td>\n",
       "      <td>8</td>\n",
       "      <td>4.764572</td>\n",
       "      <td>-0.320272</td>\n",
       "      <td>0.088199</td>\n",
       "      <td>-0.368958</td>\n",
       "      <td>-0.190405</td>\n",
       "      <td>6.559410</td>\n",
       "      <td>6.942917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890152</td>\n",
       "      <td>-0.463217</td>\n",
       "      <td>1.937756</td>\n",
       "      <td>2.197429</td>\n",
       "      <td>0.970876</td>\n",
       "      <td>2.192644</td>\n",
       "      <td>0.708398</td>\n",
       "      <td>0.919999</td>\n",
       "      <td>0.673441</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>165.546732</td>\n",
       "      <td>2.098827</td>\n",
       "      <td>10</td>\n",
       "      <td>4.785946</td>\n",
       "      <td>-0.320272</td>\n",
       "      <td>0.077667</td>\n",
       "      <td>-0.253053</td>\n",
       "      <td>-0.159623</td>\n",
       "      <td>6.763655</td>\n",
       "      <td>6.988917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702454</td>\n",
       "      <td>-0.486568</td>\n",
       "      <td>1.585320</td>\n",
       "      <td>4.857767</td>\n",
       "      <td>1.843416</td>\n",
       "      <td>1.490158</td>\n",
       "      <td>0.709199</td>\n",
       "      <td>0.921085</td>\n",
       "      <td>0.674431</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>167.727824</td>\n",
       "      <td>2.148309</td>\n",
       "      <td>9</td>\n",
       "      <td>5.005352</td>\n",
       "      <td>-0.054442</td>\n",
       "      <td>0.082726</td>\n",
       "      <td>-0.283284</td>\n",
       "      <td>-0.094782</td>\n",
       "      <td>7.656135</td>\n",
       "      <td>9.416627</td>\n",
       "      <td>...</td>\n",
       "      <td>2.182518</td>\n",
       "      <td>-0.872799</td>\n",
       "      <td>2.988784</td>\n",
       "      <td>0.660001</td>\n",
       "      <td>4.662540</td>\n",
       "      <td>0.867893</td>\n",
       "      <td>0.710225</td>\n",
       "      <td>0.922244</td>\n",
       "      <td>0.675296</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>173.795783</td>\n",
       "      <td>2.086465</td>\n",
       "      <td>8</td>\n",
       "      <td>5.005352</td>\n",
       "      <td>-0.243194</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>-0.181225</td>\n",
       "      <td>-0.089947</td>\n",
       "      <td>7.167809</td>\n",
       "      <td>7.726263</td>\n",
       "      <td>...</td>\n",
       "      <td>1.119260</td>\n",
       "      <td>-0.056762</td>\n",
       "      <td>2.014804</td>\n",
       "      <td>1.015306</td>\n",
       "      <td>2.744248</td>\n",
       "      <td>0.705630</td>\n",
       "      <td>0.710852</td>\n",
       "      <td>0.923435</td>\n",
       "      <td>0.676150</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>171.753082</td>\n",
       "      <td>2.104300</td>\n",
       "      <td>8</td>\n",
       "      <td>5.034086</td>\n",
       "      <td>-0.243194</td>\n",
       "      <td>0.068033</td>\n",
       "      <td>-0.175986</td>\n",
       "      <td>-0.202294</td>\n",
       "      <td>7.337051</td>\n",
       "      <td>7.740092</td>\n",
       "      <td>...</td>\n",
       "      <td>2.185688</td>\n",
       "      <td>-0.336308</td>\n",
       "      <td>0.869952</td>\n",
       "      <td>0.532628</td>\n",
       "      <td>1.574825</td>\n",
       "      <td>0.614661</td>\n",
       "      <td>0.711483</td>\n",
       "      <td>0.924456</td>\n",
       "      <td>0.677396</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>158.309596</td>\n",
       "      <td>1.887261</td>\n",
       "      <td>10</td>\n",
       "      <td>5.034086</td>\n",
       "      <td>-0.852066</td>\n",
       "      <td>-0.152939</td>\n",
       "      <td>-0.326366</td>\n",
       "      <td>-0.379227</td>\n",
       "      <td>7.276090</td>\n",
       "      <td>6.098199</td>\n",
       "      <td>...</td>\n",
       "      <td>1.896821</td>\n",
       "      <td>0.403291</td>\n",
       "      <td>0.860608</td>\n",
       "      <td>1.705025</td>\n",
       "      <td>2.842509</td>\n",
       "      <td>1.595895</td>\n",
       "      <td>0.711849</td>\n",
       "      <td>0.924515</td>\n",
       "      <td>0.678516</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>127.920487</td>\n",
       "      <td>1.542826</td>\n",
       "      <td>10</td>\n",
       "      <td>5.065045</td>\n",
       "      <td>-1.632415</td>\n",
       "      <td>-0.283741</td>\n",
       "      <td>-0.122253</td>\n",
       "      <td>-0.381495</td>\n",
       "      <td>5.670192</td>\n",
       "      <td>4.469017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.743762</td>\n",
       "      <td>0.320459</td>\n",
       "      <td>0.958992</td>\n",
       "      <td>1.213613</td>\n",
       "      <td>1.972874</td>\n",
       "      <td>0.711721</td>\n",
       "      <td>0.923811</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>155.034123</td>\n",
       "      <td>1.960513</td>\n",
       "      <td>6</td>\n",
       "      <td>6.956442</td>\n",
       "      <td>-1.632415</td>\n",
       "      <td>-0.004428</td>\n",
       "      <td>-0.189128</td>\n",
       "      <td>-0.310178</td>\n",
       "      <td>8.004133</td>\n",
       "      <td>8.254092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682129</td>\n",
       "      <td>0.014277</td>\n",
       "      <td>0.609740</td>\n",
       "      <td>1.144503</td>\n",
       "      <td>2.573781</td>\n",
       "      <td>4.409584</td>\n",
       "      <td>0.712524</td>\n",
       "      <td>0.923950</td>\n",
       "      <td>0.680088</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>227.970791</td>\n",
       "      <td>2.476214</td>\n",
       "      <td>9</td>\n",
       "      <td>6.956442</td>\n",
       "      <td>-0.040050</td>\n",
       "      <td>0.318778</td>\n",
       "      <td>-0.036705</td>\n",
       "      <td>-0.185285</td>\n",
       "      <td>10.227979</td>\n",
       "      <td>10.144853</td>\n",
       "      <td>...</td>\n",
       "      <td>1.912333</td>\n",
       "      <td>-1.720471</td>\n",
       "      <td>0.198102</td>\n",
       "      <td>4.116340</td>\n",
       "      <td>2.917375</td>\n",
       "      <td>1.826461</td>\n",
       "      <td>0.714117</td>\n",
       "      <td>0.925663</td>\n",
       "      <td>0.681634</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>180.064493</td>\n",
       "      <td>2.217835</td>\n",
       "      <td>9</td>\n",
       "      <td>5.378116</td>\n",
       "      <td>-0.042907</td>\n",
       "      <td>0.265940</td>\n",
       "      <td>-0.042455</td>\n",
       "      <td>-0.033232</td>\n",
       "      <td>7.967225</td>\n",
       "      <td>9.528860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.316838</td>\n",
       "      <td>-8.002438</td>\n",
       "      <td>1.277534</td>\n",
       "      <td>0.633767</td>\n",
       "      <td>3.401849</td>\n",
       "      <td>0.503329</td>\n",
       "      <td>0.715529</td>\n",
       "      <td>0.927036</td>\n",
       "      <td>0.682261</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>185.480105</td>\n",
       "      <td>2.174055</td>\n",
       "      <td>9</td>\n",
       "      <td>5.519365</td>\n",
       "      <td>-0.292213</td>\n",
       "      <td>0.135828</td>\n",
       "      <td>-0.122633</td>\n",
       "      <td>-0.127544</td>\n",
       "      <td>8.029240</td>\n",
       "      <td>8.823588</td>\n",
       "      <td>...</td>\n",
       "      <td>1.525434</td>\n",
       "      <td>-1.064948</td>\n",
       "      <td>0.961494</td>\n",
       "      <td>0.727502</td>\n",
       "      <td>3.107977</td>\n",
       "      <td>0.311935</td>\n",
       "      <td>0.716580</td>\n",
       "      <td>0.928299</td>\n",
       "      <td>0.683047</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>187.564052</td>\n",
       "      <td>2.160190</td>\n",
       "      <td>10</td>\n",
       "      <td>5.519365</td>\n",
       "      <td>-0.385902</td>\n",
       "      <td>0.087901</td>\n",
       "      <td>-0.195399</td>\n",
       "      <td>-0.313549</td>\n",
       "      <td>6.647920</td>\n",
       "      <td>7.604883</td>\n",
       "      <td>...</td>\n",
       "      <td>1.272215</td>\n",
       "      <td>-0.280341</td>\n",
       "      <td>0.623184</td>\n",
       "      <td>0.983604</td>\n",
       "      <td>4.222937</td>\n",
       "      <td>1.000910</td>\n",
       "      <td>0.717273</td>\n",
       "      <td>0.929442</td>\n",
       "      <td>0.684339</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>161.957236</td>\n",
       "      <td>1.995246</td>\n",
       "      <td>10</td>\n",
       "      <td>5.150901</td>\n",
       "      <td>-0.385902</td>\n",
       "      <td>-0.004895</td>\n",
       "      <td>-0.336119</td>\n",
       "      <td>-0.361105</td>\n",
       "      <td>6.186819</td>\n",
       "      <td>6.988040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909747</td>\n",
       "      <td>0.013557</td>\n",
       "      <td>0.930807</td>\n",
       "      <td>1.364313</td>\n",
       "      <td>4.387073</td>\n",
       "      <td>1.267289</td>\n",
       "      <td>0.717731</td>\n",
       "      <td>0.930017</td>\n",
       "      <td>0.685400</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>172.313488</td>\n",
       "      <td>2.191357</td>\n",
       "      <td>10</td>\n",
       "      <td>4.780944</td>\n",
       "      <td>-0.095693</td>\n",
       "      <td>0.199157</td>\n",
       "      <td>-0.189333</td>\n",
       "      <td>-0.274255</td>\n",
       "      <td>6.736553</td>\n",
       "      <td>7.389647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467694</td>\n",
       "      <td>-0.726174</td>\n",
       "      <td>0.690354</td>\n",
       "      <td>1.007213</td>\n",
       "      <td>0.426647</td>\n",
       "      <td>2.454344</td>\n",
       "      <td>0.718671</td>\n",
       "      <td>0.931346</td>\n",
       "      <td>0.686401</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>174.133524</td>\n",
       "      <td>2.229928</td>\n",
       "      <td>8</td>\n",
       "      <td>4.780944</td>\n",
       "      <td>-0.027506</td>\n",
       "      <td>0.180407</td>\n",
       "      <td>-0.326196</td>\n",
       "      <td>-0.213283</td>\n",
       "      <td>7.217784</td>\n",
       "      <td>8.607992</td>\n",
       "      <td>...</td>\n",
       "      <td>1.732234</td>\n",
       "      <td>-0.845856</td>\n",
       "      <td>1.529400</td>\n",
       "      <td>2.350398</td>\n",
       "      <td>6.570322</td>\n",
       "      <td>1.379112</td>\n",
       "      <td>0.719727</td>\n",
       "      <td>0.932444</td>\n",
       "      <td>0.687487</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>174.703403</td>\n",
       "      <td>2.174722</td>\n",
       "      <td>8</td>\n",
       "      <td>5.669751</td>\n",
       "      <td>-0.126364</td>\n",
       "      <td>0.105942</td>\n",
       "      <td>-0.152201</td>\n",
       "      <td>-0.126684</td>\n",
       "      <td>8.818001</td>\n",
       "      <td>8.349466</td>\n",
       "      <td>...</td>\n",
       "      <td>3.029536</td>\n",
       "      <td>-0.836272</td>\n",
       "      <td>1.201422</td>\n",
       "      <td>1.671807</td>\n",
       "      <td>2.363982</td>\n",
       "      <td>2.267280</td>\n",
       "      <td>0.720543</td>\n",
       "      <td>0.933640</td>\n",
       "      <td>0.688531</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>182.732575</td>\n",
       "      <td>2.129563</td>\n",
       "      <td>8</td>\n",
       "      <td>5.669751</td>\n",
       "      <td>-0.286350</td>\n",
       "      <td>0.119242</td>\n",
       "      <td>-0.152441</td>\n",
       "      <td>-0.055873</td>\n",
       "      <td>7.609710</td>\n",
       "      <td>7.483639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625782</td>\n",
       "      <td>-2.134158</td>\n",
       "      <td>2.728342</td>\n",
       "      <td>0.533419</td>\n",
       "      <td>1.721721</td>\n",
       "      <td>0.946708</td>\n",
       "      <td>0.721355</td>\n",
       "      <td>0.934799</td>\n",
       "      <td>0.689314</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>164.313875</td>\n",
       "      <td>2.062513</td>\n",
       "      <td>8</td>\n",
       "      <td>5.600578</td>\n",
       "      <td>-0.286350</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>-0.301475</td>\n",
       "      <td>-0.147571</td>\n",
       "      <td>8.216850</td>\n",
       "      <td>9.673444</td>\n",
       "      <td>...</td>\n",
       "      <td>3.304506</td>\n",
       "      <td>-0.400360</td>\n",
       "      <td>2.042910</td>\n",
       "      <td>1.140710</td>\n",
       "      <td>4.224669</td>\n",
       "      <td>1.171974</td>\n",
       "      <td>0.722014</td>\n",
       "      <td>0.935823</td>\n",
       "      <td>0.690065</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>166.170952</td>\n",
       "      <td>2.156391</td>\n",
       "      <td>8</td>\n",
       "      <td>7.026222</td>\n",
       "      <td>-0.202192</td>\n",
       "      <td>0.221640</td>\n",
       "      <td>-0.190790</td>\n",
       "      <td>-0.221861</td>\n",
       "      <td>8.619795</td>\n",
       "      <td>7.831939</td>\n",
       "      <td>...</td>\n",
       "      <td>1.106805</td>\n",
       "      <td>-0.999003</td>\n",
       "      <td>0.859953</td>\n",
       "      <td>2.308758</td>\n",
       "      <td>2.231489</td>\n",
       "      <td>1.552026</td>\n",
       "      <td>0.723056</td>\n",
       "      <td>0.937093</td>\n",
       "      <td>0.690755</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>176.232212</td>\n",
       "      <td>2.086583</td>\n",
       "      <td>9</td>\n",
       "      <td>7.026222</td>\n",
       "      <td>-0.387990</td>\n",
       "      <td>0.229198</td>\n",
       "      <td>-0.314173</td>\n",
       "      <td>-0.243869</td>\n",
       "      <td>8.363205</td>\n",
       "      <td>7.947315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721236</td>\n",
       "      <td>-0.939843</td>\n",
       "      <td>1.288287</td>\n",
       "      <td>2.589975</td>\n",
       "      <td>1.046557</td>\n",
       "      <td>1.069738</td>\n",
       "      <td>0.723988</td>\n",
       "      <td>0.938028</td>\n",
       "      <td>0.691221</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>143.491863</td>\n",
       "      <td>1.901088</td>\n",
       "      <td>11</td>\n",
       "      <td>4.037247</td>\n",
       "      <td>-0.900001</td>\n",
       "      <td>0.079543</td>\n",
       "      <td>-0.303523</td>\n",
       "      <td>-0.187880</td>\n",
       "      <td>5.638716</td>\n",
       "      <td>6.890223</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333869</td>\n",
       "      <td>-0.423368</td>\n",
       "      <td>1.615514</td>\n",
       "      <td>0.481381</td>\n",
       "      <td>0.606416</td>\n",
       "      <td>0.664742</td>\n",
       "      <td>0.724168</td>\n",
       "      <td>0.938831</td>\n",
       "      <td>0.691763</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>132.005504</td>\n",
       "      <td>1.682021</td>\n",
       "      <td>12</td>\n",
       "      <td>4.037247</td>\n",
       "      <td>-1.036409</td>\n",
       "      <td>-0.321299</td>\n",
       "      <td>-0.251696</td>\n",
       "      <td>-0.321073</td>\n",
       "      <td>5.155222</td>\n",
       "      <td>6.932017</td>\n",
       "      <td>...</td>\n",
       "      <td>1.845887</td>\n",
       "      <td>1.000706</td>\n",
       "      <td>0.783921</td>\n",
       "      <td>0.728993</td>\n",
       "      <td>1.941200</td>\n",
       "      <td>2.877933</td>\n",
       "      <td>0.723962</td>\n",
       "      <td>0.938472</td>\n",
       "      <td>0.692535</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>132.763077</td>\n",
       "      <td>1.733821</td>\n",
       "      <td>10</td>\n",
       "      <td>4.331709</td>\n",
       "      <td>-1.036409</td>\n",
       "      <td>-0.276156</td>\n",
       "      <td>-0.099563</td>\n",
       "      <td>-0.168561</td>\n",
       "      <td>5.901776</td>\n",
       "      <td>6.832786</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175765</td>\n",
       "      <td>1.638317</td>\n",
       "      <td>0.590665</td>\n",
       "      <td>0.817031</td>\n",
       "      <td>2.174339</td>\n",
       "      <td>0.462822</td>\n",
       "      <td>0.723902</td>\n",
       "      <td>0.938330</td>\n",
       "      <td>0.693261</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>179.366394</td>\n",
       "      <td>2.074326</td>\n",
       "      <td>9</td>\n",
       "      <td>4.698663</td>\n",
       "      <td>-0.895255</td>\n",
       "      <td>0.164444</td>\n",
       "      <td>-0.180317</td>\n",
       "      <td>-0.054230</td>\n",
       "      <td>6.793833</td>\n",
       "      <td>7.132826</td>\n",
       "      <td>...</td>\n",
       "      <td>2.112302</td>\n",
       "      <td>-3.032347</td>\n",
       "      <td>3.325043</td>\n",
       "      <td>0.499238</td>\n",
       "      <td>0.706844</td>\n",
       "      <td>1.523834</td>\n",
       "      <td>0.724576</td>\n",
       "      <td>0.939204</td>\n",
       "      <td>0.694216</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d89558d0-73c8-4fa1-a15c-4b637348088f</th>\n",
       "      <td>171.645626</td>\n",
       "      <td>2.150440</td>\n",
       "      <td>8</td>\n",
       "      <td>5.320833</td>\n",
       "      <td>-0.666705</td>\n",
       "      <td>0.077276</td>\n",
       "      <td>-0.388792</td>\n",
       "      <td>-0.307122</td>\n",
       "      <td>7.105011</td>\n",
       "      <td>7.342416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735574</td>\n",
       "      <td>-0.251614</td>\n",
       "      <td>1.265921</td>\n",
       "      <td>1.322133</td>\n",
       "      <td>3.532371</td>\n",
       "      <td>1.322375</td>\n",
       "      <td>0.725309</td>\n",
       "      <td>0.939918</td>\n",
       "      <td>0.695440</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109472 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fundamental_freq  average_accel  \\\n",
       "healthCode                                                              \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         67.085782       0.954858   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         63.795418       0.934924   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         65.103583       0.931793   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         66.238475       0.946918   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         63.286927       0.927726   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         62.957114       0.909125   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         66.226994       0.934234   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         65.436068       0.958884   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         69.620523       0.984328   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         65.600549       0.956504   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         62.692366       0.915588   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         64.653065       0.910956   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         63.594047       0.924236   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         68.210807       0.932986   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         60.632964       0.890667   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         60.546090       0.874371   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         59.790683       0.855578   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         57.360890       0.831971   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         58.154674       0.830002   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         55.315161       0.794198   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         52.780136       0.753188   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         52.894673       0.711603   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         46.761131       0.618119   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         37.631491       0.511707   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         44.106746       0.569364   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         44.843415       0.611570   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         35.471330       0.466006   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         25.679023       0.328498   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         24.267882       0.272414   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         19.578273       0.274975   \n",
       "...                                                ...            ...   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        174.706946       2.034269   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        144.212367       1.930601   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        162.674692       2.030165   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        195.441310       2.238836   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        164.124277       2.181733   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        161.177924       2.008431   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        165.546732       2.098827   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        167.727824       2.148309   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        173.795783       2.086465   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        171.753082       2.104300   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        158.309596       1.887261   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        127.920487       1.542826   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        155.034123       1.960513   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        227.970791       2.476214   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        180.064493       2.217835   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        185.480105       2.174055   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        187.564052       2.160190   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        161.957236       1.995246   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        172.313488       2.191357   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        174.133524       2.229928   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        174.703403       2.174722   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        182.732575       2.129563   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        164.313875       2.062513   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        166.170952       2.156391   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        176.232212       2.086583   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        143.491863       1.901088   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        132.005504       1.682021   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        132.763077       1.733821   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        179.366394       2.074326   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f        171.645626       2.150440   \n",
       "\n",
       "                                      peakcount       max       min     mut_x  \\\n",
       "healthCode                                                                      \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         14  1.264397 -0.289971 -0.534878   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         13  1.138931 -0.253882 -0.506954   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         13  1.138931 -0.330068 -0.499181   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         11  1.111950 -0.330068 -0.509581   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         10  1.111950 -0.305990 -0.480510   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         12  1.092683 -0.379909 -0.476771   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         12  1.148762 -0.379909 -0.510586   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e          9  1.148762 -0.217064 -0.534148   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         11  1.249605 -0.217064 -0.560564   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e          6  1.249605 -0.200400 -0.527813   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         10  1.043506 -0.155986 -0.476333   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         11  1.058875 -0.395313 -0.464231   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         11  1.107832 -0.395313 -0.471030   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         12  1.120446 -0.359916 -0.491304   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         13  1.120446 -0.392977 -0.443334   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         15  1.061445 -0.392977 -0.414754   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         14  1.061445 -0.384322 -0.391439   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         10  1.013798 -0.335147 -0.353427   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e          9  1.162445 -0.437504 -0.367034   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         10  1.162445 -0.502105 -0.326042   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         11  1.030213 -0.502105 -0.282951   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         14  1.174667 -1.471883 -0.249338   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         19  1.174667 -1.755507 -0.050172   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         25  0.918106 -3.284295  0.170182   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         24  1.161511 -3.284295  0.207179   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         23  1.287563 -1.774269  0.137964   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         19  1.287563 -2.121439  0.094504   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         12  1.256009 -2.525567  0.109291   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         18  0.838937 -2.525567  0.150805   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e         20  0.613648 -2.375303  0.157841   \n",
       "...                                         ...       ...       ...       ...   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f         13  4.710333 -1.171275 -0.036977   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f         12  4.644733 -1.171275 -0.109766   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          9  6.040651 -0.733896  0.023096   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          9  6.040651 -0.153889  0.013914   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          9  4.764572 -0.196148  0.140554   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          8  4.764572 -0.320272  0.088199   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f         10  4.785946 -0.320272  0.077667   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          9  5.005352 -0.054442  0.082726   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          8  5.005352 -0.243194  0.005106   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          8  5.034086 -0.243194  0.068033   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f         10  5.034086 -0.852066 -0.152939   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f         10  5.065045 -1.632415 -0.283741   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          6  6.956442 -1.632415 -0.004428   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          9  6.956442 -0.040050  0.318778   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          9  5.378116 -0.042907  0.265940   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          9  5.519365 -0.292213  0.135828   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f         10  5.519365 -0.385902  0.087901   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f         10  5.150901 -0.385902 -0.004895   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f         10  4.780944 -0.095693  0.199157   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          8  4.780944 -0.027506  0.180407   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          8  5.669751 -0.126364  0.105942   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          8  5.669751 -0.286350  0.119242   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          8  5.600578 -0.286350  0.059082   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          8  7.026222 -0.202192  0.221640   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          9  7.026222 -0.387990  0.229198   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f         11  4.037247 -0.900001  0.079543   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f         12  4.037247 -1.036409 -0.321299   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f         10  4.331709 -1.036409 -0.276156   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          9  4.698663 -0.895255  0.164444   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f          8  5.320833 -0.666705  0.077276   \n",
       "\n",
       "                                         mut_y     mut_z      muf_x  \\\n",
       "healthCode                                                            \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.069511 -0.771628   0.944891   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.103759 -0.766953   0.916676   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.082214 -0.769834   0.859019   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.053556 -0.783584   0.945719   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.057301 -0.780704   0.928506   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.055130 -0.762466   0.874466   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.047011 -0.773262   0.850504   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.046814 -0.789749   0.820175   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.044535 -0.798351   0.920737   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.003825 -0.788620   0.849760   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.037848 -0.779430   0.693798   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.051783 -0.778352   0.774116   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.064635 -0.784763   0.968877   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.041242 -0.784748   0.850870   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.001585 -0.763810   0.830313   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.002267 -0.758657   0.848571   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.022985 -0.748136   0.915272   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.025571 -0.741990   0.738707   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.026064 -0.731961   0.701466   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.006285 -0.704335   0.804711   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.024918 -0.682193   0.748362   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.036152 -0.624678   1.386751   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.248194 -0.285224   1.511354   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.180029 -0.063882   1.620267   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.057366 -0.198674   1.882485   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.201438 -0.147749   2.219901   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.282201 -0.078991   2.109373   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.185570 -0.066015   1.945332   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.089829  0.060713   1.550522   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.074430  0.154899   0.938614   \n",
       "...                                        ...       ...        ...   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.358137 -0.217428   6.361396   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.218760 -0.123272   7.321057   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.104038 -0.148624   7.660468   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.181022 -0.330799   8.089426   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.173421 -0.260175   7.057437   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.368958 -0.190405   6.559410   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.253053 -0.159623   6.763655   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.283284 -0.094782   7.656135   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.181225 -0.089947   7.167809   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.175986 -0.202294   7.337051   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.326366 -0.379227   7.276090   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.122253 -0.381495   5.670192   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.189128 -0.310178   8.004133   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.036705 -0.185285  10.227979   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.042455 -0.033232   7.967225   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.122633 -0.127544   8.029240   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.195399 -0.313549   6.647920   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.336119 -0.361105   6.186819   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.189333 -0.274255   6.736553   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.326196 -0.213283   7.217784   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.152201 -0.126684   8.818001   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.152441 -0.055873   7.609710   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.301475 -0.147571   8.216850   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.190790 -0.221861   8.619795   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.314173 -0.243869   8.363205   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.303523 -0.187880   5.638716   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.251696 -0.321073   5.155222   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.099563 -0.168561   5.901776   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.180317 -0.054230   6.793833   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f -0.388792 -0.307122   7.105011   \n",
       "\n",
       "                                          muf_y   ...      medf_z  cross_xz  \\\n",
       "healthCode                                        ...                         \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.738003   ...    0.174295  0.693181   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.501419   ...    0.172362  0.660998   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.494451   ...    0.166739  0.648426   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.445917   ...    0.040059  0.650320   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.574811   ...    0.150732  0.615483   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.415136   ...    0.186134  0.625301   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.363455   ...    0.102905  0.660302   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.359124   ...    0.049214  0.676352   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.411789   ...    0.048028  0.702152   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.443316   ...    0.106975  0.669287   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.283654   ...    0.041018  0.611130   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.289797   ...    0.071172  0.596429   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.434174   ...    0.135187  0.600220   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.397725   ...    0.068432  0.626066   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.374351   ...    0.145532  0.580425   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.407986   ...    0.027377  0.546694   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.411247   ...    0.112565  0.523219   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.494519   ...    0.027193  0.476323   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.515345   ...    0.032848  0.501439   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.496162   ...    0.110738  0.462908   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.488581   ...    0.046876  0.414767   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   1.086806   ...    0.585580  0.399146   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   1.585861   ...    0.615039  0.175905   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   1.855273   ...    0.349716 -2.664000   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   1.867747   ...    0.660298 -1.042808   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   2.274327   ...    0.673942 -0.933773   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   2.325445   ...    1.053766 -1.196385   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   1.885167   ...    0.990695 -1.655540   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   1.413614   ...    0.769227  2.483891   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e   0.785898   ...    0.651089  1.018994   \n",
       "...                                         ...   ...         ...       ...   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   8.825400   ...    1.370133  0.170066   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   6.352910   ...    0.650892  0.890435   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   6.998384   ...    1.344519 -0.155398   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   8.008158   ...    1.546752 -0.042063   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   7.147127   ...    0.758394 -0.540228   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   6.942917   ...    0.890152 -0.463217   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   6.988917   ...    0.702454 -0.486568   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   9.416627   ...    2.182518 -0.872799   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   7.726263   ...    1.119260 -0.056762   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   7.740092   ...    2.185688 -0.336308   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   6.098199   ...    1.896821  0.403291   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   4.469017   ...    0.684375  0.743762   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   8.254092   ...    0.682129  0.014277   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  10.144853   ...    1.912333 -1.720471   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   9.528860   ...    1.316838 -8.002438   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   8.823588   ...    1.525434 -1.064948   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   7.604883   ...    1.272215 -0.280341   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   6.988040   ...    0.909747  0.013557   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   7.389647   ...    0.467694 -0.726174   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   8.607992   ...    1.732234 -0.845856   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   8.349466   ...    3.029536 -0.836272   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   7.483639   ...    0.625782 -2.134158   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   9.673444   ...    3.304506 -0.400360   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   7.831939   ...    1.106805 -0.999003   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   7.947315   ...    0.721236 -0.939843   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   6.890223   ...    1.333869 -0.423368   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   6.932017   ...    1.845887  1.000706   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   6.832786   ...    1.175765  1.638317   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   7.132826   ...    2.112302 -3.032347   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f   7.342416   ...    0.735574 -0.251614   \n",
       "\n",
       "                                      cross_yz  spect_cent_x  spect_cent_y  \\\n",
       "healthCode                                                                   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.090084      0.238413      0.027467   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.135288      0.314994      0.012541   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.106794      0.271671      0.023342   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.068347      0.241556      0.007254   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.073397      0.256973      0.011995   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.072305      0.146630      0.011684   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.060796      0.395388      0.005775   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.059277      0.198089      0.006052   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.055784      0.362078      0.002558   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.004851      0.236350      0.019285   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.048559      0.265534      0.001021   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.066529      0.218246      0.002419   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.082363      0.325600      0.014517   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.052554      0.211159      0.004213   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.002076      0.163394      0.011204   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.002988      0.192699      0.001123   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.030723      0.161024      0.005927   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.034462      0.147918      0.006186   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.035609      0.040231      0.005279   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.008924      0.119833      0.002141   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.036526      0.092451      0.001302   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.057872      0.194690      0.056801   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.870170      0.210071      0.020674   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -2.818149      0.046273      0.175368   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  0.288746      0.285638      0.073846   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  1.363385      0.009544      0.086704   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  3.572549      0.048290      0.167465   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  2.811010      0.070494      0.016316   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -1.479556      0.184992      0.055043   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e -0.480505      0.005138      0.015430   \n",
       "...                                        ...           ...           ...   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  1.647149      1.875171      5.481855   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  1.774611      0.909478      1.102413   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.700010      0.355164      0.563702   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.547227      0.709349      5.324022   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.666558      1.621264      1.817138   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  1.937756      2.197429      0.970876   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  1.585320      4.857767      1.843416   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  2.988784      0.660001      4.662540   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  2.014804      1.015306      2.744248   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.869952      0.532628      1.574825   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.860608      1.705025      2.842509   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.320459      0.958992      1.213613   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.609740      1.144503      2.573781   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.198102      4.116340      2.917375   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  1.277534      0.633767      3.401849   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.961494      0.727502      3.107977   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.623184      0.983604      4.222937   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.930807      1.364313      4.387073   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.690354      1.007213      0.426647   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  1.529400      2.350398      6.570322   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  1.201422      1.671807      2.363982   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  2.728342      0.533419      1.721721   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  2.042910      1.140710      4.224669   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.859953      2.308758      2.231489   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  1.288287      2.589975      1.046557   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  1.615514      0.481381      0.606416   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.783921      0.728993      1.941200   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  0.590665      0.817031      2.174339   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  3.325043      0.499238      0.706844   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f  1.265921      1.322133      3.532371   \n",
       "\n",
       "                                      spect_cent_z  average_dist_meanx  \\\n",
       "healthCode                                                               \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      1.127965            0.076262   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.373424            0.072738   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.681087            0.067990   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.797826            0.070011   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.323727            0.071155   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.792151            0.068916   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.632894            0.068502   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.478479            0.067823   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.568121            0.065979   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.376152            0.065443   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.659814            0.062251   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.612663            0.061782   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.750520            0.063319   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.766621            0.063790   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.452960            0.063791   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.591684            0.064051   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.758911            0.064786   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.598078            0.063991   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.594211            0.062993   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.603580            0.063918   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.568530            0.064036   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.490418            0.066443   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.527406            0.072911   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.020392            0.077946   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.061787            0.085492   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.116680            0.092395   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.071125            0.095814   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.014799            0.096954   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.037350            0.096286   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e      0.053263            0.094895   \n",
       "...                                            ...                 ...   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.933417            0.704383   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      0.801904            0.704768   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      0.751472            0.705495   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      0.565444            0.706641   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.598413            0.707670   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      2.192644            0.708398   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.490158            0.709199   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      0.867893            0.710225   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      0.705630            0.710852   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      0.614661            0.711483   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.595895            0.711849   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.972874            0.711721   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      4.409584            0.712524   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.826461            0.714117   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      0.503329            0.715529   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      0.311935            0.716580   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.000910            0.717273   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.267289            0.717731   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      2.454344            0.718671   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.379112            0.719727   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      2.267280            0.720543   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      0.946708            0.721355   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.171974            0.722014   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.552026            0.723056   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.069738            0.723988   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      0.664742            0.724168   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      2.877933            0.723962   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      0.462822            0.723902   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.523834            0.724576   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f      1.322375            0.725309   \n",
       "\n",
       "                                      average_dist_meany  average_dist_meanz  \\\n",
       "healthCode                                                                     \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.075348            0.095569   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.069466            0.088834   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.068576            0.092119   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.067201            0.092783   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.066718            0.090758   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.064779            0.090519   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.062522            0.088770   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.060693            0.085879   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.059962            0.085895   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.058832            0.084310   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.056025            0.078660   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.054715            0.075319   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.054911            0.075436   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.054852            0.075310   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.054894            0.075121   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.055479            0.075558   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.056283            0.075330   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.057532            0.075354   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.058459            0.076930   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.059872            0.078990   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.060780            0.079731   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.062564            0.082444   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.069775            0.092801   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.078599            0.097122   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.084775            0.103727   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.092359            0.110029   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.096121            0.111838   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.096645            0.111802   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.096844            0.111552   \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e            0.096245            0.111110   \n",
       "...                                                  ...                 ...   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.915790            0.668040   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.916569            0.668796   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.917298            0.669915   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.918229            0.671376   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.919386            0.672535   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.919999            0.673441   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.921085            0.674431   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.922244            0.675296   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.923435            0.676150   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.924456            0.677396   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.924515            0.678516   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.923811            0.679012   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.923950            0.680088   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.925663            0.681634   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.927036            0.682261   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.928299            0.683047   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.929442            0.684339   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.930017            0.685400   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.931346            0.686401   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.932444            0.687487   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.933640            0.688531   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.934799            0.689314   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.935823            0.690065   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.937093            0.690755   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.938028            0.691221   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.938831            0.691763   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.938472            0.692535   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.938330            0.693261   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.939204            0.694216   \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f            0.939918            0.695440   \n",
       "\n",
       "                                         sex  \n",
       "healthCode                                    \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "a95537bd-e2cd-432a-8f3f-501800ec5e2e  Female  \n",
       "...                                      ...  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "d89558d0-73c8-4fa1-a15c-4b637348088f    Male  \n",
       "\n",
       "[109472 rows x 26 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tengaps_total = tengaps_total[tengaps_total.weight < 400]\n",
    "tengaps_total = tengaps_total[tengaps_total.weight > 80]\n",
    "\n",
    "# this dataframe doesn't have demographic data\n",
    "tengaps_no_demog = tengaps_total.drop(columns=['sex', 'currentAge', 'weight', 'height'])\n",
    "\n",
    "# Inserts sex into \n",
    "\n",
    "#tengaps_no_demog.insert(25, 'currentAge', tengaps_total.currentAge.values)\n",
    "#tengaps_no_demog.insert(26, 'weight', tengaps_total.weight.values)\n",
    "#tengaps_no_demog.insert(27, 'height', tengaps_total.height.values)\n",
    "tengaps_no_demog.insert(25, 'sex', tengaps_total.sex.values)\n",
    "tengaps_no_demog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell is dedicated to creating a balanced class training set\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numOfTotalHC = 311\n",
    "numOfTrainHC = 217\n",
    "numOfTestHC = 94\n",
    "\n",
    "training = tengaps_no_demog.iloc[0:(numOfTrainHC * find_lowest_num_samples(tengaps_no_demog))]\n",
    "testing = tengaps_no_demog.iloc[(numOfTrainHC * find_lowest_num_samples(tengaps_no_demog)):]\n",
    "\n",
    "female_train = training.loc[training['sex'] == 'Female']\n",
    "male_train = training.loc[training['sex'] == 'Male']\n",
    "choppedmale_train = male_train.iloc[0:17000]\n",
    "\n",
    "Xmale = np.array(choppedmale_train.iloc[:, 0:25])\n",
    "Xfemale = np.array(female_train.iloc[:, 0:25])\n",
    "X_scaledmale = preprocessing.scale(Xmale)\n",
    "X_scaledfemale = preprocessing.scale(Xfemale)\n",
    "\n",
    "X_scaledtotal = np.array(list(X_scaledmale)+list(X_scaledfemale))\n",
    "y_total = np.array(list(choppedmale_train.iloc[:, 25]) + list(female_train.iloc[:, 25]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaledtotal, y_total, test_size=0.33, random_state=42)\n",
    "\n",
    "X_mixedequal = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixedequal = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "# Binary encoding\n",
    "male_zero = [1 if x=='Female' else 0 for x in y_mixedequal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  25.1s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  25.4s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  25.9s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  25.9s\n",
      "[CV]  n_estimators=10, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=True, total=  25.9s\n",
      "[CV] n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  3.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=52, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total= 3.4min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.5min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.5min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.5min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.5min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total= 3.5min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 2.0min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 2.0min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 2.0min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 2.0min\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total= 2.0min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.6min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  16.3s\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  16.1s\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.5min\n",
      "[CV] n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.5min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.5min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 5.6min\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  17.0s\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  17.3s\n",
      "[CV] n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=10, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=  17.3s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 6.2min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 5.9min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 6.0min\n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 6.0min\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=False, total= 6.0min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.3min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV] n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=115, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total= 4.2min\n",
      "[CV] n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False, total= 1.8min\n",
      "[CV] n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False, total= 1.7min\n",
      "[CV] n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False, total= 1.7min\n",
      "[CV] n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False, total= 1.7min\n",
      "[CV] n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=31, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=20, bootstrap=False, total= 1.7min\n",
      "[CV] n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 7.2min\n",
      "[CV] n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 7.1min\n",
      "[CV] n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False, total= 4.0min\n",
      "[CV] n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False, total= 3.9min\n",
      "[CV] n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=11.8min\n",
      "[CV] n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True, total= 3.3min\n",
      "[CV] n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False, total= 4.1min\n",
      "[CV] n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False, total= 4.1min\n",
      "[CV] n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=73, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=False, total= 4.0min\n",
      "[CV] n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 6.9min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 6.9min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=True, total= 6.9min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True, total= 3.3min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=11.6min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=11.7min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=11.7min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=11.7min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True, total= 3.4min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=True, total= 3.5min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False, total= 6.7min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 3.3min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False, total= 6.7min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total= 5.5min\n",
      "[CV] n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total= 5.4min\n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total= 5.5min\n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False, total= 6.6min\n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False, total= 6.6min\n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=115, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=70, bootstrap=False, total= 6.7min\n",
      "[CV] n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total= 5.5min\n",
      "[CV] n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total= 5.4min\n",
      "[CV] n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True, total= 1.7min\n",
      "[CV] n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True, total= 1.7min\n",
      "[CV] n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True, total= 1.7min\n",
      "[CV] n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True, total= 1.7min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=52, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=70, bootstrap=True, total= 1.7min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False, total= 8.6min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False, total= 8.7min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False, total= 8.8min\n",
      "[CV] n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 3.1min\n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 3.1min\n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 3.2min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False, total= 8.6min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=110, bootstrap=False, total= 8.6min\n",
      "[CV]  n_estimators=94, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total= 3.0min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True, total= 3.5min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True, total= 3.5min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True, total= 3.3min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True, total= 3.3min\n",
      "[CV]  n_estimators=157, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=None, bootstrap=True, total= 3.2min\n",
      "[CV]  n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False, total= 6.2min\n",
      "[CV]  n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False, total= 5.8min\n",
      "[CV]  n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False, total= 4.9min\n",
      "[CV]  n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False, total= 4.9min\n",
      "[CV]  n_estimators=178, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=30, bootstrap=False, total= 4.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 29.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [10, 31, 52, 73, 94, 115, 136, 157, 178, 200], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "dsrf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = dsrf, param_distributions = random_grid, n_iter = 20, scoring='roc_auc', cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_mixedequal, male_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 30,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 178}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=178, n_jobs=1,\n",
       "            oob_score=False, random_state=22, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrf = RandomForestClassifier(n_estimators=178, max_depth=30, min_samples_split=2, min_samples_leaf=2, bootstrap=False, random_state=22)\n",
    "dsrf.fit(X_mixedequal, male_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_labels = [1 if x=='Female' else 0 for x in testing.iloc[:, 25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_female = []\n",
    "for y in total_labels:\n",
    "    if y == 1:\n",
    "        more_female.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_male = []\n",
    "for y in total_labels:\n",
    "    if y == 0:\n",
    "        more_male.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_test = testing.loc[testing['sex'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_test = testing.loc[testing['sex'] == 'Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33088"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33088"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6808510638297872"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22528/33088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6503264023210832"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrf.score(testing.iloc[:, 0:25], total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2046"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dsrf.predict(female_test.iloc[:, 0:25])).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.7340824, 0.2659176]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.65917603, 0.34082397]),\n",
       " array([0.38576779, 0.61423221]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.67790262, 0.32209738]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.6835206, 0.3164794]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.68913858, 0.31086142]),\n",
       " array([0.67509363, 0.32490637]),\n",
       " array([0.667603, 0.332397]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.74812734, 0.25187266]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.68820225, 0.31179775]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.6835206, 0.3164794]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.69756554, 0.30243446]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.67228464, 0.32771536]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.67977528, 0.32022472]),\n",
       " array([0.68820225, 0.31179775]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.66385768, 0.33614232]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.71910112, 0.28089888]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.71910112, 0.28089888]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.74625468, 0.25374532]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.65168539, 0.34831461]),\n",
       " array([0.64700375, 0.35299625]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.53370787, 0.46629213]),\n",
       " array([0.66104869, 0.33895131]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.417603, 0.582397]),\n",
       " array([0.37172285, 0.62827715]),\n",
       " array([0.38389513, 0.61610487]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.75561798, 0.24438202]),\n",
       " array([0.76966292, 0.23033708]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.74438202, 0.25561798]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.77434457, 0.22565543]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.68632959, 0.31367041]),\n",
       " array([0.74344569, 0.25655431]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.73970037, 0.26029963]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.69756554, 0.30243446]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.71254682, 0.28745318]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.75187266, 0.24812734]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.7659176, 0.2340824]),\n",
       " array([0.75, 0.25]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.74812734, 0.25187266]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.74250936, 0.25749064]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.68258427, 0.31741573]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.73970037, 0.26029963]),\n",
       " array([0.74250936, 0.25749064]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.69756554, 0.30243446]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.77902622, 0.22097378]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.75, 0.25]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.6741573, 0.3258427]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.73689139, 0.26310861]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.74906367, 0.25093633]),\n",
       " array([0.75093633, 0.24906367]),\n",
       " array([0.75374532, 0.24625468]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.74906367, 0.25093633]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.74906367, 0.25093633]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.74812734, 0.25187266]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.75749064, 0.24250936]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.73689139, 0.26310861]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.4082397, 0.5917603]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.67696629, 0.32303371]),\n",
       " array([0.68820225, 0.31179775]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.52996255, 0.47003745]),\n",
       " array([0.56273408, 0.43726592]),\n",
       " array([0.59644195, 0.40355805]),\n",
       " array([0.58988764, 0.41011236]),\n",
       " array([0.58988764, 0.41011236]),\n",
       " array([0.57677903, 0.42322097]),\n",
       " array([0.58707865, 0.41292135]),\n",
       " array([0.61423221, 0.38576779]),\n",
       " array([0.5917603, 0.4082397]),\n",
       " array([0.57397004, 0.42602996]),\n",
       " array([0.44194757, 0.55805243]),\n",
       " array([0.53838951, 0.46161049]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.74344569, 0.25655431]),\n",
       " array([0.49812734, 0.50187266]),\n",
       " array([0.51685393, 0.48314607]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.49812734, 0.50187266]),\n",
       " array([0.50749064, 0.49250936]),\n",
       " array([0.5411985, 0.4588015]),\n",
       " array([0.62921348, 0.37078652]),\n",
       " array([0.65543071, 0.34456929]),\n",
       " array([0.6329588, 0.3670412]),\n",
       " array([0.56367041, 0.43632959]),\n",
       " array([0.56086142, 0.43913858]),\n",
       " array([0.57490637, 0.42509363]),\n",
       " array([0.44101124, 0.55898876]),\n",
       " array([0.3988764, 0.6011236]),\n",
       " array([0.39419476, 0.60580524]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.62921348, 0.37078652]),\n",
       " array([0.68913858, 0.31086142]),\n",
       " array([0.65355805, 0.34644195]),\n",
       " array([0.64606742, 0.35393258]),\n",
       " array([0.63014981, 0.36985019]),\n",
       " array([0.66011236, 0.33988764]),\n",
       " array([0.67134831, 0.32865169]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.66385768, 0.33614232]),\n",
       " array([0.66011236, 0.33988764]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.66947566, 0.33052434]),\n",
       " array([0.64419476, 0.35580524]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.67977528, 0.32022472]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.667603, 0.332397]),\n",
       " array([0.68913858, 0.31086142]),\n",
       " array([0.65543071, 0.34456929]),\n",
       " array([0.62546816, 0.37453184]),\n",
       " array([0.67696629, 0.32303371]),\n",
       " array([0.66947566, 0.33052434]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.66573034, 0.33426966]),\n",
       " array([0.66479401, 0.33520599]),\n",
       " array([0.66198502, 0.33801498]),\n",
       " array([0.667603, 0.332397]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.667603, 0.332397]),\n",
       " array([0.66479401, 0.33520599]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.67696629, 0.32303371]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.68632959, 0.31367041]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.6488764, 0.3511236]),\n",
       " array([0.65730337, 0.34269663]),\n",
       " array([0.6582397, 0.3417603]),\n",
       " array([0.66104869, 0.33895131]),\n",
       " array([0.66011236, 0.33988764]),\n",
       " array([0.6835206, 0.3164794]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.71254682, 0.28745318]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.75749064, 0.24250936]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.68632959, 0.31367041]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.68820225, 0.31179775]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.71910112, 0.28089888]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.75, 0.25]),\n",
       " array([0.81928839, 0.18071161]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.69475655, 0.30524345]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.68632959, 0.31367041]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.76404494, 0.23595506]),\n",
       " array([0.75749064, 0.24250936]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.76872659, 0.23127341]),\n",
       " array([0.82303371, 0.17696629]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.76310861, 0.23689139]),\n",
       " array([0.76310861, 0.23689139]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.65730337, 0.34269663]),\n",
       " array([0.65168539, 0.34831461]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.69756554, 0.30243446]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.74344569, 0.25655431]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.75749064, 0.24250936]),\n",
       " array([0.78277154, 0.21722846]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.74625468, 0.25374532]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.74438202, 0.25561798]),\n",
       " array([0.76966292, 0.23033708]),\n",
       " array([0.66573034, 0.33426966]),\n",
       " array([0.76217228, 0.23782772]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.73970037, 0.26029963]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.75280899, 0.24719101]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.80524345, 0.19475655]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.74812734, 0.25187266]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.80898876, 0.19101124]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.75093633, 0.24906367]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.77902622, 0.22097378]),\n",
       " array([0.67134831, 0.32865169]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.76310861, 0.23689139]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.73033708, 0.26966292]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.75187266, 0.24812734]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.75374532, 0.24625468]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.8164794, 0.1835206]),\n",
       " array([0.75374532, 0.24625468]),\n",
       " array([0.64794007, 0.35205993]),\n",
       " array([0.65730337, 0.34269663]),\n",
       " array([0.82022472, 0.17977528]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.78838951, 0.21161049]),\n",
       " array([0.76217228, 0.23782772]),\n",
       " array([0.76404494, 0.23595506]),\n",
       " array([0.68258427, 0.31741573]),\n",
       " array([0.77996255, 0.22003745]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.75093633, 0.24906367]),\n",
       " array([0.79307116, 0.20692884]),\n",
       " array([0.67977528, 0.32022472]),\n",
       " array([0.78651685, 0.21348315]),\n",
       " array([0.79494382, 0.20505618]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.71910112, 0.28089888]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.70131086, 0.29868914]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.74812734, 0.25187266]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.75280899, 0.24719101]),\n",
       " array([0.76404494, 0.23595506]),\n",
       " array([0.74906367, 0.25093633]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.75, 0.25]),\n",
       " array([0.76966292, 0.23033708]),\n",
       " array([0.80524345, 0.19475655]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.38576779, 0.61423221]),\n",
       " array([0.53558052, 0.46441948]),\n",
       " array([0.55805243, 0.44194757]),\n",
       " array([0.50842697, 0.49157303]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.51779026, 0.48220974]),\n",
       " array([0.50187266, 0.49812734]),\n",
       " array([0.52153558, 0.47846442]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.52434457, 0.47565543]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.51498127, 0.48501873]),\n",
       " array([0.51310861, 0.48689139]),\n",
       " array([0.51310861, 0.48689139]),\n",
       " array([0.50468165, 0.49531835]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.52996255, 0.47003745]),\n",
       " array([0.52715356, 0.47284644]),\n",
       " array([0.52059925, 0.47940075]),\n",
       " array([0.49719101, 0.50280899]),\n",
       " array([0.50374532, 0.49625468]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.52996255, 0.47003745]),\n",
       " array([0.52621723, 0.47378277]),\n",
       " array([0.40636704, 0.59363296]),\n",
       " array([0.40168539, 0.59831461]),\n",
       " array([0.38576779, 0.61423221]),\n",
       " array([0.49438202, 0.50561798]),\n",
       " array([0.51872659, 0.48127341]),\n",
       " array([0.51029963, 0.48970037]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.49625468, 0.50374532]),\n",
       " array([0.50749064, 0.49250936]),\n",
       " array([0.52434457, 0.47565543]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.50374532, 0.49625468]),\n",
       " array([0.47191011, 0.52808989]),\n",
       " array([0.4494382, 0.5505618]),\n",
       " array([0.43726592, 0.56273408]),\n",
       " array([0.41292135, 0.58707865]),\n",
       " array([0.44850187, 0.55149813]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.50093633, 0.49906367]),\n",
       " array([0.47846442, 0.52153558]),\n",
       " array([0.49250936, 0.50749064]),\n",
       " array([0.49157303, 0.50842697]),\n",
       " array([0.45318352, 0.54681648]),\n",
       " array([0.42322097, 0.57677903]),\n",
       " array([0.43164794, 0.56835206]),\n",
       " array([0.46067416, 0.53932584]),\n",
       " array([0.42228464, 0.57771536]),\n",
       " array([0.42041199, 0.57958801]),\n",
       " array([0.46441948, 0.53558052]),\n",
       " array([0.48127341, 0.51872659]),\n",
       " array([0.52621723, 0.47378277]),\n",
       " array([0.55243446, 0.44756554]),\n",
       " array([0.52621723, 0.47378277]),\n",
       " array([0.51685393, 0.48314607]),\n",
       " array([0.50187266, 0.49812734]),\n",
       " array([0.52247191, 0.47752809]),\n",
       " array([0.52153558, 0.47846442]),\n",
       " array([0.50468165, 0.49531835]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.52434457, 0.47565543]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.6170412, 0.3829588]),\n",
       " array([0.63670412, 0.36329588]),\n",
       " array([0.67041199, 0.32958801]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.66479401, 0.33520599]),\n",
       " array([0.667603, 0.332397]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.66479401, 0.33520599]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.6741573, 0.3258427]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.75468165, 0.24531835]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.70973783, 0.29026217]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.76966292, 0.23033708]),\n",
       " array([0.76872659, 0.23127341]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.75280899, 0.24719101]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.78370787, 0.21629213]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.71067416, 0.28932584]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.74719101, 0.25280899]),\n",
       " array([0.72846442, 0.27153558]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.7406367, 0.2593633]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.79962547, 0.20037453]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.76404494, 0.23595506]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.71254682, 0.28745318]),\n",
       " array([0.70411985, 0.29588015]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.73501873, 0.26498127]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.71254682, 0.28745318]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.69382022, 0.30617978]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.71348315, 0.28651685]),\n",
       " array([0.73595506, 0.26404494]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.74438202, 0.25561798]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.7088015, 0.2911985]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.80524345, 0.19475655]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.76498127, 0.23501873]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.72659176, 0.27340824]),\n",
       " array([0.72284644, 0.27715356]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.76779026, 0.23220974]),\n",
       " array([0.73876404, 0.26123596]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.72940075, 0.27059925]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.74531835, 0.25468165]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.72097378, 0.27902622]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.73314607, 0.26685393]),\n",
       " array([0.73127341, 0.26872659]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.7247191, 0.2752809]),\n",
       " array([0.72752809, 0.27247191]),\n",
       " array([0.76310861, 0.23689139]),\n",
       " array([0.75374532, 0.24625468]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.77247191, 0.22752809]),\n",
       " array([0.76498127, 0.23501873]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.67790262, 0.32209738]),\n",
       " array([0.53838951, 0.46161049]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.51779026, 0.48220974]),\n",
       " array([0.53277154, 0.46722846]),\n",
       " array([0.50655431, 0.49344569]),\n",
       " array([0.52059925, 0.47940075]),\n",
       " array([0.51872659, 0.48127341]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.5411985, 0.4588015]),\n",
       " array([0.52715356, 0.47284644]),\n",
       " array([0.54213483, 0.45786517]),\n",
       " array([0.63951311, 0.36048689]),\n",
       " array([0.65074906, 0.34925094]),\n",
       " array([0.65355805, 0.34644195]),\n",
       " array([0.52715356, 0.47284644]),\n",
       " array([0.5159176, 0.4840824]),\n",
       " array([0.59737828, 0.40262172]),\n",
       " array([0.64606742, 0.35393258]),\n",
       " array([0.5093633, 0.4906367]),\n",
       " array([0.67134831, 0.32865169]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.66666667, 0.33333333]),\n",
       " array([0.66947566, 0.33052434]),\n",
       " array([0.66104869, 0.33895131]),\n",
       " array([0.66947566, 0.33052434]),\n",
       " array([0.66385768, 0.33614232]),\n",
       " array([0.67696629, 0.32303371]),\n",
       " array([0.65543071, 0.34456929]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.71722846, 0.28277154]),\n",
       " array([0.68164794, 0.31835206]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.6928839, 0.3071161]),\n",
       " array([0.68445693, 0.31554307]),\n",
       " array([0.67790262, 0.32209738]),\n",
       " array([0.67790262, 0.32209738]),\n",
       " array([0.6835206, 0.3164794]),\n",
       " array([0.6835206, 0.3164794]),\n",
       " array([0.68071161, 0.31928839]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.67602996, 0.32397004]),\n",
       " array([0.67322097, 0.32677903]),\n",
       " array([0.69007491, 0.30992509]),\n",
       " array([0.71441948, 0.28558052]),\n",
       " array([0.82865169, 0.17134831]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.73689139, 0.26310861]),\n",
       " array([0.74157303, 0.25842697]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.72378277, 0.27621723]),\n",
       " array([0.71816479, 0.28183521]),\n",
       " array([0.74438202, 0.25561798]),\n",
       " array([0.73782772, 0.26217228]),\n",
       " array([0.71535581, 0.28464419]),\n",
       " array([0.8005618, 0.1994382]),\n",
       " array([0.80243446, 0.19756554]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.68258427, 0.31741573]),\n",
       " array([0.68913858, 0.31086142]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.70599251, 0.29400749]),\n",
       " array([0.70037453, 0.29962547]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.68539326, 0.31460674]),\n",
       " array([0.68913858, 0.31086142]),\n",
       " array([0.69756554, 0.30243446]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.69101124, 0.30898876]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.70786517, 0.29213483]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.69194757, 0.30805243]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.67883895, 0.32116105]),\n",
       " array([0.68726592, 0.31273408]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.6994382, 0.3005618]),\n",
       " array([0.72565543, 0.27434457]),\n",
       " array([0.72003745, 0.27996255]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.71910112, 0.28089888]),\n",
       " array([0.69850187, 0.30149813]),\n",
       " array([0.69569288, 0.30430712]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.70505618, 0.29494382]),\n",
       " array([0.70224719, 0.29775281]),\n",
       " array([0.70318352, 0.29681648]),\n",
       " array([0.71161049, 0.28838951]),\n",
       " array([0.7340824, 0.2659176]),\n",
       " array([0.73220974, 0.26779026]),\n",
       " array([0.70692884, 0.29307116]),\n",
       " array([0.72191011, 0.27808989]),\n",
       " array([0.71629213, 0.28370787]),\n",
       " array([0.69662921, 0.30337079]),\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dsrf.predict_proba(testing.iloc[:, 0:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.5846228239845261\n",
      "Male accuracy: 0.7627608047690015\n",
      "Female accuracy: 0.2553374655647383\n",
      "ROC_AUC score: 0.5090491351668699\n",
      "Average Precision score: 0.3553857341988309\n"
     ]
    }
   ],
   "source": [
    "# These are the metrics from the classifier that was scored using roc_auc\n",
    "# 22\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Total accuracy: \" + str(accuracy_score(total_labels, dsrf.predict(testing.iloc[:, 0:25]), normalize=True)))\n",
    "print(\"Male accuracy: \" + str(accuracy_score(more_male, dsrf.predict(male_test.iloc[:, 0:25]), normalize=True)))\n",
    "print(\"Female accuracy: \" + str(accuracy_score(more_female, dsrf.predict(female_test.iloc[:, 0:25]), normalize=True)))\n",
    "\n",
    "print(\"ROC_AUC score: \" + str(roc_auc_score(total_labels, dsrf.predict(testing.iloc[:, 0:25]))))\n",
    "print(\"Average Precision score: \" + str(average_precision_score(total_labels, dsrf.predict(testing.iloc[:, 0:25]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76384"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34144"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_mixedequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33088"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1606"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "y_pred_rf = dsrf.predict_proba(testing.iloc[:, 0:25])[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(total_labels, y_pred_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.plot()\n",
    "plt.savefig('bmiroc.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 700, num = 10)]\n",
    "weights=['uniform', 'distance']\n",
    "algorithm=['ball_tree', 'kd_tree', 'brute', 'auto']\n",
    "leaf_size=[20, 30, 50, 70, 80, 100, 200]\n",
    "# Create the random grid\n",
    "random_grid = {'n_neighbors': n_estimators,\n",
    "               'weights': weights,\n",
    "               'algorithm': algorithm,\n",
    "               'leaf_size': leaf_size}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_mixedequal, male_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15616391184573003"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(female_test.iloc[:, 0:25], more_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8359258569299552"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(male_test.iloc[:, 0:25], more_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [33088, 45408]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-13684032f567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [33088, 45408]"
     ]
    }
   ],
   "source": [
    "knn.score(testing.iloc[:, 0:25], total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC_AUC score: \" + str(roc_auc_score(total_labels, knn.predict(testing.iloc[:, 0:25]))))\n",
    "print(\"Average Precision score: \" + str(average_precision_score(total_labels, knn.predict(testing.iloc[:, 0:25]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16544"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(male_zero).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KNeighborsClassifier' object has no attribute 'decision_function'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-91af1d20a65f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_mixedequal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmale_zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[1;32m    384\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             )\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myList = list(range(10, 300))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = filter(lambda x: x % 50 != 0, myList)\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_mixedequal, male_zero, cv=5, scoring='roc_auc')\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbors = list(filter(lambda x: x % 100 != 0, myList))\n",
    "\n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - BMI Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "tengaps_total  = pd.read_hdf('tengaps_total.h5', 'df')\n",
    "\n",
    "# Min number of samples is 352... total subjects after filtering is 311\n",
    "tengaps_total = min_df(find_lowest_num_samples(tengaps_total), tengaps_total)\n",
    "\n",
    "\n",
    "tengaps_bmi = tengaps_total[tengaps_total.weight < 400]\n",
    "tengaps_bmi = tengaps_total[tengaps_total.weight > 80]\n",
    "\n",
    "# this dataframe doesn't have demographic data\n",
    "tengaps_bmi = tengaps_total.drop(columns=['sex', 'currentAge', 'weight', 'height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BMI = []\n",
    "for q in list(set(tengaps_total.index.values)):\n",
    "    temp = []\n",
    "    temp.append(((tengaps_total.loc[q].weight.values) / (((tengaps_total.loc[q].height.values)**2))) * 703)\n",
    "    BMI.append(temp)\n",
    "    \n",
    "BMI = np.array(BMI)\n",
    "BMI = BMI.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bins(BMI):\n",
    "    '''\n",
    "    Returns a list of bins (labels) depending on the BMI category\n",
    "    0 - severely underweight\n",
    "    1 - underweight\n",
    "    2 - normal\n",
    "    3 - overweight\n",
    "    4 - severely overweight\n",
    "    '''\n",
    "    bins = []\n",
    "    for x in range(0, len(BMI)):\n",
    "        if BMI[x] < 18.5:\n",
    "            bins.append(0)\n",
    "        elif BMI[x] >= 18.5 and BMI[x] < 25:\n",
    "            bins.append(1)\n",
    "        elif BMI[x] >= 25 and BMI[x] < 30:\n",
    "            bins.append(2)\n",
    "        else:\n",
    "            bins.append(3)\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_bins = create_bins(BMI)\n",
    "tengaps_bmi.insert(25, 'BMIbins', final_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell is dedicated to creating a balanced class training set\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numOfTotalHC = 311\n",
    "numOfTrainHC = 186\n",
    "numOfTestHC = 125\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "training = tengaps_bmi.iloc[0:(numOfTrainHC * find_lowest_num_samples(tengaps_bmi))]\n",
    "\n",
    "X = np.array(training.iloc[:, 0:25])\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y = np.array(training.iloc[:, 25])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_mixed = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixed = np.concatenate((y_train, y_test), axis=0)\n",
    "# Splits the training and testing into 80/20 with no sample scrambling\n",
    "# Must scramble after so that training set has no test samples in it\n",
    "#training = everything.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = tengaps_bmi.iloc[(numOfTrainHC * find_lowest_num_samples(tengaps_bmi)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfbmi = RandomForestClassifier(n_estimators=30)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "#rf_bmi = RandomizedSearchCV(estimator = rfbmi, param_distributions = random_grid, n_iter = 20, scoring='accuracy', cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rfbmi.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "bestrf = RandomForestClassifier(n_estimators=45, min_samples_split=2, min_samples_leaf=2, max_depth=50, bootstrap=False, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=45, n_jobs=1,\n",
       "            oob_score=False, random_state=22, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestrf.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3642750176180409"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestrf.score(testing.iloc[:, 0:25], testing.iloc[:, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  132  191   29]\n",
      " [   0 9428 5156 3016]\n",
      " [   0 9315 5322 2259]\n",
      " [   0 6497 2272 1791]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(str(confusion_matrix(testing.iloc[:, 25], bestrf.predict(testing.iloc[:, 0:25]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor - BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "tengaps_total  = pd.read_hdf('tengaps_total.h5', 'df')\n",
    "\n",
    "# Min number of samples is 352... total subjects after filtering is 311\n",
    "tengaps_total = min_df(find_lowest_num_samples(tengaps_total), tengaps_total)\n",
    "\n",
    "\n",
    "tengaps_bmi = tengaps_total[tengaps_total.weight < 400]\n",
    "tengaps_bmi = tengaps_total[tengaps_total.weight > 80]\n",
    "\n",
    "# this dataframe doesn't have demographic data\n",
    "tengaps_bmiflat = tengaps_total.drop(columns=['sex', 'currentAge', 'weight', 'height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BMI = []\n",
    "for q in list(set(tengaps_total.index.values)):\n",
    "    temp = []\n",
    "    temp.append(((tengaps_total.loc[q].weight.values) / (((tengaps_total.loc[q].height.values)**2))) * 703)\n",
    "    BMI.append(temp)\n",
    "    \n",
    "BMI = np.array(BMI)\n",
    "BMI = BMI.flatten()\n",
    "tengaps_bmiflat.insert(25, 'BMI', BMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is dedicated to creating a balanced class training set\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numOfTotalHC = 311\n",
    "numOfTrainHC = 186\n",
    "numOfTestHC = 125\n",
    "\n",
    "# Shouldn't have to one-hot encode the sex because using random forest\n",
    "training = tengaps_bmiflat.iloc[0:(numOfTrainHC * find_lowest_num_samples(tengaps_bmiflat))]\n",
    "\n",
    "X = np.array(training.iloc[:, 0:25])\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y = np.array(training.iloc[:, 25])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_mixed = np.concatenate((X_train, X_test), axis=0)\n",
    "y_mixed = np.concatenate((y_train, y_test), axis=0)\n",
    "# Splits the training and testing into 80/20 with no sample scrambling\n",
    "# Must scramble after so that training set has no test samples in it\n",
    "#training = everything.iloc[0:(numOfTrainHC * find_lowest_num_samples(newtotal_df))]\n",
    "testing = tengaps_bmiflat.iloc[(numOfTrainHC * find_lowest_num_samples(tengaps_bmiflat)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 1000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfreg = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_rand_reg = RandomizedSearchCV(estimator = rfreg, param_distributions = random_grid, n_iter = 5, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_rand_reg.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=90,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=4, min_samples_split=10,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=230, n_jobs=1,\n",
       "           oob_score=False, random_state=22, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfregfinal = RandomForestRegressor(n_estimators=230, min_samples_split=10, min_samples_leaf=4, max_depth=90, bootstrap=False, random_state=22)\n",
    "rfregfinal.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.007860755320008073"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WORSE THAN A HORIZONTAL LINE... BAD\n",
    "rfregfinal.score(testing.iloc[:, 0:25], testing.iloc[:, 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor - BMI Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#myList = list(range(10, 1000))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "#neighbors = filter(lambda x: x % 10 != 0, myList)\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "#cv_scores = []\n",
    "\n",
    "#for k in neighbors:\n",
    "#    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "#    scores = cross_val_score(knn, X_mixedequal, male_zero, cv=5, scoring='accuracy')\n",
    "#    cv_scores.append(scores.mean())\n",
    "\n",
    "kbmi = KNeighborsClassifier(n_neighbors=9)\n",
    "kbmi.fit(X_mixed, y_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38909443269908384"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbmi.score(testing.iloc[:, 0:25],testing.iloc[:, 25])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
